@article{Melara2015,
author = {Melara, Marcela S and Blankstein, Aaron and Bonneau, Joseph and Felten, Edward W and Freedman, Michael J},
journal = {usenix security},
pages = {1--16},
title = {{CONIKS : Bringing Key Transparency to End Users}},
year = {2015}
}
@article{Sabottke2015,
author = {Sabottke, Carl and Dumitras, Tudor},
isbn = {9781931971232},
journal = {usenix security},
title = {{Vulnerability Disclosure in the Age of Social Media : Exploiting Twitter for Predicting Real-World Exploits}},
year = {2015}
}
@article{Wang2015,
author = {Wang, Shuai and Wang, Pei and Wu, Dinghao},
isbn = {9781931971232},
journal = {usenix security},
title = {{Reassembleable Disassembling}},
year = {2015}
}
@article{Soska2015,
author = {Soska, Kyle and Christin, Nicolas},
isbn = {9781931971232},
journal = {usenix security},
pages = {33--48},
title = {{Measuring the Longitudinal Evolution of the Online Anonymous Marketplace Ecosystem}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Post-Mortem of a Zombie: Conficker Cleanup After Six Years}},
year = {2015}
}
@article{Chen2015,
author = {Chen, Jin and Chen, Haibo and Bauman, Erick and Lin, Zhiqiang and Zang, Binyu and Guan, Haibing},
journal = {usenix security},
title = {{You Shouldn’t Collect My Secrets: Thwarting Sensitive Keystroke Leakage in Mobile IME Apps}},
url = {papers3://publication/uuid/6B7A0206-A821-40C5-AEAF-E8C7CA5FA510},
year = {2015}
}
@article{Behaviors2015,
author = {Behaviors, App-usage},
journal = {usenix security},
title = {{LinkDroid : Reducing Unregulated Aggregation of}},
year = {2015}
}
@article{Vanhoef2015,
abstract = {We present new biases in RC4, break the Wi-Fi Protected Access Temporal Key Integrity Protocol (WPA-TKIP), and design a practical plaintext recovery attack against the Transport Layer Security (TLS) protocol. To empir- ically find new biases in the RC4 keystream we use sta- tistical hypothesis tests. This reveals many new biases in the initial keystream bytes, as well as several new long- term biases. Our fixed-plaintext recovery algorithms are capable of using multiple types of biases, and return a list of plaintext candidates in decreasing likelihood. To break WPA-TKIP we introduce a method to gen- erate a large number of identical packets. This packet is decrypted by generating its plaintext candidate list, and using redundant packet structure to prune bad candidates. From the decrypted packet we derive the TKIP MIC key, which can be used to inject and decrypt packets. In prac- tice the attack can be executed within an hour. We also attack TLS as used by HTTPS, where we show how to decrypt a secure cookie with a success rate of 94{\{}{\%}{\}} using 9 · 2 27 ciphertexts. This is done by injecting known data around the cookie, abusing this using Mantin’s ABSAB bias, and brute-forcing the cookie by traversing the plain- text candidates. Using our traffic generation technique, we are able to execute the attack in merely 75 hours.},
author = {Vanhoef, Mathy},
doi = {10.1353/mis.2012.0028},
isbn = {9781931971232},
journal = {usenix security},
number = {2},
pages = {128--145},
title = {{Your Biases Belong To Us: Breaking RC4 in WPA-TKIP and TLS}},
volume = {35},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{How the ELF Ruined Christmas}},
year = {2015}
}
@article{Graziano2015,
author = {Graziano, Mariano and Canali, Davide and Bilge, Leyla and Lanzi, Andrea and Balzarotti, Davide and Canali, Davide and Balzarotti, Davide and Lanzi, Andrea},
isbn = {9781931971232},
journal = {usenix security},
title = {{Needles in a Haystack : Mining Information from Public Dynamic Analysis Sandboxes for Malware Intelligence This paper is included in the Proceedings of the}},
year = {2015}
}
@article{Liu2015,
author = {Liu, Yang and Sarabi, Armin and Zhang, Jing and Naghizadeh, Parinaz and Karir, Manish and Bailey, Michael and Liu, Mingyan and Arbor, Ann},
isbn = {9781931971232},
journal = {usenix security},
title = {{Cloudy with a Chance of Breach : Forecasting Cyber Security Incidents}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{GSMem: Data Exfiltration from Air-Gapped Computers over GSM Frequencies }},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{The Unexpected Dangers of Dynamic JavaScript}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{UIPicker : User-Input Privacy Identification in Mobile Applications}},
year = {2015}
}
@article{Dinh2015,
author = {Dinh, Tien Tuan Anh and Saxena, Prateek and Chang, Ee-Chien and Ooi, Beng Chin and Zhang, Chunwang},
journal = {usenix security},
title = {{M2R: Enabling Stronger Privacy in MapReduce Computation}},
year = {2015}
}
@article{Reaves2015,
author = {Reaves, Brad and Shernan, Ethan and Bates, Adam and Carter, Henry and Traynor, Patrick},
journal = {usenix security},
title = {{Boxed Out: Blocking Cellular Interconnect Bypass Fraud at the Network Edge}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Towards Discovering and Understanding Task Hijacking in Android}},
year = {2015}
}
@article{Chul2015,
author = {Chul, Eui and Shin, Richard and Song, Dawn and Moazzezi, Reza},
isbn = {9781931971232},
journal = {usenix security},
title = {{Recognizing Functions in Binaries with Neural Networks}},
year = {2015}
}
@article{Fawaz2015,
author = {Fawaz, Kassem and Feng, Huan and Shin, Kang G},
isbn = {9781931971232},
journal = {usenix security},
title = {{Anatomization and Protection of Mobile Apps ’ Location Privacy Threats}},
year = {2015}
}
@article{Nelms2015,
abstract = {Most modern malware download attacks occur via the browser, typically due to social engineering and drive-by downloads. In this paper, we study the " origin " of malware download attacks experienced by real network users, with the objective of improving malware down-load defenses. Specifically, we study the web paths fol-lowed by users who eventually fall victim to different types of malware downloads. To this end, we propose a novel incident investigation system, named WebWitness. Our system targets two main goals: 1) automatically trace back and label the sequence of events (e.g., visited web pages) preceding malware downloads, to highlight how users reach attack pages on the web; and 2) leverage these automatically labeled in-the-wild malware down-load paths to better understand current attack trends, and to develop more effective defenses. We deployed WebWitness on a large academic net-work for a period of ten months, where we collected and categorized thousands of live malicious download paths. An analysis of this labeled data allowed us to design a new defense against drive-by downloads that rely on in-jecting malicious content into (hacked) legitimate web pages. For example, we show that by leveraging the inci-dent investigation information output by WebWitness we can decrease the infection rate for this type of drive-by downloads by almost six times, on average, compared to existing URL blacklisting approaches.},
author = {Nelms, Terry and Perdisci, Roberto and Antonakakis, Manos and Ahamad, Mustaque},
journal = {usenix security},
title = {{WebWitness: Investigating, Categorizing, and Mitigating Malware Download Paths}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{In the Compression Hornet’s Nest: A Security Study of Data Compression in Network Services }},
year = {2015}
}
@article{Ur2015,
author = {Ur, Blase and Segreti, Sean M and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith and Komanduri, Saranga and Kurilova, Darya and Mazurek, Michelle L and Melicher, William and Shay, Richard},
isbn = {978-1-931971-232},
journal = {usenix security},
pages = {463--481},
title = {{Measuring real-world accuracies and biases in modeling password guessability}},
url = {https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ur},
year = {2015}
}
@article{Reaves2015a,
author = {Reaves, Bradley and Scaife, Nolen and Bates, Adam and Traynor, Patrick and Butler, Kevin},
isbn = {9781931971232},
journal = {usenix security},
title = {{Mo(bile) Money, Mo(bile) Problems: Analysis of Branchless Banking Applications in the Developing World}},
year = {2015}
}
@article{Jagpal2015,
abstract = {In this work we expose wide-spread efforts by crimi-nals to abuse the Chrome Web Store as a platform for distributing malicious extensions. A central compo-nent of our study is the design and implementation of WebEval, the first system that broadly identifies mali-cious extensions with a concrete, measurable detection rate of 96.5{\{}{\%}{\}}. Over the last three years we detected 9,523 malicious extensions: nearly 10{\{}{\%}{\}} of every ex-tension submitted to the store. Despite a short window of operation—we removed 50{\{}{\%}{\}} of malware within 25 minutes of creation— a handful of under 100 extensions escaped immediate detection and infected over 50 mil-lion Chrome users. Our results highlight that the exten-sion abuse ecosystem is drastically different from ma-licious binaries: miscreants profit from web traffic and user tracking rather than email spam or banking theft.},
author = {Jagpal, Nav and Dingle, Eric and Gravel, Jean-Philippe and Mavrommatis, Panayiotis and Provos, Niels and Abu, Moheeb and Kurt, Rajab and Google, Thomas},
isbn = {9781931971232},
journal = {usenix security},
title = {{Trends and Lessons from Three Years Fighting Malicious Extensions}},
year = {2015}
}
@article{Ren2015,
author = {Ren, Ling and Kwon, Albert and Dijk, Marten Van},
journal = {usenix security},
title = {{Constants Count : Practical Improvements to Oblivious RAM}},
url = {https://eprint.iacr.org/2014/997.pdf},
year = {2015}
}
@article{Varadarajan2015,
abstract = {Public infrastructure-as-a-service clouds, such as Amazon EC2, Google Compute Engine (GCE) and Microsoft Azure allow clients to run virtual machines (VMs) on shared physical infrastructure. This practice of multi-tenancy brings economies of scale, but also introduces the risk of sharing a physical server with an arbitrary and potentially malicious VM. Past works have demonstrated how to place a VM alongside a target victim (co-location) in early-generation clouds and how to extract secret information via side- channels. Although there have been numerous works on side-channel attacks, there have been no studies on placement vulnerabilities in public clouds since the adoption of stronger isolation technologies such as Virtual Private Clouds (VPCs). We investigate this problem of placement vulnerabilities and quantitatively evaluate three popular public clouds for their susceptibility to co-location attacks. We find that adoption of new technologies (e.g., VPC) makes many prior attacks, such as cloud cartography, ineffective. We find new ways to reliably test for co-location across Amazon EC2, Google GCE, and Microsoft Azure. We also found ways to detect co-location with victim web servers in a multi-tiered cloud application located behind a load balancer. We use our new co-residence tests and multiple customer accounts to launch VM instances under different strategies that seek to maximize the likelihood of co-residency. We find that it is much easier (10x higher success rate) and cheaper (up to {\{}{\$}{\}}114 less) to achieve co-location in these three clouds when compared to a secure reference placement policy.},
archivePrefix = {arXiv},
arxivId = {1507.03114},
author = {Varadarajan, Venkatanathan and Zhang, Yinqian and Ristenpart, Thomas and Swift, Michael},
eprint = {1507.03114},
journal = {usenix security},
keywords = {cloud se-,co-location detection,multi-tenancy},
title = {{A Placement Vulnerability Study in Multi-tenant Public Clouds}},
url = {http://arxiv.org/abs/1507.03114},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{and De-anonymization}},
year = {2015}
}
@article{Michalevsky2015,
archivePrefix = {arXiv},
arxivId = {1502.03182v2},
author = {Michalevsky, Yan and Boneh, Dan and Schulman, Aaron and Nakibly, Gabi},
eprint = {1502.03182v2},
journal = {usenix security},
title = {{PowerSpy: Location Tracking using Mobile Device Power Analysis}},
year = {2015}
}
@article{Beringer2015,
abstract = {We have proved, with machine-checked proofs in Coq, that an OpenSSL implementation of HMAC with SHA-256 correctly implements its FIPS functional specifi-cation and that its functional specification guarantees the expected cryptographic properties. This is the first machine-checked cryptographic proof that combines a source-program implementation proof, a compiler-correctness proof, and a cryptographic-security proof, with no gaps at the specification interfaces. The verification was done using three systems within the Coq proof assistant: the Foundational Cryptogra-phy Framework, to verify crypto properties of functional specs; the Verified Software Toolchain, to verify C pro-grams w.r.t. functional specs; and CompCert, for verified compilation of C to assembly language.},
author = {Beringer, Lennart and Petcher, Adam and Ye, Katherine Q and Appel, Andrew W},
isbn = {9781931971232},
journal = {usenix security},
title = {{Verified correctness and security of OpenSSL HMAC}},
year = {2015}
}
@article{Larapanos2015,
abstract = {Two-factor authentication protects online accounts even if passwords are leaked. Most users, however, still prefer password-only authentication. One of the reasons behind two-factor authentication being unpopular is the extra steps that the user must complete in order to log in. Current two-factor authentication mechanisms require the user to interact with his phone, and e.g., copy a verification code to the browser. In this paper we propose Sound-Proof, a two-factor authentication mechanism that does not require interaction between the user and his phone. In Sound-Proof the second authentication factor is the proximity of the user's phone to the device being used to log in. The proximity of the two devices is verified by comparing the ambient noise recorded by their microphones. Audio recording and comparison are transparent to the user. Sound-Proof can be easily deployed as it works with major browsers without plugins. We build a prototype for both Android and iOS. We provide empirical evidence that ambient noise is a robust discriminant to determine the proximity of two devices both indoors and outdoors, and even if the phone is in a pocket or purse. We further conduct a user study designed to compare the perceived usability of Sound-Proof with Google 2-Step Verification. Participants ranked Sound-Proof as more usable and the majority would be willing to use Sound-Proof even for scenarios in which two-factor authentication is optional.},
archivePrefix = {arXiv},
arxivId = {arXiv:1503.03790v2},
author = {Larapanos, Nikolaos and Marforio, Claudio and Soriente, Claudio and Capkun, Srdjan},
eprint = {arXiv:1503.03790v2},
journal = {usenix security},
pages = {1--16},
title = {{Sound-Proof: Usable Two-Factor Authentication Based on Ambient Sound}},
url = {http://arxiv.org/pdf/1503.03790v2.pdf},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Marionette: A Programmable Network Traffic Obfuscation System}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Rocking Drones with Intentional Sound Noise on Gyroscopic Sensors}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-son.pdf},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Compiler-instrumented, Dynamic Secret-Redaction of Legacy Processes for Attacker Deception}},
year = {2015}
}
@article{Carlini2015,
author = {Carlini, Nicolas and Barresi, Antonio and Z{\"{u}}rich, E T H and Payer, Mathias and Wagner, David and Gross, Thomas R and Z{\"{u}}rich, E T H and Carlini, Nicolas and Barresi, Antonio and Wagner, David and Gross, Thomas R},
isbn = {9781931971232},
journal = {usenix security},
title = {{Control-Flow Bending : On the Effectiveness of Control-Flow Integrity}},
year = {2015}
}
@article{Masti2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1503.07000v1},
author = {Masti, Ramya Jayaram and Rai, Devendra and Ranganathan, Aanjhan and Christian, M},
eprint = {arXiv:1503.07000v1},
journal = {usenix security},
number = {i},
title = {{Thermal Covert Channels on Multi-core Platforms}},
year = {2015}
}
@article{Xu2015,
author = {Xu, Zhang and Wang, Haining and Wu, Zhenyu},
isbn = {9781931971232},
journal = {usenix security},
pages = {929--944},
title = {{A Measurement Study on Co-residence Threat inside the Cloud}},
year = {2015}
}
@article{Ramos2015,
author = {Ramos, David A and Engler, Dawson},
isbn = {9781931971232},
journal = {usenix security},
title = {{Under-Constrained Symbolic Execution : Correctness Checking for Real Code This paper is included in the Proceedings of the Correctness Checking for Real Code}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-ramos.pdf},
year = {2015}
}
@article{Weissbacher2015,
author = {Weissbacher, Michael and Robertson, William and Kruegel, Christopher and Vigna, Giovanni},
journal = {usenix security},
title = {{ZigZag : Automatically Hardening Web Applications Against Client-side Validation Vulnerabilities}},
year = {2015}
}
@article{Rane2015,
author = {Rane, Ashay and Lin, Calvin},
journal = {usenix security},
title = {{Raccoon : Closing Digital Side-Channels through Obfuscated Execution}},
year = {2015}
}
@article{Caliskan-Islam2015,
abstract = {—Source code authorship attribution could provide proof of authorship in court, automate the process of finding a cyber criminal from the source code left in an infected system, or aid in resolving copyright, copyleft and plagiarism issues in the programming fields. In this work, we investigate methods to de-anonymize source code authors of C++ using coding style. We cast source code authorship attribution as a machine learning problem using natural language processing techniques to extract the necessary features. The Code Stylometry Feature Set is a novel representation of coding style found in source code that reflects coding style from properties derived from abstract syntax trees. Such a unique representation of coding style has not been used before in code attribution. Our random forest and abstract syntax tree-based approach attributes more authors (250) with significantly higher accuracy (95{\{}{\%}{\}}) on a larger data set (Google Code Jam) than has been previously attempted. Furthermore these novel features are more robust than previous approaches, and are still able to attribute authors even when code is run through commercial obfuscation with no significant change in accuracy. This analysis also pro-duces interesting insights relevant to software engineering. We find that (i) the code resulting from difficult programming tasks is easier to attribute than easier tasks and (ii) skilled programmers (who can complete the more difficult tasks) are easier to attribute than less skilled programmers.},
author = {Caliskan-Islam, Aylin and Harang, Richard and Liu, Andrew and Narayanan, Arvind and Voss, Clare and Yamaguchi, Fabian and Greenstadt, Rachel},
isbn = {9781931971232},
journal = {usenix security},
title = {{De-anonymizing Programmers via Code Stylometry}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{EvilCohort: Detecting Communities of Malicious Accounts on Online Services}},
year = {2015}
}
@article{Pinkas2015,
author = {Pinkas, Benny and Schneider, Thomas and Zohner, Michael and Segev, Gil},
isbn = {9781931971232},
journal = {usenix security},
title = {{Phasing : Private Set Intersection using Permutation-based Hashing}},
year = {2015}
}
@article{Oltrogge2015,
abstract = {.They help in using PIN. 639k apps. only 45 use pin (they look for customized version of TrustManager). They detect if an app could be adapted to pin. They use slicing on Java part with special care of string building. Conservative: all API strings from hardcoded URL. Permissive: some stuff ignored (e.g., internal Intent) 1.8{\{}{\%}{\}} or 425{\{}{\%}{\}} can use pinning. Do not consider API used by libraries. Raccomend self pinning for selfsigned, otherwise CA pinning. User study: 25{\{}{\%}{\}} developers understand pinning, 40{\{}{\%}{\}} tried but too hard. They develop a tool that suggest if pinning is usable and also provide code to do pinning to developers based on already used certificate.},
author = {Oltrogge, Marten and Acar, Yasemin and Dechand, Sergej and Smith, Matthew and Fahl, Sascha},
isbn = {9781931971232},
journal = {usenix security},
title = {{To Pin or Not to Pin — Helping App Developers Bullet Proof Their TLS Connections}},
year = {2015}
}
@article{DeRuiter2015,
author = {de Ruiter, J and Poll, E},
isbn = {9781931971232},
journal = {usenix security},
title = {{Protocol state fuzzing of TLS implementations}},
url = {http://www.cs.bham.ac.uk/{\{}{~}{\}}deruitej/papers/usenix15.pdf},
year = {2015}
}
@article{Ming2015,
author = {Ming, Jiang and Wu, Dinghao and Xiao, Gaoyao and Wang, Jun and Liu, Peng},
isbn = {9781931971232},
journal = {usenix security},
title = {{TaintPipe: Pipelined Symbolic Taint Analysis}},
url = {papers3://publication/uuid/28C7B549-B88A-413B-BB57-C25A202402DF},
year = {2015}
}
@article{Fayaz2015,
abstract = {Networks today rely on expensive and proprietary hard- ware appliances, which are deployed at fixed locations, for DDoS defense. This introduces key limitations with respect to flexibility (e.g., complex routing to get traffic to these "chokepoints") and elasticity in handling changing attack patterns. We observe an opportunity to ad- dress these limitations using new networking paradigms such as software-defined networking (SDN) and network functions virtualization (NFV). Based on this observation, we design and implement of Bohatei, an elastic and flexible DDoS defense system. In designing Bohatei, we address key challenges of scalability, responsive- ness, and adversary-resilience. We have implemented defenses for several well-known DDoS attacks in Bohatei. Our evaluations show that Bohatei is scalable (handling 500 Gbps attacks), responsive (mitigating attacks within one minute), and resilient to dynamic adversaries.},
archivePrefix = {arXiv},
arxivId = {1506.08501},
author = {Fayaz, Seyed K and Tobioka, Yoshiaki and Sekar, Vyas and Bailey, Michael},
eprint = {1506.08501},
isbn = {9781931971232},
journal = {usenix security},
title = {{Bohatei: Flexible and Elastic DDoS Defense}},
url = {http://arxiv.org/abs/1506.08501},
year = {2015}
}
@article{Heilman2015,
author = {Heilman, Ethan and Kendler, Alison and Goldberg, Sharon and Israel, M S R},
journal = {usenix security},
number = {August},
title = {{Eclipse Attacks on Bitcoin ’ s Peer-to-Peer Network ∗}},
year = {2015}
}
@article{Chen2015a,
author = {Chen, Kai and Wang, Peng and Lee, Yeonjoon and Wang, Xiaofeng and Zhang, Nan and Huang, Heqing and Zou, Wei and Liu, Peng},
isbn = {9781931971232},
journal = {usenix security},
title = {{Finding Unknown Malice in 10 Seconds : Mass Vetting for New Threats at the Google-Play Scale}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Faster Secure Computation through Automatic Parallelization}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Boxify: Full-fledged App Sandboxing for Stock Android}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{The Pythia PRF Service}},
year = {2015}
}
@article{Kaloper-mersinjak2015,
author = {Kaloper-mer{\v{s}}injak, David and Mehnert, Hannes and Madhavapeddy, Anil and Sewell, Peter and Kaloper-merˇ, David},
isbn = {9781931971232},
journal = {usenix security},
title = {{Not-Quite-So-Broken TLS : Lessons in Re-Engineering a Security Protocol Specification and Implementation This paper is included in the Proceedings of the specification and implementation}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Large-Scale Semi-Supervised Learning}},
year = {2015}
}
@article{Wijesekera2015,
abstract = {Due to the amount of data that smartphone applications can potentially access, platforms enforce permission systems that allow users to regulate how applications access protected resources. If users are asked to make security decisions too frequently and in benign situations, they may become habituated and approve all future requests without regard for the consequences. If they are asked to make too few security decisions, they may become concerned that the platform is revealing too much sensitive information. To explore this tradeoff, we instrumented the Android platform to collect data regarding how often and under what circumstances smartphone applications are accessing protected resources regulated by permissions. We performed a 36-person field study to explore the notion of "contextual integrity," that is, how often are applications accessing protected resources when users are not expecting it? Based on our collection of 27 million data points and exit interviews with participants, we examine the situations in which users would like the ability to deny applications access to protected resources. We found out that at least 80{\{}{\%}{\}} of our participants would have preferred to prevent at least one permission request, and overall, they thought that over a third of requests were invasive and desired a mechanism to block them.},
archivePrefix = {arXiv},
arxivId = {1504.03747},
author = {Wijesekera, Primal and Baokar, Arjun and Hosseini, Ashkan and Egelman, Serge and Wagner, David and Beznosov, Konstantin},
eprint = {1504.03747},
isbn = {9781931971232},
journal = {usenix security},
title = {{Android Permissions Remystified: A Field Study on Contextual Integrity}},
url = {http://arxiv.org/abs/1504.03747},
year = {2015}
}
@article{Huang2015,
author = {Huang, Jianjun and Li, Zhichun and Xiao, Xusheng and Wu, Zhenyu and Lu, Kangjie and Zhang, Xiangyu},
isbn = {9781931971232},
journal = {usenix security},
title = {{SUPOR : Precise and Scalable Sensitive User Input Detection for Android Apps}},
year = {2015}
}
@article{Garman2015,
abstract = {Despite recent high-profile attacks on the RC4 algorithm in TLS, its usage is still running at about 30{\{}{\%}{\}} of all TLS traffic. This is attributable to the lack of practicality of the existing attacks, the desire to support legacy implementations, and resistance to change. We provide new attacks against RC4 in TLS that are focussed on recovering user passwords, still the pre-eminent means of user authentication on the Web today. Our attacks enhance the statistical techniques used in the existing attacks and exploit specific features of the password setting to produce attacks that are much closer to being practical. We report on extensive simulations that illustrate this. We also report on two " proof of concept " implementations of the attacks for specific application layer protocols, namely BasicAuth and IMAP. Our work validates the truism that attacks only get better with time: we obtain good success rates in recovering user passwords with around 2 26 encryptions, whereas the previous generation of attacks required 2 34 encryptions to recover an HTTP session cookie.},
author = {Garman, Christina and Paterson, Kenneth G and {Van Der Merwe}, Thyla and Holloway, Royal},
journal = {usenix security},
title = {{Attacks Only Get Better: Password Recovery Attacks Against RC4 in TLS}},
year = {2015}
}
@article{Hu2015,
abstract = {As defense solutions against control-flow hijacking attacks gain wide deployment, control-oriented exploits from memory errors become difficult. As an alternative, attacks targeting non-control data do not require diverting the application’s control flow during an attack. Although it is known that such data-oriented attacks can mount significant damage, no systematic methods to automatically construct them from memory errors have been developed. In this work, we develop a new technique called data-flow stitching, which systematically finds ways to join data flows in the program to generate data-oriented exploits. We build a prototype embodying our technique in a tool called FLOWSTITCH that works directly on Windows and Linux binaries. In our experiments, we find that FLOWSTITCH automatically constructs 16 previously unknown and three known data-oriented attacks from eight real-world vulnerable programs. All the automatically-crafted exploits respect fine-grained CFI and DEP constraints, and 10 out of the 19 exploits work with standard ASLR defenses enabled. The constructed exploits can cause significant damage, such as disclosure of sensitive information (e.g., passwords and encryption keys) and escalation of privilege.},
author = {Hu, Hong and Chua, Zheng Leong and Adrian, Sendroiu and Saxena, Prateek and Liang, Zhenkai},
isbn = {9781931971232},
journal = {usenix security},
title = {{Automatic Generation of Data-Oriented Exploits}},
year = {2015}
}
@article{Borgolte2015,
author = {Borgolte, Kevin and Kruegel, Christopher and Vigna, Giovanni and Borgolte, Kevin and Kruegel, Christopher and Vigna, Giovanni},
isbn = {9781931971232},
journal = {usenix security},
title = {{Meerkat : Detecting Website Defacements through Image-based Object Recognition This paper is included in the Proceedings of the}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Securing Self-Virtualizing Ethernet Devices}},
year = {2015}
}
@article{Gruss2015,
author = {Gruss, Daniel and Spreitzer, Raphael and Mangard, Stefan},
journal = {usenix security},
title = {{Cache Template Attacks: Automating Attacks on Inclusive Last-Level Caches}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Cashtags: Protecting the Input and Display of Sensitive Data}},
year = {2015}
}
@article{Kwon2015,
abstract = {This paper sheds light on crucial weaknesses in the design of hidden services that allow us to break the anonymity of hidden service clients and operators pas- sively. In particular, we show that the circuits, paths established through the Tor network, used to commu- nicate with hidden services exhibit a very different be- havior compared to a general circuit. We propose two attacks, under two slightly different threat models, that could identify a hidden service client or operator using these weaknesses. We found that we can identify the users’ involvement with hidden services with more than 98{\{}{\%}{\}} true positive rate and less than 0.1{\{}{\%}{\}} false positive rate with the first attack, and 99{\{}{\%}{\}} true positive rate and 0.07{\{}{\%}{\}} false positive rate with the second. We then re- visit the threat model of previous website fingerprinting attacks, and show that previous results are directly ap- plicable, with greater efficiency, in the realm of hidden services. Indeed, we show that we can correctly deter- mine which of the 50 monitored pages the client is visit- ing with 88{\{}{\%}{\}} true positive rate and false positive rate as low as 2.9{\{}{\%}{\}}, and correctly deanonymize 50 monitored hidden service servers with true positive rate of 88{\{}{\%}{\}} and false positive rate of 7.8{\{}{\%}{\}} in an open world setting.},
author = {Kwon, Albert and Alsabah, Mashael and Lazar, David and Dacier, Marc and Devadas, Srinivas},
isbn = {9781931971232},
journal = {usenix security},
title = {{Circuit Fingerprinting Attacks : Passive Deanonymization of Tor Hidden Services}},
year = {2015}
}
@article{,
journal = {usenix security},
title = {{Cookies Lack Integrity: Real-World Implications}},
year = {2015}
}
@article{Sun2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1503.03940v1},
author = {Sun, Y and Edmundson, A and Vanbever, L},
eprint = {arXiv:1503.03940v1},
journal = {usenix security},
title = {{RAPTOR: routing attacks on privacy in tor}},
url = {http://arxiv.org/abs/1503.03940},
year = {2015}
}
@article{Bates2015,
author = {Bates, Adam and Tian, Dave and Butler, Kevin R B and Moyer, Thomas},
isbn = {978-1-931971-232},
journal = {usenix security},
pages = {319--334},
title = {{Trustworthy Whole-system Provenance for the Linux Kernel}},
url = {http://dl.acm.org/citation.cfm?id=2831143.2831164},
year = {2015}
}
@article{Lee2015,
abstract = {Many applications such as the Chrome and Firefox browsers are largely implemented in C++ for its performance and modularity. Type casting, which converts one type of an object to another, plays an essential role in enabling polymorphism in C++ because it allows a program to utilize certain general or specific implementations in the class hierarchies. However, if not correctly used, it may return unsafe and incorrectly casted values, leading to so-called bad-casting or type-confusion vulnerabilities. Since a bad-casted pointer violates a programmer’s intended pointer semantics and enables an attacker to corrupt memory, bad-casting has critical security implications similar to those of other memory corruption vulnerabilities. Despite the increasing number of bad-casting vulnerabilities, the bad-casting detection problem has not been addressed by the security community. In this paper, we present CAVER, a runtime bad-casting detection tool. It performs program instrumentation at compile time and uses a new runtime type tracing mechanism—the type hierarchy table—to overcome the limitation of existing approaches and efficiently verify type casting dynamically. In particular, CAVER can be easily and automatically adopted to target applications, achieves broader detection coverage, and incurs reasonable runtime overhead. We have applied CAVER to largescale software including Chrome and Firefox browsers, and discovered 11 previously unknown security vulnerabilities: nine in GNU libstdc++ and two in Firefox, all of which have been confirmed and subsequently fixed by vendors. Our evaluation showed that CAVER imposes up to 7.6{\{}{\%}{\}} and 64.6{\{}{\%}{\}} overhead for performance-intensive benchmarks on the Chromium and Firefox browsers, respectively.},
author = {Lee, Byoungyoung and Song, Chengyu and Kim, Taesoo and Lee, Wenke},
isbn = {978-1-931971-232},
journal = {usenix security},
pages = {81--96},
title = {{Type Casting Verification: Stopping an Emerging Attack Vector}},
url = {http://blogs.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/lee},
year = {2015}
}
@article{McGregor2015,
author = {McGregor, Susan E and Charters, Polina and Holliday, Tobin and Roesner, Franziska},
isbn = {9781931971232},
journal = {usenix security},
title = {{Investigating the Computer Security Practices and Needs of Journalists}},
year = {2015}
}
@article{Marczak2014,
author = {Marczak, William R and Scott-Railton, John and Marquis-Boire, Morgan and Paxson, Vern},
isbn = {9781931971157},
journal = {usenix security},
pages = {511--525},
title = {{When Governments Hack Opponents : A Look at Actors and Technology}},
year = {2014}
}
@article{Demmler2014,
abstract = {Secure two-party computation allows two mutually dis- trusting parties to jointly compute an arbitrary function on their private inputs without revealing anything but the result. An interesting target for deploying secure compu- tation protocols are mobile devices as they contain a lot of sensitive user data. However, their resource restriction makes the deployment of secure computation protocols a challenging task. In this work, we optimize and implement the secure computation protocol by Goldreich-Micali- Wigderson (GMW) on mobile phones. To increase per- formance, we extend the protocol by a trusted hardware token (i.e., a smartcard). The trusted hardware token al- lows to pre-compute most of the workload in an initial- ization phase, which is executed locally on one device and can be pre-computed independently of the later com- munication partner. We develop and analyze a proof- of-concept implementation of generic secure two-party computation on Android smart phones making use of a microSD smartcard. Our use cases include private set intersection for finding shared contacts and private scheduling of a meeting with location preferences. For private set intersection, our token-aided implementation on mobile phones is up to two orders of magnitude faster than previous generic secure two-party computation pro- tocols on mobile phones and even as fast as previous work on desktop computers.},
author = {Demmler, Daniel and Schneider, Thomas and Zohner, Michael and Universit, Technische},
isbn = {9781931971157},
journal = {usenix security},
pages = {893--908},
title = {{Ad-Hoc Secure Two-Party Computation on Mobile Devices using Hardware Tokens}},
year = {2014}
}
@article{Wang2014,
author = {Wang, Tao and Cai, Xiang and Nithyanand, Rishab and Johnson, Rob and Goldberg, Ian},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {143--157},
title = {{Effective Attacks and Provable Defenses for Website Fingerprinting}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/wang{\{}{\_}{\}}tao},
year = {2014}
}
@article{Li2014,
author = {Li, Zhigong and Han, Weili and Xu, Wenyuan},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {559--574},
title = {{A Large-Scale Empirical Analysis of Chinese Web Passwords}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/li{\{}{\_}{\}}zhigong},
year = {2014}
}
@article{Meyer2014,
author = {Meyer, Christopher and Somorovsky, Juraj and Weiss, Eugen and Schwenk, J{\"{o}}rg and Schinzel, Sebastian and Tews, Erik},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {733--748},
title = {{Revisiting SSL/TLS Implementations: New Bleichenbacher Side Channels and Attacks}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/meyer},
year = {2014}
}
@article{Lentz2014,
author = {Lentz, Matthew and Erd{\'{e}}lyi, Viktor and Aditya, Paarijaat and Shi, Elaine and Druschel, Peter and Bhattacharjee, Bobby},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {925--940},
title = {{SDDR: Light-Weight, Secure Mobile Encounters}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/lentz},
year = {2014}
}
@article{Karapanos2014,
author = {Karapanos, Nikolaos and Capkun, Srdjan},
isbn = {9781931971157},
journal = {usenix security},
title = {{On the Effective Prevention of TLS Man-in-the- Middle Attacks in Web Applications}},
year = {2014}
}
@article{Fredrikson2014,
abstract = {Zero-Knowledge; Compiler;},
author = {Fredrikson, Matthew and Livshits, Benjamin},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {909--924},
title = {{Z{\O}: An Optimizing Distributing Zero-Knowledge Compiler}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/fredrikson},
year = {2014}
}
@article{Tripp2014,
abstract = {Mobile apps often require access to private data, such as the device ID or location. At the same time, popular platforms like Android and iOS have limited support for user privacy. This frequently leads to unauthorized disclosure of private information by mobile apps, e.g. for advertising and analytics purposes. This paper addresses the problem of privacy enforcement in mobile systems, which we formulate as a classification problem: When arriving at a privacy sink (e.g., database update or outgoing web message), the runtime system must classify the sink’s behavior as either legitimate or illegitimate. The traditional approach of information-flow (or taint) tracking applies “binary” classification, whereby information release is legitimate iff there is no data flow from a privacy source to sink arguments. While this is a useful heuristic, it also leads to false alarms. We propose to address privacy enforcement as a learning problem, relaxing binary judgments into a quantitative/ probabilistic mode of reasoning. Specifically, we propose a Bayesian notion of statistical classification, which conditions the judgment whether a release point is legitimate on the evidence arising at that point. In our concrete approach, implemented as the BAYESDROID system that is soon to be featured in a commercial product, the evidence refers to the similarity between the data values about to be released and the private data stored on the device. Compared to TaintDroid, a state-of-the-art taint-based tool for privacy enforcement, BAYESDROID is substantially more accurate. Applied to 54 top-popular Google Play apps, BAYESDROID is able to detect 27 privacy violations with only 1 false alarm.},
author = {Tripp, Omer and Rubin, Julia},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {175--190},
title = {{A Bayesian Approach to Privacy Enforcement in Smartphones}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/tripp},
year = {2014}
}
@article{Kapravelos2014,
author = {Kapravelos, Alexandros and Grier, Chris and Chachra, Neha and Kruegel, Christopher and Vigna, Giovanni and Paxson, Vern},
isbn = {9781931971157},
journal = {usenix security},
title = {{Hulk: Eliciting Malicious Behavior in Browser Extensions}},
url = {http://www.icir.org/vern/papers/hulk-usesec14.pdf papers3://publication/uuid/46DE8A29-F371-45E1-BBF2-9DBF00C277F3},
year = {2014}
}
@article{Peng2014,
abstract = {This paper introduces X-Force, a novel binary analysis engine. Given a potentially malicious binary executable, X-Force can force the binary to execute requiring no inputs or proper environment. It also explores different ex- ecution paths inside the binary by systematically forcing the branch outcomes of a very small set of conditional control transfer instructions. X-Force features a crash-free execution model that can detect and recover from exceptions. In particular, it can fix invalid memory accesses by allocating memory on-demand and setting the offending pointers to the allocated memory. We have applied X-Force to three security applications. The first is to construct control flow graphs and call graphs for stripped binaries. The second is to expose hidden behaviors of malware, including packed and obfuscated APT malware. X-Force is able to reveal hidden malicious behaviors that had been missed by manual inspection. In the third application, X-Force substantially improves analysis coverage in dynamic type reconstruction for stripped binaries.},
author = {Peng, Fei and Deng, Zhui and Zhang, Xiangyu and Xu, Dongyan and Lin, Zhiqiang and Su, Zhendong},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {829--844},
title = {{X-Force: Force-Executing Binary Programs for Security Applications}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/peng},
year = {2014}
}
@article{Lecuyer2014,
author = {L{\'{e}}cuyer, Mathias and Ducoffe, Guillaume and Lan, Francis and Papancea, Andrei and Petsios, Theofilos and Spahn, Riley and Chaintreau, Augustin and Geambasu, Roxana},
journal = {usenix security},
title = {{XRay: Increasing the Web's Transparency with Differential Correlation}},
year = {2014}
}
@article{Backes2014,
author = {Backes, Michael and N{\"{u}}rnberger, Stefan and Planck, Max and Systems, Software},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {433--447},
title = {{Oxymoron: Making Fine-Grained Memory Randomization Practical by Allowing Code Sharing}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/backes},
year = {2014}
}
@article{Blond2014,
abstract = {We present an empirical analysis of targeted attacks against a human-rights Non-Governmental Organization (NGO) representing a minority living in China. In par- ticular, we analyze the social engineering techniques, at- tack vectors, and malware employed in malicious emails received by two members of the NGO over a four-year period. We find that both the language and topic of the emails were highly tailored to the victims, and that sender impersonation was commonly used to lure them into opening malicious attachments. We also show that the majority of attacks employed malicious documents with recent but disclosed vulnerabilities that tend to evade common defenses. Finally, we find that the NGO received malware from different families and that over a quarter of the malware can be linked to entities that have been reported to engage in targeted attacks against polit- ical and industrial organizations, and Tibetan NGOs.},
author = {Blond, Stevens Le and Uritesc, Adina and Gilbert, C{\'{e}}dric and Chua, Zheng Leong and Saxena, Prateek and Kirda, Engin},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {543--558},
title = {{A Look at Targeted Attacks Through the Lense of an NGO}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/le-blond},
year = {2014}
}
@article{Bao2014,
abstract = {Function identification is a fundamental challenge in reverse engineering and binary program analysis. For instance, binary rewriting and control flow integrity rely on accurate function detection and identification in binaries. Although many binary program analyses assume functions can be identified a priori, identifying functions in stripped binaries remains a challenge. In this paper, we propose BYTEWEIGHT, a new automatic function identification algorithm. Our approach automatically learns key features for recognizing functions and can therefore easily be adapted to different platforms, new compilers, and new optimizations. We evaluated our tool against three well-known tools that feature function identification: IDA, BAP, and Dyninst. Our data set consists of 2,200 binaries created with three different compilers, with four different optimization levels, and across two different operating systems. In our experiments with 2,200 binaries, we found that BYTEWEIGHT missed 44,621 functions in comparison with the 266,672 functions missed by the industry-leading tool IDA. Furthermore, while IDA misidentified 459,247 functions, BYTEWEIGHT misidentified only 43,992 functions.},
author = {Bao, Tiffany and Burket, Jonathan and Woo, Maverick and Turner, Rafael and Brumley, David},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {845--860},
title = {{BYTEWEIGHT: Learning to Recognize Functions in Binary Code}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/bao},
year = {2014}
}
@article{Kuhrer2014,
author = {K{\"{u}}hrer, Marc and Hupperich, Thomas and Rossow, Christian and Holz, Thorsten and Bochum, Ruhr-university and Marc, K and Horst, G},
isbn = {9781931971157},
journal = {usenix security},
title = {{Exit from Hell ? Reducing the Impact of Amplification DDoS Attacks Exit from Hell ? Reducing the Impact of Amplification DDoS Attacks}},
year = {2014}
}
@article{Kosba2014,
author = {Kosba, Ahmed E and Papadopoulos, Dimitrios and Papamanthou, Charalampos and Sayed, Mahmoud F and Shi, Elaine and Triandopoulos, Nikos},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {765--780},
title = {{TRUESET: Faster Verifiable Set Computations}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/kosba},
year = {2014}
}
@article{Shi2014,
abstract = {Malware analysis relies heavily on the use of virtual machines for functionality and safety. There are subtle differences in operation between virtual machines and physical machines. Contemporary malware checks for these differences to detect that it is being run in a vir- tual machine, and modifies its behavior to thwart being analyzed by the defenders. Existing approaches to un- cover these differences use randomized testing, or mal- ware analysis, and cannot guarantee completeness. In this paper we propose Cardinal Pill Testing—a modification of Red Pill Testing [21] that aims to enu- merate the differences between a given VM and a phys- ical machine, through carefully designed tests. Cardinal Pill Testing finds five times more pills by running fif- teen times fewer tests than Red Pill Testing. We further examine the causes of pills and find that, while the ma- jority of them stem from the failure of virtual machines to follow CPU design specifications, a significant num- ber stem from under-specification of the effects of certain instructions by the Intel manual. This leads to divergent implementations in different CPU and virtual machine architectures. Cardinal Pill Testing successfully enumer- ates differences that stem from the first cause, but only exhaustive testing or an understanding of implementa- tion semantics can enumerate those that stem from the second cause. Finally, we sketch a method to hide pills from malware by systematically correcting their outputs in the virtual machine. 1},
author = {Shi, Hao and Alwabel, Abdulla and Mirkovic, Jelena and Information, U S C},
isbn = {9781931971157},
journal = {usenix security},
title = {{Cardinal Pill Testing of System Virtual Machines Cardinal Pill Testing of System Virtual Machines}},
year = {2014}
}
@article{Kemerlis2014,
abstract = {Return-to-user (ret2usr) attacks redirect corrupted kernel pointers to data residing in user space. In response, sev-eral kernel-hardening approaches have been proposed to enforce a more strict address space separation, by pre-venting arbitrary control flow transfers and dereferences from kernel to user space. Intel and ARM also recently introduced hardware support for this purpose in the form of the SMEP, SMAP, and PXN processor features. Un-fortunately, although mechanisms like the above prevent the explicit sharing of the virtual address space among user processes and the kernel, conditions of implicit shar-ing still exist due to fundamental design choices that trade stronger isolation for performance. In this work, we demonstrate how implicit page frame sharing can be leveraged for the complete circumven-tion of software and hardware kernel isolation protec-tions. We introduce a new kernel exploitation technique, called return-to-direct-mapped memory (ret2dir), which bypasses all existing ret2usr defenses, namely SMEP, SMAP, PXN, KERNEXEC, UDEREF, and kGuard. We also discuss techniques for constructing reliable ret2dir exploits against x86, x86-64, AArch32, and AArch64 Linux targets. Finally, to defend against ret2dir attacks, we present the design and implementation of an exclu-sive page frame ownership scheme for the Linux ker-nel that prevents the implicit sharing of physical memory pages with minimal runtime overhead.},
author = {Kemerlis, Vasileios P and Polychronakis, Michalis and Keromytis, Angelos D},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {957--972},
title = {{ret2dir: Rethinking Kernel Isolation}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/kemerlis},
year = {2014}
}
@article{Durumeric2014,
author = {Durumeric, Zakir and Bailey, Michael and Halderman, J Alex},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {65--78},
title = {{An Internet-Wide View of Internet-Wide Scanning}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/durumeric},
year = {2014}
}
@article{Pinkas2014,
abstract = {Private set intersection (PSI) allows two parties to compute the intersection of their sets without revealing any information about items that are not in the intersection. It is one of the best studied applications of secure computation and many PSI protocols have been proposed. However, the variety of existing PSI protocols makes it$\backslash$rdifficult to identify the solution that performs best in a respective scenario, especially since they were not all implemented and compared in the same setting.$\backslash$rIn this work, we give an overview on existing PSI protocols that are secure against semi-honest adversaries. We take advantage of the most recent efficiency improvements in OT extension to propose significant optimizations to previous PSI protocols and to suggest a new PSI protocol whose runtime is superior to that of existing protocols. We compare the performance of the protocols both theoretically and experimentally, by implementing all protocols on the same platform, and give recommendations on which protocol to use in a particular setting.},
author = {Pinkas, Benny and Schneider, Thomas and Zohner, Michael},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {797--812},
title = {{24 Faster Private Set Intersection Based on OT Extension}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/pinkas},
year = {2014}
}
@article{Brocker2014,
abstract = {The ubiquitous webcam indicator LED is an important privacy feature which provides a visual cue that the cam-era is turned on. We describe how to disable the LED on a class of Apple internal iSight webcams used in some versions of MacBook laptops and iMac desktops. This enables video to be captured without any visual indication to the user and can be accomplished entirely in user space by an unprivileged (non-root) application. The same technique that allows us to disable the LED, namely reprogramming the firmware that runs on the iSight, enables a virtual machine escape whereby malware running inside a virtual machine reprograms the camera to act as a USB Human Interface Device (HID) keyboard which executes code in the host operating system. We build two proofs-of-concept: (1) an OS X applica-tion, iSeeYou, which demonstrates capturing video with the LED disabled; and (2) a virtual machine escape that launches Terminal.app and runs shell commands. To de-fend against these and related threats, we build an OS X kernel extension, iSightDefender, which prohibits the modification of the iSight's firmware from user space.},
author = {Brocker, Matthew and Checkoway, Stephen},
isbn = {9781931971157},
journal = {usenix security},
pages = {1--13},
title = {{iıSeeYou: Disabling the MacBook Webcam Indicator LED}},
url = {papers3://publication/uuid/69851422-1454-4E07-9BBD-D413E88BC141},
year = {2014}
}
@article{Hardy2014,
abstract = {Targeted attacks on civil society and non-governmental organizations have gone underreported despite the fact that these organizations have been shown to be frequent targets of these attacks. In this paper, we shed light on targeted malware attacks faced by these organizations by studying malicious e-mails received by 10 civil society organizations (the majority of which are from groups related to China and Tibet issues) over a period of 4 years. Our study highlights important properties of malware threats faced by these organizations with implications on how these organizations defend themselves and how we quantify these threats. We find that the technical sophistication of malware we observe is fairly low, with more effort placed on socially engineering the e-mail content. Based on this observation, we develop the Targeted Threat Index (TTI), a metric which incorporates both social engineering and technical sophistication when assessing the risk of malware threats. We demonstrate that this metric is more effective than simple technical sophistication for identifying malware threats with the highest potential to successfully compromise victims. We also discuss how education efforts focused on changing user behaviour can help prevent compromise. For two of the three Tibetan groups in our study simple steps such as avoiding the use of email attachments could cut document-based malware threats delivered through e-mail that we observed by up to 95{\{}{\%}{\}}.},
author = {Hardy, Seth and Crete-nishihata, Masashi and Kleemola, Katharine and Senft, Adam and Sonne, Byron and Wiseman, Greg and Gill, Phillipa and Deibert, Ronald J},
isbn = {9781931971157},
journal = {usenix security},
pages = {527--541},
title = {{Targeted Threat Index : Characterizing and Quantifying Politically-Motivated Targeted Malware}},
year = {2014}
}
@article{Mowery2014,
author = {Mowery, Keaton and Rescorla, Eric and Checkoway, Stephen and Halderman, J Alex and Shacham, Hovav},
journal = {usenix security},
number = {August},
title = {{Security Analysis of a Full-Body Scanner}},
year = {2014}
}
@article{Fredrikson2014a,
abstract = {Describes how inverse model attacks can use a model with a high epsilon value for epislon-differential privacy in order to find out the value of one of the predictor variables. This is much more possible for large value of epsilons (>5) than smallvalues (<1).},
author = {Fredrikson, Matthew and Lantz, Eric and Jha, Somesh and Lin, Simon},
isbn = {9781931971157},
journal = {usenix security},
title = {{Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing}},
url = {http://www.biostat.wisc.edu/{\{}{~}{\}}page/WarfarinUsenix2014.pdf},
year = {2014}
}
@article{Jansen2014,
author = {Jansen, Rob and Geddes, John and Wacek, Chris and Sherr, Micah and Syverson, Paul},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {127--142},
title = {{Never Been KIST: Tor's Congestion Management Blossoms with Kernel-Informed Socket Transport}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/jansen},
year = {2014}
}
@article{Lau2014,
author = {Lau, Billy and Chung, Simon and Song, Chengyu and Jang, Yeongjin and Lee, Wenke and Boldyreva, Alexandra and Lau, Billy and Chung, Simon and Song, Chengyu and Jang, Yeongjin and Lee, Wenke and Boldyreva, Alexandra},
isbn = {9781931971157},
journal = {usenix security},
title = {{Mimesis Aegis : A Mimicry Privacy Shield – A System’s Approach to Data Privacy on Public Cloud Mimesis Aegis : A Mimicry Privacy Shield}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-lau.pdf},
year = {2014}
}
@article{Silver2014,
abstract = {We study the security of popular password managers and their policies on automatically filling inWeb passwords. We examine browser built-in password managers, mobile password managers, and 3rd party managers. We observe significant differences in autofill policies among password managers. Several autofill policies can lead to disastrous consequences where a remote network attacker can extract multiple passwords from the user’s password manager without any interaction with the user. We experiment with these attacks and with techniques to enhance the security of password managers. We show that our enhancements can be adopted by existing managers.},
author = {Silver, David and Jana, Suman and Chen, Eric and Jackson, Collin and Boneh, Dan},
isbn = {978-1-931971-15-7},
journal = {usenix security},
keywords = {Authentication,Password Manager,Secure Filling,Sweep Attacks},
pages = {449--464},
title = {{Password Managers: Attacks and Defenses}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-silver.pdf},
year = {2014}
}
@article{Varadarajan2014,
author = {Varadarajan, Venkatanathan and Ristenpart, Thomas and Swift, Michael},
isbn = {9781931971157},
journal = {usenix security},
title = {{Scheduler-based Defenses against Cross-VM Side-channels}},
year = {2014}
}
@article{Stock2014,
author = {Stock, Ben and Erlangen-nuremberg, F A U and Lekies, Sebastian and Mueller, Tobias and Spiegel, Patrick and Johns, Martin},
journal = {usenix security},
title = {{Precise client-side protection against DOM-based Cross-Site Scripting}},
year = {2014}
}
@article{Ben-Sasson2014,
abstract = {We build a system that provides succinct non-interactive zero-knowledge proofs (zk-SNARKs) for program executions on a von Neumann RISC architecture. The system has two components: a cryptographic proof system for verifying satisfiability of arithmetic circuits, and a circuit generator to translate program executions to such circuits. Our design of both components improves in functionality and efficiency over prior work, as follows.Our circuit generator is the first to be universal: it does not need to know the program, but only a bound on its running time. Moreover, the size of the output circuit depends additively (rather than multiplicatively) on program size, allowing verification of larger programs.The cryptographic proof system improves proving and verification times, by leveraging new algorithms and a pairing library tailored to the protocol.We evaluated our system for programs with up to 10,000 instructions, running for up to 32,000 machine steps, each of which can arbitrarily access random-access memory; and also demonstrated it executing programs that use just-in-time compilation. Our proofs are 230 bytes long at 80 bits of security, or 288 bytes long at 128 bits of security. Typical verification time is 5 milliseconds, regardless of the original program's running time.},
author = {Ben-Sasson, Eli and Chiesa, Alessandro and Tromer, Eran and Virza, Madars},
isbn = {9781931971157},
journal = {usenix security},
keywords = {computationally-sound proofs,succinct arguments,zero-knowledge},
pages = {781--796},
title = {{Succinct Non-Interactive Zero Knowledge for a von Neumann Architecture}},
url = {https://eprint.iacr.org/2013/879},
year = {2014}
}
@article{Costin2014,
abstract = {As embedded systems are more than ever present in our society, their security is becoming an increasingly important issue. However, based on the results of many recent analyses of individual firmware images, embedded systems acquired a reputation of being insecure. Despite these facts, we still lack a global understanding of embedded systems’ security aswell as the tools and techniques needed to support such general claims. In this paper we present the first public, large-scale analysis of firmware images. In particular, we unpacked 32 thousand firmware images into 1.7 million individual files, which we then statically analyzed.We leverage this large-scale analysis to bring new insights on the security of embedded devices and to underline and detail several important challenges that need to be addressed in future research.We also show the main benefits of looking at many different devices at the same time and of linking our results with other large-scale datasets such as the ZMap’s HTTPS survey. In summary, without performing sophisticated static analysis,we discovered a total of 38 previously unknown vulnerabilities in over 693 firmware images. Moreover, by correlating similar files inside apparently unrelated firmware images, we were able to extend some of those vulnerabilities to over 123 different products. We also confirmed that some of these vulnerabilities altogether are affecting at least 140K devices accessible over the Internet. It would not have been possible to achieve these results without an analysis at such wide scale. We believe that this project, which we plan to provide as a firmware unpacking and analysis web service, will help shed some light on the security of embedded devices.},
author = {Costin, Andrei and Zaddach, Jonas and Francillon, Aur{\'{e}}lien and Balzarotti, Davide},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {(to appear)},
title = {{A Large-Scale Analysis of the Security of Embedded Firmwares}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/costin},
year = {2014}
}
@article{Carlini2014,
abstract = {Abstract Return Oriented Programming ( ROP ) has become the exploitation technique of choice for modern memory-safety vulnerability attacks. Recently, there have been multiple attempts at defenses to prevent ROP attacks. In this paper, we introduce three new attack ...},
author = {Carlini, Nicholas and Wagner, David},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {385--399},
title = {{ROP is Still Dangerous: Breaking Modern Defenses}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/carlini},
year = {2014}
}
@article{Dautrich2014,
author = {Dautrich, Jonathan and Stefanov, Emil and Shi, Elaine},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {749--764},
title = {{Burst ORAM: Minimizing ORAM Response Times for Bursty Access Patterns}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/dautrich},
year = {2014}
}
@article{Bonneau2014,
abstract = {Challenging the conventional wisdom that users cannot remember cryptographically-strong secrets, we test the hypothesis that users can learn randomly-assigned 56- bit codes (encoded as either 6 words or 12 characters) through spaced repetition. We asked remote research participants to perform a distractor task that required log- ging into a website 90 times, over up to two weeks, with a password of their choosing. After they entered their chosen password correctly we displayed a short code (4 letters or 2 words, 18.8 bits) that we required them to type. For subsequent logins we added an increasing de- lay prior to displaying the code, which participants could avoid by typing the code from memory. As participants learned, we added two more codes to comprise a 56.4- bit secret. Overall, 94{\{}{\%}{\}} of participants eventually typed their entire secret from memory, learning it after a me- dian of 36 logins. The learning component of our system added a median delay of just 6.9 s per login and a to- tal of less than 12 minutes over an average of ten days. 88{\{}{\%}{\}} were able to recall their codes exactly when asked at least three days later, with only 21{\{}{\%}{\}} reporting having written their secret down. As one participant wrote with surprise, “the words are branded into my brain.” While our study is preliminary in nature, we believe it debunks the myth that users are inherently incapable of remem- bering cryptographically-strong secrets for a select few high-stakes scenarios, such as a password for enterprise login or as a master key to protect other credentials (e.g., in a password manager).},
author = {Bonneau, Joseph and Schechter, Stuart},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {607--623},
title = {{Towards Reliable Storage of 56-bit Secrets in Human Memory}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/bonneau},
year = {2014}
}
@article{Michalevsky2014,
author = {Michalevsky, Yan and Boneh, Dan and Nakibly, Gabi},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {1053--1067},
title = {{Gyrophone: Recognizing Speech from Gyroscope Signals}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/michalevsky},
year = {2014}
}
@article{Wang2014a,
abstract = {gnuplot plot},
author = {Wang, Gang and Barbara, Santa and Wang, Tianyi and Zheng, Haitao and Zhao, Ben Y},
isbn = {9781931971157},
journal = {usenix security},
pages = {239--254},
title = {{Man vs . Machine : Practical Adversarial Detection of Malicious Crowdsourcing Workers}},
year = {2014}
}
@article{Cox2014,
author = {Cox, Landon P and Gilbert, Peter and Lawler, Geoffrey and Pistol, Valentin and Razeen, Ali and Wu, Bi and Cheemalapati, Sai},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {481--494},
title = {{SpanDex: Secure Password Tracking for Android}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/cox},
year = {2014}
}
@article{Yarom2014,
abstract = {Flush+Reload is a cache side-channel attack that monitors access to data in shared pages. In this paper we demonstrate how to use the attack to extract private encryption keys from GnuPG. The high resolution and low noise of the Flush+Reload attack enables a spy program to recover over 98{\{}{\%}{\}} of the bits of the private key in a single decryption or signing round. Unlike previous attacks, the attack targets the last level L3 cache. Consequently, the spy program and the victim do not need to share the execution core of the CPU. The attack is not limited to a traditional OS and can be used in a virtualised environment, where it can attack programs executing in a different VM.},
author = {Yarom, Yuval and Falkner, Katrina},
doi = {Report 2013/448, 2013},
isbn = {9781931971157},
journal = {usenix security},
pages = {1--9},
title = {{Flush + Reload : a High Resolution , Low Noise , L3 Cache Side-Channel Attack}},
url = {http://eprint.iacr.org/},
year = {2014}
}
@article{Soska2014,
author = {Soska, Kyle and Christin, Nicolas},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {625--640},
title = {{Automatically Detecting Vulnerable Websites Before They Turn Malicious}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/soska},
year = {2014}
}
@article{Egele2014,
author = {Egele, Manuel and Woo, Maverick and Brumley, David},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {303--317},
title = {{Blanket Execution: Dynamic Similarity Testing for Program Binaries and Components}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/egele},
year = {2014}
}
@article{Vogl2014,
author = {Vogl, Sebastian and Gawlik, Robert and Garmany, Behrad and Kittel, Thomas and Pfoh, Jonas and Eckert, Claudia and Holz, Thorsten},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {1--17},
title = {{Dynamic Hooks: Hiding Control Flow Changes within Non-Control Data}},
url = {papers3://publication/uuid/0D41C930-EB35-483B-B590-E9BE12169028},
year = {2014}
}
@article{Heuser2014,
abstract = {{\{}{\#}{\}}asm},
author = {Heuser, Stephan and Nadkarni, Adwait and Enck, William and Sadeghi, Ahmad-Reza},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {1005--1019},
title = {{ASM: A Programmable Interface for Extending Android Security}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/heuser},
year = {2014}
}
@article{Florencio2014,
abstract = {We explore how to manage a portfolio of passwords. We review why mandating exclusively strong passwords with no re-use gives users an impossible task as portfolio size grows. We find that approaches justified by loss-minimization alone, and those that ignore important attack vectors (e.g., vectors exploiting re-use), are amenable to analysis but unrealistic. In contrast, we propose, model and analyze portfolio management under a realistic attack suite, with an objective function costing both loss and user effort. Our findings directly challenge accepted wisdom and conventional advice. We find, for example, that a portfolio strategy ruling out weak passwords or password re-use is sub-optimal. We give an optimal solution for how to group accounts for re-use, and model-based principles for portfolio management.},
author = {Florencio, Dinei and Herley, Cormac and {Paul C}, Van Oorschot},
isbn = {9781931971157},
journal = {usenix security},
title = {{Password Portfolios and the Finite-Effort User : Sustainably Managing Large Numbers of Accounts ∗}},
year = {2014}
}
@article{Zhou2014,
author = {Zhou, Yuchen and Evans, David},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {495--510},
title = {{SSOScan: Automated Testing of Web Applications for Single Sign-On Vulnerabilities}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/zhou},
year = {2014}
}
@article{Rebert2014,
abstract = {Randomly mutating well-formed program inputs or sim- ply fuzzing, is a highly effective and widely used strategy to find bugs in software. Other than showing fuzzers find bugs, there has been little systematic effort in understand- ing the science of how to fuzz properly. In this paper, we focus on how to mathematically formulate and reason about one critical aspect in fuzzing: how best to pick seed files to maximize the total number of bugs found during a fuzz campaign. We design and evaluate six different algorithms using over 650 CPU days on Amazon Elas- tic Compute Cloud (EC2) to provide ground truth data. Overall, we find 240 bugs in 8 applications and show that the choice of algorithm can greatly increase the number of bugs found. We also show that current seed selection strategies as found in Peach may fare no better than pick- ing seeds at random. We make our data set and code publicly available. 1},
author = {Rebert, Alexandre and Cha, Sang Kil and Avgerinos, Thanassis and Foote, Jonathan and Warren, David and Engineering, Software and Grieco, Gustavo and Franco, Centro Internacional and Cient{\'{\i}}ficas, Investigaciones and Brumley, David},
isbn = {9781931971157},
journal = {usenix security},
title = {{Optimizing Seed Selection for Fuzzing}},
year = {2014}
}
@article{Li2014a,
abstract = {We conduct a security analysis of five popular web-based password managers. Unlike “local” password managers, web-based password managers run in the browser. We identify four key security concerns for web-based pass- word managers and, for each, identify representative vul- nerabilities through our case studies. Our attacks are se- vere: in four out of the five password managers we stud- ied, an attacker can learn a user’s credentials for arbi- trary websites. We find vulnerabilities in diverse features like one-time passwords, bookmarklets, and shared pass- words. The root-causes of the vulnerabilities are also di- verse: ranging from logic and authorization mistakes to misunderstandings about the web security model, in ad- dition to the typical vulnerabilities like CSRF and XSS. Our study suggests that it remains to be a challenge for the password managers to be secure. To guide future de- velopment of password managers, we provide guidance for password managers. Given the diversity of vulner- abilities we identified, we advocate a defense-in-depth approach to ensure security of password managers},
author = {Li, Zhiwei and He, Warren and Akhawe, Devdatta and Song, Dawn},
isbn = {978-1-931971-15-7},
journal = {usenix security},
title = {{The Emperor's New Password Manager: Security Analysis of Web-based Password Managers}},
url = {http://devd.me/papers/pwdmgr-usenix14.pdf$\backslash$nhttps://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/li{\{}{\_}{\}}zhiwei},
year = {2014}
}
@article{Luchaup2014,
author = {Luchaup, Daniel and Dyer, Kevin P and Jha, Somesh and Ristenpart, Thomas and Shrimpton, Thomas},
isbn = {9781931971157},
journal = {usenix security},
pages = {115},
title = {{LibFTE: a toolkit for constructing practical, format-abiding encryption schemes}},
year = {2014}
}
@article{Szurdi2014,
abstract = {Typosquatting is a speculative behavior that leverages Internet naming and governance practices to extract profit from users’ misspellings and typing errors. Simple and inexpensive domain registration motivates speculators to register domain names in bulk to profit from display advertisements, to redirect traffic to third party pages, to deploy phishing sites, or to serve malware. While previous research has focused on typosquatting domains which target popular websites, speculators also appear to be typosquatting on the “long tail” of the popularity distribution: millions of registered domain names appear to be potential typos of other site names, and only 6.8{\{}{\%}{\}} target the 10,000 most popular .com domains. Investigating the entire distribution can give a more complete understanding of the typosquatting phenomenon. In this paper, we perform a comprehensive study of ty- posquatting domain registrations within the .com TLD. Our methodology helps us to significantly improve upon existing solutions in identifying typosquatting domains and their monetization strategies, especially for less pop- ular targets. We find that about half of the possible typo domains identified by lexical analysis are truly typo do- mains. From our zone file analysis, we estimate that 20{\{}{\%}{\}} of the total number of .com domain registrations are true typo domains and their number is increasing with the ex- pansion of the .com domain space. This large number of typo registrations motivates us to review intervention at- tempts and implement efficient user-side mitigation tools to diminish the financial benefit of typosquatting to mis- creants.},
author = {Szurdi, J and Kocso, B and Cseh, G and Felegyhazi, M and Kanich, C},
isbn = {9781931971157},
journal = {usenix security},
title = {{The Long Taile of Typosquatting Domain Names}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-szurdi.pdf},
year = {2014}
}
@article{Alrwais2014,
author = {Alrwais, Sumayah and Yuan, Kan and Alowaisheq, Eihal and Li, Zhou and Wang, XiaoFeng},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {207--222},
title = {{Understanding the Dark Side of Domain Parking}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/alrwais},
year = {2014}
}
@article{Wang2014b,
author = {Wang, Tielei and Jang, Yeongjin and Chen, Yizheng and Chung, Simon and Lau, Billy and Lee, Wenke},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {79--93},
title = {{On the Feasibility of Large-Scale Infections of iOS Devices}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/wang{\{}{\_}{\}}tielei},
year = {2014}
}
@article{Dahse2014,
abstract = {Web applications evolved in the last decades from sim- ple scripts to multi-functional applications. Such com- plex web applications are prone to different types of se- curity vulnerabilities that lead to data leakage or a com- promise of the underlying web server. So called second- order vulnerabilities occur when an attack payload is first stored by the application on the web server and then later on used in a security-critical operation. In this paper, we introduce the first automated static code analysis approach to detect second-order vulnera- bilities and related multi-step exploits in web applica- tions. By analyzing reads and writes to memory loca- tions of the web server, we are able to identify unsani- tized data flows by connecting input and output points of data in persistent data stores such as databases or ses- sion data. As a result, we identified 159 second-order vulnerabilities in six popular web applications such as the conference management systems HotCRP and Open- Conf. Moreover, the analysis of web applications eval- uated in related work revealed that we are able to detect several critical vulnerabilities previously missed.},
author = {Dahse, Johannes and Holz, Thorsten},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {989--1003},
title = {{Static Detection of Second-Order Vulnerabilities in Web Applications}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/dahse},
year = {2014}
}
@article{Chen2014,
abstract = {The security of smartphone GUI frameworks remains an important yet under-scrutinized topic. In this pa- per, we report that on the Android system (and likely other OSes), a weaker form of GUI confidentiality can be breached in the form of UI state (not the pixels) by a background app without requiring any permissions. Our finding leads to a class of attackswhichwe nameUI state inference attack. The underlying problemis that popular GUI frameworks by design can potentially reveal every UI state change through a newly-discovered public side channel— shared memory. In our evaluation, we show that for 6 out of 7 popular Android apps, the UI state in- ference accuracies are 80–90{\{}{\%}{\}}for the first candidate UI states, and over 93{\{}{\%}{\}}for the top 3 candidates. Even though the UI state does not reveal the exact pix- els, we show that it can serve as a powerful building block to enable more serious attacks. To demonstrate this, we design and fully implement several new attacks based on the UI state inference attack, including hijack- ing the UI state to steal sensitive user input (e.g., login credentials) and obtain sensitive camera images shot by the user (e.g., personal check photos for banking apps). We also discuss non-trivial challenges in eliminating the identified side channel, and suggest more secure alterna- tive system designs. 1},
author = {Chen, Qi Alfred and Qian, Zhiyun and Mao, Z Morley},
doi = {978-1-931971-15-7},
isbn = {978-1-931971-15-7},
journal = {usenix security},
number = {August},
pages = {16},
title = {{Peeking into Your App without Actually Seeing It : UI State Inference and Novel Android Attacks}},
year = {2014}
}
@article{Viswanath2014,
author = {Viswanath, Bimal and Gummadi, Krishna P and Bashir, M Ahmad and Crovella, Mark and Mislove, Alan},
journal = {usenix security},
title = {{Towards Detecting Anomalous User Behavior in Online Social Networks}},
year = {2014}
}
@article{Zimmeck2014,
author = {Zimmeck, Sebastian and Bellovin, Steven M},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {1--16},
title = {{Privee: An Architecture for Automatically Analyzing Web Privacy Policies}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/zimmeck},
year = {2014}
}
@article{Gokta\cs2014,
author = {G{\"{o}}kta$\backslash$c s, Enes and Athanasopoulos, Elias and Polychronakis, Michalis and Bos, Herbert and Portokalidis, Georgios},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {417--432},
title = {{Size Does Matter: Why Using Gadget-Chain Length to Prevent Code-Reuse Attacks is Hard}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/goktas},
year = {2014}
}
@article{Wustrow2014,
author = {Wustrow, Eric and Swanson, Colleen M and Halderman, J Alex},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {159--174},
title = {{TapDance: End-to-Middle Anticensorship without Flow Blocking}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/wustrow},
year = {2014}
}
@article{Vijayakumar2014,
author = {Vijayakumar, Hayawardh and Ge, Xinyang and Payer, Mathias and Jaeger, Trent},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {973--988},
title = {{JIGSAW: Protecting Resource Access by Inferring Programmer Expectations}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/vijaykumar},
year = {2014}
}
@article{Bhoraskar2014,
abstract = {gui-exploreation to reach specific library components},
author = {Bhoraskar, Ravi and Han, Seungyeop and Jeon, Jinseong and Azim, Tanzirul and Chen, Shuo and Jung, Jaeyeon and Nath, Suman and Wang, Rui and Wetherall, David},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {1021--1036},
title = {{Brahmastra: Driving Apps to Test the Security of Third-Party Components}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/bhoraskar},
year = {2014}
}
@article{Komanduri2014,
abstract = {To discourage the creation of predictable passwords, vul- nerable to guessing attacks, we present Telepathwords. As a user creates a password, Telepathwords makes real- time predictions for the next character that user will type. While the concept is simple, making accurate predictions requires efficient algorithms to model users’ behavior and to employ already-typed characters to predict subse- quent ones. We first made the Telepathwords technology available to the public in late 2013 and have since served hundreds of thousands of user sessions. We ran a human-subjects experiment to compare pass- word policies that use Telepathwords to those that rely on composition rules, comparing participants’ passwords using two different password-evaluation algorithms. We found that participants create far fewer weak passwords using the Telepathwords-based policies than policies based only on character composition. Participants using Telepathwords were also more likely to report that the password feedback was helpful.},
author = {Komanduri, Saranga and Shay, Richard and Cranor, Lorrie Faith and Herley, Cormac and Schechter, Stuart},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {591--606},
title = {{Telepathwords: Preventing Weak Passwords by Reading Users Minds}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/komanduri},
year = {2014}
}
@article{Tice2014,
abstract = {Constraining dynamic control transfers is a common tech- nique for mitigating software vulnerabilities. This de- fense has been widely and successfully used to protect return addresses and stack data; hence, current attacks instead typically corrupt vtable and function pointers to subvert a forward edge (an indirect jump or call) in the control-flow graph. Forward edges can be protected us- ing Control-Flow Integrity (CFI) but, to date, CFI im- plementations have been research prototypes, based on impractical assumptions or ad hoc, heuristic techniques. To be widely adoptable, CFI mechanisms must be inte- grated into production compilers and be compatible with software-engineering aspects such as incremental compi- lation and dynamic libraries. This paper presents implementations of fine-grained, forward-edge CFI enforcement and analysis for GCC and LLVM that meet the above requirements. An analysis and evaluation of the security, performance, and resource consumption of these mechanisms applied to the SPEC CPU2006 benchmarks and common benchmarks for the Chromium web browser show the practicality of our ap- proach: these fine-grained CFI mechanisms have signif- icantly lower overhead than recent academic CFI proto- types. Implementing CFI in industrial compiler frame- works has also led to insights into design tradeoffs and practical challenges, such as dynamic loading.},
author = {Tice, Caroline and Roeder, Tom and Collingbourne, Peter and Checkoway, Stephen and Erlingsson, {\'{U}}lfar and Lozano, Luis and Pike, Geoff},
isbn = {9781931971157},
journal = {usenix security},
pages = {941--955},
title = {{Enforcing Forward-Edge Control-Flow Integrity in GCC {\{}{\&}{\}} LLVM}},
year = {2014}
}
@article{Saltaformaggio2014,
abstract = {State-of-the-art memory forensics involves signature-based scanning of memory images to uncover data structure instances of interest to investigators. A largely unaddressed challenge is that investigators may not be able to interpret the content of data structure fields, even with a deep understanding of the data structure’s syntax and semantics. This is very common for data structures with application-specific encoding, such as those representing images, figures, passwords, and formatted file contents. For example, an investigator may know that a buffer field is holding a photo image, but still cannot display (and hence understand) the image. We call this the data structure content reverse engineering challenge. In this paper, we present DSCRETE, a system that enables automatic interpretation and rendering of in-memory data structure contents. DSCRETE is based on the observation that the application in which a data structure is defined usually contains interpretation and rendering logic to generate human-understandable output for that data structure. Hence DSCRETE aims to identify and reuse such logic in the program’s binary and create a “scanner+renderer” tool for scanning and rendering instances of the data structure in a memory image. Different from signature-based approaches, DSCRETE avoids reverse engineering data structure signatures. Our evaluation with a wide range of real-world application binaries shows that DSCRETE is able to recover a variety of application data—e.g., images, figures, screenshots, user accounts, and formatted files and messages—with high accuracy. The raw contents of such data would otherwise be unfathomable to human investigators.},
author = {Saltaformaggio, Brendan and Gu, Zhongshu and Zhang, Xiangyu and Xu, Dongyan},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {255--269},
title = {{DSCRETE: Automatic Rendering of Forensic Information from Memory Images via Application Logic Reuse}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/saltaformaggio},
year = {2014}
}
@article{Pattuk2014,
abstract = {In a typical infrastructure-as-a-service cloud setting, different clients harness the cloud provider's services by executing virtual machines (VM). However, recent studies have shown that the cryptographic keys, the most crucial component in many of our daily used cryptographic protocols (e.g., SSL/TLS), can be extracted using cross-VM side-channel attacks. To defeat such a threat, this paper introduces HERMES, a new system that aims to protect the cryptographic keys in the cloud against any kind of cross-VM side-channel attacks by simply partitioning the cryptographic keys into random shares, and storing each share in a different VM. Moreover, it also periodically re-shares the cryptographic keys, thereby invalidating the potentially extracted partial ones. We have implemented HERMES as a library extension that is transparent to the application software, and performed deep case studies with a web and a mail server on Amazon EC2 cloud. Our experimental results show that the runtime overhead of the proposed system can be as low as 1{\{}{\%}{\}}.},
author = {Pattuk, Erman and Kantarcioglu, Murat and Lin, Zhiqiang and Ulusoy, Huseyin},
isbn = {978-1-931971-15-7},
journal = {usenix security},
pages = {703--718},
title = {{Preventing Cryptographic Key Leakage in Cloud Virtual Machines}},
url = {https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/pattuk},
year = {2014}
}
@article{Athanasopoulos2013,
author = {Athanasopoulos, Elias},
journal = {usenix security},
number = {2013},
pages = {1--5},
title = {{Control Flow Integrity for COTS Binaries - draft2}},
year = {2013}
}
@article{Zhu2013,
archivePrefix = {arXiv},
arxivId = {1303.0597},
author = {Zhu, Tao and Phipps, David and Pridgen, Adam and Crandall, Jedidiah R and Wallach, Dan S},
eprint = {1303.0597},
isbn = {978-1-931971-03-4},
journal = {usenix security},
number = {August},
title = {{The velocity of censorship: High-fidelity detection of microblog post deletions}},
url = {http://arxiv.org/abs/1303.0597 http://arxiv.org/pdf/1303.0597},
year = {2013}
}
@article{Livshits2013,
abstract = {Mobile app development best practices suggest that developers obtain opt-in consent from users prior to accessing potentially sensitive information on the phone. We study challenges that mobile application developers have with meeting such requirements, and highlight the promise of using new automated, static analysis-based solutions that identify and insert missing prompts in order to guard otherwise unprotected resource accesses. We find evidence that third-party libraries, incorporated by developers across the mobile industry, may access privacy-sensitive resources without seeking consent or even against the user’s choice. Based on insights from real examples, we develop the theoretical underpinning of the problem of mediating resource accesses in mobile applications. We design and implement a graph-theoretic algorithm to place mediation prompts that protect every resource access, while avoiding repetitive prompting and prompting in background tasks or third-party libraries. We demonstrate the viability of our approach by analyzing 100 apps, averaging 7.3 MB in size and consisting of dozens of DLLs. Our approach scales well: once an app is represented in the form of a graph, the remaining static analysis takes under a second on average. Overall, our strategy succeeds in about 95{\{}{\%}{\}} of all unique cases.},
author = {Livshits, Benjamin and Jung, Jaeyeon},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {113--130},
title = {{Automatic Mediation of Privacy-Sensitive Resource Access in Smartphone Applications}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/presentation/livshits},
year = {2013}
}
@article{Fournet2013,
author = {Fournet, C{\'{e}}dric and Kohlweiss, Markuld and Danezis, George and Danezis, George},
isbn = {9781931971034},
journal = {usenix security},
title = {{ZQL : A Compiler for Privacy-Preserving Data Processing ZQL : A Compiler for Privacy-Preserving Data Processing}},
year = {2013}
}
@article{Noorman2013,
abstract = {In this paper we propose Sancus, a security architecture for networked embedded devices. Sancus supports extensibility in the form of remote (even third-party) software installation on devices while maintaining strong security guarantees. More specifically, Sancus can remotely attest to a software provider that a specific software module is running uncompromised, and can authenticate messages from software modules to software providers. Software modules can securely maintain local state, and can securely interact with other software modules that they choose to trust. The most distinguishing feature of Sancus is that it achieves these security guarantees without trusting any infrastructural software on the device. The Trusted Computing Base (TCB) on the device is only the hardware. Moreover, the hardware cost of Sancus is low. We describe the design of Sancus, and develop and evaluate a prototype FPGA implementation of a Sancus-enabled device. The prototype extends an MSP430 processor with hardware support for the memory access control and cryptographic functionality required to run Sancus. We also develop a C compiler that targets our device and that can compile standard C modules to Sancus protected software modules.},
author = {Noorman, Job and Preneel, Bart and Leuven, K U and Agten, Pieter and Daniels, Wilfried and Strackx, Raoul and Huygens, Christophe and Piessens, Frank and Vanherrewege, Anthony and Verbauwhede, Ingrid},
isbn = {978-1-931971-03-4},
journal = {usenix security},
title = {{Sancus : Low-cost trustworthy extensible networked devices with a zero-software Trusted Computing Base}},
year = {2013}
}
@article{AlFardan2013,
abstract = {The Transport Layer Security (TLS) protocol aims to provide con⬚dentiality and in-$\backslash$ntegrity of data in transit across untrusted networks. TLS has become the de facto protocol$\backslash$nstandard for secured Internet and mobile applications. TLS supports several symmetric$\backslash$nencryption options, including a scheme based on the RC4 stream cipher. In this paper,$\backslash$nwe present ciphertext-only plaintext recovery attacks against TLS when RC4 is selected for$\backslash$nencryption. Variants of these attacks also apply to WPA, a prominent IEEE standard for$\backslash$nwireless network encryption. Our attacks build on recent advances in the statistical analysis$\backslash$nof RC4, and on new ⬚ndings announced in this paper. Our results are supported by an$\backslash$nexperimental evaluation of the feasibility of the attacks. We also discuss countermeasures.},
author = {AlFardan, Nj and Bernstein, Dj},
isbn = {9781931971034},
journal = {usenix security},
pages = {1--31},
title = {{On the security of RC4 in TLS and WPA}},
url = {http://scholar.google.com/scholar?hl=en{\{}{\&}{\}}btnG=Search{\{}{\&}{\}}q=intitle:On+the+Security+of+RC4+in+TLS+and+WPA+?{\{}{\#}{\}}0},
year = {2013}
}
@article{Paxson2013,
author = {Paxson, Vern and Christodorescu, Mihai and Javed, Mobin},
isbn = {9781931971034},
journal = {usenix security},
pages = {16--32},
title = {{Practical Comprehensive Bounds on Surreptitious Communication Over DNS}},
url = {http://www.cs.berkeley.edu/{\{}{~}{\}}mobin/publications/2013/DNS{\{}{\_}{\}}USENIX13.pdf},
year = {2013}
}
@article{Johns2013,
abstract = {The Web’s principal security policy is the Same-Origin Policy (SOP), which enforces origin-based isolation of mutually distrusting Web applications. Since the early days, the SOP was repeatedly undermined with variants of the DNS Rebinding attack, allowing untrusted script code to gain illegitimate access to protected network re- sources. To counter these attacks, the browser vendors introduced countermeasures, such as DNS Pinning, to mitigate the attack. In this paper, we present a novelDNS Rebinding attack method leveraging the HTML5 Appli- cation Cache. Our attack allows reliable DNS Rebinding attacks, circumventing all currently deployed browser- based defense measures. Furthermore, we analyze the fundamental problem which allows DNS Rebinding to work in the first place: The SOP’s main purpose is to en- sure security boundaries of Web servers. However, the Web servers themselves are only indirectly involved in the corresponding security decision. Instead, the SOP relies on information obtained from the domain name system, which is not necessarily controlled by the Web server’s owners. This mismatch is exploited by DNS Re- binding. Based on this insight, we propose a light-weight extension to the SOP which takes Web server provided information into account. We successfully implemented our extended SOP for the Chromium Web browser and report on our implementation’s interoperability and se- curity properties},
author = {Johns, Martin and Lekies, Sebastian and Stock, Ben},
isbn = {9781931971034},
journal = {usenix security},
title = {{Eradicating DNS Rebinding with the Extended Same-Origin Policy}},
year = {2013}
}
@article{Wang2013,
abstract = {Apple adopts the mandatory app review and code sign- ing mechanisms to ensure that only approved apps can run on iOS devices. In this paper, we present a novel attack method that fundamentally defeats both mecha- nisms. Our method allows attackers to reliably hide ma- licious behavior that would otherwise get their app re- jected by the Apple review process. Once the app passes the review and is installed on an end user’s device, it can be instructed to carry out the intended attacks. The key idea is to make the apps remotely exploitable and subsequently introduce malicious control flows by rearranging signed code. Since the new control flows do not exist during the app review process, such apps, namely Jekyll apps, can stay undetected when reviewed and easily obtain Apple’s approval. We implemented a proof-of-concept Jekyll app and successfully published it in App Store. We remotely launched the attacks on a controlled group of devices that installed the app. The result shows that, despite run- ning inside the iOS sandbox, Jekyll app can successfully perform many malicious tasks, such as stealthily posting tweets, taking photos, stealing device identity informa- tion, sending email and SMS, attacking other apps, and even exploiting kernel vulnerabilities.},
author = {Wang, Tielei and Lu, Kangjie and Lu, Long and Chung, Simon and Lee, Wenke},
isbn = {9781931971034},
journal = {usenix security},
keywords = {application reputation,mobile applications},
pages = {559--572},
title = {{Jekyll on iOS: When Benign Apps Become Evil}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity13/sec13-paper{\{}{\_}{\}}wang{\{}{\_}{\}}2.pdf},
year = {2013}
}
@article{Pappas2013,
author = {Pappas, Vasilis and Polychronakis, Michalis and Keromytis, Angelos D},
isbn = {9781931971034},
journal = {usenix security},
title = {{Transparent ROP Exploit Mitigation Using Indirect Branch Tracing Transparent ROP Exploit Mitigation using Indirect Branch Tracing}},
year = {2013}
}
@article{Kreuter2013,
author = {Kreuter, B and Mood, B and Shelat, A and Butler, K},
isbn = {9781931971034},
journal = {usenix security},
pages = {321--336},
title = {{PCF: A Portable Circuit Format for Scalable Two-Party Secure Computation}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity13/sec13-paper{\{}{\_}{\}}kreuter.pdf},
year = {2013}
}
@article{Zeng2013,
abstract = {Low-level Inlined Reference Monitors (IRM) such as control-flow integrity and software-based fault isolation can foil numerous software attacks. Conventionally, those IRMs are implemented through binary rewriting or transformation on equivalent low-level programs that are tightly coupled with a specific Instruction Set Ar- chitecture (ISA). Resulting implementations have poor retargetability to different ISAs. This paper intro- duces an IRM-implementation framework at a com- piler intermediate-representation (IR) level. The IR-level framework enables easy retargetability to different ISAs, but raises the challenge of how to preserve security at the low level, as the compiler backend might invalidate the assumptions at the IR level. We propose a constraint language to encode the assumptions and check whether they still hold after the backend transformations and op- timizations. Furthermore, an independent verifier is im- plemented to validate the security of low-level code. We have implemented the framework inside LLVM to en- force the policy of control-flow integrity and data sand- boxing for both reads and writes. Experimental results demonstrate that it incurs modest runtime overhead of 19.90{\{}{\%}{\}} and 25.34{\{}{\%}{\}} on SPECint2000 programs for x86- 32 and x86-64, respectively.},
author = {Zeng, Bin and Tan, Gang and Erlingsson, {\'{U}}lfar},
isbn = {9781931971034},
journal = {usenix security},
title = {{Strato : A Retargetable Framework for Low-Level Inlined-Reference Monitors}},
year = {2013}
}
@article{Haller2013,
abstract = {Dowser is a `guided' fuzzer that combines taint tracking, program analysis and symbolic execution to find buffer overflow and underflow vulnerabilities buried deep in a program's logic. The key idea is that analysis of a program lets us pinpoint the right areas in the program code to probe and the appropriate inputs to do so. Intuitively, for typical buffer overflows, we need consider only the code that accesses an array in a loop, rather than all possible instructions in the program. After finding all such candidate sets of instructions, we rank them according to an estimation of how likely they are to contain interesting vulnerabilities. We then subject the most promising sets to further testing. Specifically, we first use taint analysis to determine which input bytes influence the array index and then execute the program symbolically, making only this set of inputs symbolic. By constantly steering the symbolic execution along branch outcomes most likely to lead to overflows, we were able to detect deep bugs in real programs (like the nginx webserver, the inspircd IRC server, and the ffmpeg videoplayer). Two of the bugs we found were previously undocumented buffer overflows in ffmpeg and the poppler PDF rendering library.},
author = {Haller, Istvan and Slowinska, Asia and Bos, Herbert and Neugschwandtner, Matthias Mattias},
isbn = {9781931971034},
journal = {usenix security},
pages = {49--64},
title = {{Dowsing for Overflows: A Guided Fuzzer to Find Buffer Boundary Violation}},
year = {2013}
}
@article{Pandita2013,
abstract = {{\{}{\#}{\}}WhyPer. They use NLP to understand what the users expectations are, regarding three permissions (address book, calendar, record audio). They first build a NLP graph given the API documentation (they get what are the "resources" and "actions" on such), and they use this to classify sentences in the app's description. As eval, they compare with manual annotation.},
author = {Pandita, Rahul and Xiao, Xusheng and Yang, Wei and Enck, William and Xie, Tao},
isbn = {9781931971034},
journal = {usenix security},
title = {{Whyper: Towards Automating Risk Assessment of Mobile Applications}},
year = {2013}
}
@article{Jang2013,
abstract = {Software lineage refers to the evolutionary relationship among a collection of software. The goal of software lineage inference is to recover the lineage given a set of program binaries. Software lineage can provide extremely useful information in many security scenarios such as malware triage and software vulnerability tracking. In this paper, we systematically study software lineage inference by exploring four fundamental questions not addressed by prior work. First, how do we automatically infer software lineage from program binaries? Second, how do we measure the quality of lineage inference al- gorithms? Third, how useful are existing approaches to binary similarity analysis for inferring lineage in reality, and how about in an idealized setting? Fourth, what are the limitations that any software lineage inference algo- rithm must cope with? Towards these goals we build I L INE , a system for auto- matic software lineage inference of program binaries, and also I E VAL , a system for scientific assessment of lineage quality. We evaluated I L INE on two types of lineage— straight line and directed acyclic graph—with large-scale real-world programs: 1,777 goodware spanning over a combined 110 years of development history and 114 mal- ware with known lineage collected by the DARPA Cyber Genome program. We used I E VAL to study seven metrics to assess the diverse properties of lineage. Our results reveal that partial order mismatches and graph arc edit distance often yield the most meaningful comparisons in our experiments. Even without assuming any prior infor- mation about the data sets, I L INE proved to be effective in lineage inference—it achieves a mean accuracy of over 84{\{}{\%}{\}} for goodware and over 72{\{}{\%}{\}} for malware in our data sets.},
author = {Jang, Jiyong and Woo, Maverick and Brumley, David},
isbn = {9781931971034},
journal = {usenix security},
title = {{Towards Automatic Software Lineage Inference.}},
url = {http://users.ece.cmu.edu/{\{}{~}{\}}jiyongj/papers/usenixsec13.pdf},
year = {2013}
}
@article{Roesner2013,
abstract = {Web and smartphone applications commonly embed third-party user interfaces like advertisements and social media widgets. However, this capability comes with security implications, both for the embedded interfaces and the host page or application. While browsers have evolved over time to address many of these issues, mobile systems like Android--which do not yet support true cross-application interface embedding--present an opportunity to redesign support for secure embedded user interfaces from scratch. In this paper, we explore the requirements for a system to support secure embedded user interfaces by systematically analyzing existing systems like browsers, smartphones, and research systems. We describe our experience modifying Android to support secure interface embedding and evaluate our implementation using case studies that rely on embedded interfaces, such as advertisement libraries, Facebook social plugins (e.g., the "Like" button), and access control gadgets. We provide concrete techniques and reflect on lessons learned for secure embedded user interfaces.},
author = {Roesner, Franziska and Kohno, Tadayoshi},
isbn = {9781931971034},
journal = {usenix security},
pages = {97--112},
title = {{Securing embedded user interfaces: Android and beyond}},
url = {http://dl.acm.org/citation.cfm?id=2534766.2534776},
year = {2013}
}
@article{Finifter2013,
abstract = {We perform an empirical study to better understand two well-known vulnerability rewards programs, or VRPs, which software vendors use to encourage community participation in finding and responsibly disclosing software vulnerabilities. The Chrome VRP has cost approximately {\{}{\$}{\}}580,000 over 3 years and has resulted in 501 bounties paid for the identification of security vulnerabilities. The Firefox VRP has cost approximately {\{}{\$}{\}}570,000 over the last 3 years and has yielded 190 bounties. 28{\{}{\%}{\}} of Chrome's patched vulnerabilities appearing in security advisories over this period, and 24{\{}{\%}{\}} of Firefox's, are the result of VRP contributions. Both programs appear economically efficient, comparing favorably to the cost of hiring full-time security researchers. The Chrome VRP features low expected payouts accompanied by high potential payouts, while the Firefox VRP features fixed payouts. Finding vulnerabilities for VRPs typically does not yield a salary comparable to a full-time job; the common case for recipients of rewards in either program is that they have received only one reward. Firefox has far more critical-severity vulnerabilities than Chrome, which we believe is attributable to an architectural difference between the two browsers.},
author = {Finifter, Matthew and Akhawe, Devdatta and Wagner, David},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {273--289},
title = {{An empirical study of vulnerability rewards programs}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity13/sec13-paper{\{}{\_}{\}}finifter.pdf},
year = {2013}
}
@article{Wang2013a,
abstract = {A script-based attack framework is a new type of cyber- attack tool written in scripting languages. It carries var- ious attack scripts targeting vulnerabilities across differ- ent systems. It also supports fast development of new at- tack scripts that can even exploit zero-day vulnerabilities. Such mechanisms pose a big challenge to the defense side since traditional malware analysis cannot catch up with the emerging speed of new attack scripts. In this paper, we propose MetaSymploit, the first system of fast attack script analysis and automatic signature generation for a network Intrusion Detection System (IDS). As soon as a new attack script is developed and distributed,Meta- Symploit uses security-enhanced symbolic execution to quickly analyze the script and automatically generate specific IDS signatures to defend against all possible at- tacks launched by this new script from Day One. We im- plement a prototype of MetaSymploit targeting Metas- ploit, the most popular penetration framework. In the experiments on 45 real attack scripts, MetaSymploit au- tomatically generates Snort IDS rules as signatures that effectively detect the attacks launched by the 45 scripts. Furthermore, the results show that MetaSymploit sub- stantially complements and improves existing Snort rules that are manually written by the official Snort team.},
author = {Wang, Ruowen and Ning, Peng and Xie, Tao and Chen, Quan},
isbn = {9781931971034},
journal = {usenix security},
title = {{MetaSymploit: Day-One Defense against Script-based Attacks with Security-Enhanced Symbolic Analysis.}},
url = {https://www.usenix.org/sites/default/files/conference/protected-files/ruowen{\{}{\_}{\}}sec13{\{}{\_}{\}}slides.pdf},
year = {2013}
}
@article{Doychev2013,
abstract = {We present CacheAudit, a versatile framework for the automatic, static analysis of cache side channels. CacheAudit takes as input a program binary and a cache configuration, and it derives formal, quantitative security guarantees for a comprehensive set of side-channel adversaries, namely those based on observing cache states, traces of hits and misses, and execution times.$\backslash$n$\backslash$nOur technical contributions include novel abstractions to efficiently compute precise over-approximations of the possible side-channel observations for each of these adversaries. These approximations then yield upper bounds on the information that is revealed. In case studies we apply CacheAudit to binary executables of algorithms for symmetric encryption and sorting, obtaining the first formal proofs of security for implementations with countermeasures such as preloading and data-independent memory access patterns.},
author = {Doychev, Goran and Feld, Dominik and K{\"{o}}pf, Boris and Mauborgne, Laurent and Reineke, Jan},
doi = {10.1145/2756550},
isbn = {978-1-931971-03-4},
issn = {1094-9224},
journal = {usenix security},
pages = {431--446},
title = {{CacheAudit: A Tool for the Static Analysis of Cache Side Channels}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/paper/doychev},
year = {2013}
}
@article{Zhao2013,
abstract = {Computing devices with touch-screens have experienced unprecedented growth in recent years. Such an evolutionary advance has been facilitated by various applications that are heavily relying on multi-touch gestures. In addition, picture gesture authentication has been recently introduced as an alternative login experience to text-based password on such devices. In particular, the new Microsoft Windows 8TM operating system adopts such an alternative authentication to complement traditional text-based authentication. In this paper, we present an empirical analysis of picture gesture authentication on more than 10,000 picture passwords collected from over 800 subjects through online user studies. Based on the ﬁndings of our user studies, we also propose a novel attack framework that is capable of cracking passwords on previously unseen pictures in a picture gesture authentication system. Our approach is based on the concept of selection function that models users’ password selection processes. Our evaluation results show the proposed approach could crack a considerable portion of collected picture passwords under different settings.},
author = {Zhao, Ziming and Ahn, Gail-joon and Technology, G F S},
isbn = {9781931971034},
journal = {usenix security},
pages = {383--398},
title = {{On the Security of Picture Gesture Authentication On the Security of Picture Gesture Authentication}},
year = {2013}
}
@article{Corrigan-Gibbs2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1209.4819v2},
author = {Corrigan-Gibbs, Henry and Wolinsky, David Isaac and Ford, Bryan},
eprint = {arXiv:1209.4819v2},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {147--162},
title = {{Proactively Accountable Anonymous Messaging in Verdict}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/presentation/corrigan-gibbs},
year = {2013}
}
@article{Durumeric2013,
abstract = {Internet-wide network scanning has numerous security applications, including exposing new vulnerabilities and tracking the adoption of defensive mechanisms, but prob- ing the entire public address space with existing tools is both difficult and slow. We introduce ZMap, a modular, open-source network scanner specifically architected to perform Internet-wide scans and capable of surveying the entire IPv4 address space in under 45 minutes from user space on a single machine, approaching the theo- retical maximum speed of gigabit Ethernet. We present the scanner architecture, experimentally characterize its performance and accuracy, and explore the security impli- cations of high speed Internet-scale network surveys, both offensive and defensive. We also discuss best practices for good Internet citizenship when performing Internet-wide surveys, informed by our own experiences conducting a long-term research survey over the past year. 1},
author = {Durumeric, Zakir and Wustrow, Eric and Halderman, J Alex},
isbn = {9781931971034},
journal = {usenix security},
number = {August},
pages = {605--619},
title = {{ZMap: Fast Internet-wide Scanning and Its Security Applications}},
url = {https://zmap.io/paper.pdf},
year = {2013}
}
@article{Lee2013,
abstract = {Kernel rootkits undermine the integrity of system by manipulating its operating system kernel. External hardware-based monitors can serve as a root of trust that is resilient to rootkit attacks. The existing external hardware-based approaches lack an event-triggered verification scheme for mutable kernel objects. To address the issue, we present KI-Mon, a hardware-based platform for event-triggered kernel integrity monitor. A refined form of bus traffic monitoring efficiently verifies the update values of the objects, and callback verification routines can be programmed and executed for a designated event space. We have built a KI-Mon prototype to demonstrate the efficacy of KI-Mon’s event-triggered mechanism in terms of performance overhead for the monitored host system and the processor usage of the KI-Mon processor.},
author = {Lee, Hojoon and Advanced, Korea and Kaist, Technology and Moon, Hyungon and Jang, Daehee and Kim, Kihwan and Lee, Jihoon and Paek, Yunheung and Kang, Brent Byunghoon},
isbn = {9781931971034},
journal = {usenix security},
pages = {511--526},
title = {{KI-Mon : a hardware-assisted event-triggered monitoring platform for mutable kernel object}},
year = {2013}
}
@article{Bugiel2013,
abstract = {{\{}{\#}{\}}FlaskDroid.},
author = {Bugiel, Sven and Heuser, Stephan and Sadeghi, Ahmad-Reza},
isbn = {9781931971034},
journal = {usenix security},
pages = {131--146},
title = {{Flexible and fine-grained mandatory access control on Android for diverse security and privacy policies}},
url = {http://dl.acm.org/citation.cfm?id=2534766.2534778},
year = {2013}
}
@article{Thomas2013,
abstract = {As web services such as Twitter, Facebook, Google, and Yahoo nowdominate the daily activities of Internet users, cyber criminals have adapted their monetization strategies to engage users within these walled gardens. To facilitate access to these sites, an underground market has emerged where fraudulent accounts – automatically gen-erated credentials used to perpetrate scams, phishing, and malware – are sold in bulk by the thousands. In order to understand this shadowy economy, we investigate the market for fraudulent Twitter accounts to monitor prices, availability, and fraud perpetrated by 27 merchants over the course of a 10-month period. We use our insights to develop a classifier to retroactively detect several million fraudulent accounts sold via this marketplace, 95{\{}{\%}{\}} of which we disable with Twitter’s help. During active months, the 27 merchants we monitor appeared respon- sible for registering 10–20{\{}{\%}{\}} of all accounts later flagged for spam by Twitter, generating {\{}{\$}{\}}127–459K for their efforts.},
author = {Thomas, Kurt and Paxson, Vern and Mccoy, Damon and Grier, Chris},
isbn = {9781931971034},
journal = {usenix security},
pages = {195--210},
title = {{Trafficking Fraudulent Accounts : The Role of the Underground Market in Twitter Spam and Abuse Trafficking Fraudulent Accounts :}},
year = {2013}
}
@article{Imeson2013,
author = {Imeson, Frank and Emtenan, Ariq and Garg, Siddharth and Tripunitara, Mahesh},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {495--510},
title = {{Securing Computer Hardware Using 3D Integrated Circuit (IC) Technology and Split Manufacturing for Obfuscation}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/presentation/imeson},
year = {2013}
}
@article{Bellare2013,
author = {Bellare, Mihir and Keelveedhi, Sriram and Ristenpart, Thomas},
isbn = {9781931971034},
journal = {usenix security},
pages = {179--194},
title = {{DupLESS: Server-Aided Encryption for Deduplicated Storage}},
year = {2013}
}
@article{Lian2013,
author = {Lian, Wilson and Rescorla, Eric and Shacham, Hovav and Savage, Stefan},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {573--588},
title = {{Measuring the Practical Impact of DNSSEC Deployment}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/paper/lian},
year = {2013}
}
@article{,
journal = {usenix security},
title = {{Control-Flow Structuring }},
year = {2013}
}
@article{Wang2013b,
author = {Wang, Gang and Konolige, Tristan and Barbara, Santa and Wilson, Christo and Wang, Xiao and Zheng, Haitao and Zhao, Ben Y and Barbara, Santa and Wang, Gang and Konolige, Tristan and Wilson, Christo and Wang, Xiao},
isbn = {9781931971034},
journal = {usenix security},
title = {{You Are How You Click : Clickstream Analysis for Sybil Detection}},
year = {2013}
}
@article{Carter2013,
author = {Carter, Henry and Mood, Benjamin and Traynor, Patrick and Butler, Kevin},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {289--304},
title = {{Secure Outsourced Garbled Circuit Evaluation for Mobile Devices}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/paper/carter},
year = {2013}
}
@article{Xing2013,
abstract = {Modern Web services routinely personalize content to appeal to the specific interests, viewpoints, and contexts of individual users. Ideally, personalization allows sites to highlight information uniquely relevant to each of their users, thereby increasing user satisfaction—and, eventually, the service’s bottom line. Unfortunately, as we demonstrate in this paper, the personalization mechanisms currently employed by popular services have not been hardened against attack. We show that third parties can manipulate them to increase the visibility of arbitrary content—whether it be a new YouTube video, an unpopular product on Amazon, or a low-ranking website in Google search returns. In particular, we demonstrate that attackers can inject information into users’ profiles on these services, thereby perturbing the results of the services’ personalization algorithms. While the details of our exploits are tailored to each service, the general approach is likely to apply quite broadly. By demonstrating the attack against three popular Web services, we highlight a new class of vulnerability that allows an attacker to affect a user’s experience with a service, unbeknownst to the user or the service provider.},
author = {Xing, Xingyu and Meng, Wei and Doozan, Dan and Snoeren, Alex C and Feamster, Nick and Lee, Wenke},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {671--686},
title = {{Take This Personally: Pollution Attacks on Personalized Services}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/paper/xing},
year = {2013}
}
@article{Springborn2013,
author = {Springborn, Kevin and Barford, Paul},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {211--226},
title = {{Impression Fraud in On-line Advertising via Pay-Per-View Networks}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity13/sec13-paper{\{}{\_}{\}}springborn.pdf},
year = {2013}
}
@article{Kapravelos2013,
abstract = {In recent years, attacks targeting web browsers and their plugins have become a prevalent threat. Attackers deploy web pages that contain exploit code, typically written in HTML and JavaScript, and use them to compromise unsuspecting victims. Initially, static techniques, such as signature-based detection, were adequate to identify such attacks. The response from the attackers was to heavily obfuscate the attack code, rendering static techniques insufficient. This led to dynamic analysis systems that execute the JavaScript code included in web pages in order to expose malicious behavior. However, today we are facing a new reaction from the attackers: evasions. The latest attacks found in the wild incorporate code that detects the presence of dynamic analysis systems and try to avoid analysis and/or detection. In this paper, we present Revolver, a novel approach to automatically detect evasive behavior in malicious JavaScript. Revolver uses efficient techniques to identify similarities between a large number of JavaScript programs (despite their use of obfuscation techniques, such as packing, polymorphism, and dynamic code generation), and to automatically interpret their differences to detect evasions. More precisely, Revolver leverages the observation that two scripts that are similar should be classified in the same way by web malware detectors (either both scripts are malicious or both scripts are benign); differences in the classification may indicate that one of the two scripts contains code designed to evade a detector tool. Using large-scale experiments, we show that Revolver is effective at automatically detecting evasion attempts in JavaScript, and its integration with existing web malware analysis systems can support the continuous improvement of detection techniques.},
author = {Kapravelos, Alexandros and Shoshitaishvili, Yan and Barbara, Santa and Cova, Marco and Kruegel, Christopher and Vigna, Giovanni},
isbn = {9781931971034},
journal = {usenix security},
title = {{Revolver : An Automated Approach to the Detection of Evasive Web-based Malware}},
year = {2013}
}
@article{Davidson2013,
abstract = {Embedded systems increasingly use software-driven low-power microprocessors for security-critical settings, surfacing a need for tools that can audit the security of the software (often called firmware) running on such de-vices. Despite the fact that firmware programs are of-ten written in C, existing source-code analysis tools do not work well for this setting because of the specific ar-chitectural features of low-power platforms. We there-fore design and implement a new tool, called FIE, that builds off the KLEE symbolic execution engine in order to provide an extensible platform for detecting bugs in firmware programs for the popular MSP430 family of microcontrollers. FIE incorporates new techniques for symbolic execution that enable it to verify security prop-erties of the simple firmwares often found in practice. We demonstrate FIE's utility by applying it to a corpus of 99 open-source firmware programs that altogether use 13 different models of the MSP430. We are able to ver-ify memory safety for the majority of programs in this corpus and elsewhere discover 21 bugs.},
author = {Davidson, Drew and Ristenpart, Thomas and Madison, Wisconsin},
isbn = {978-1-931971-03-4},
journal = {usenix security},
title = {{FIE on Firmware : Finding Vulnerabilities in Embedded Systems using Symbolic Execution}},
year = {2013}
}
@article{Jana2013,
author = {Jana, Suman and Molnar, David and Moshchuk, Alexander and Dunn, Alan and Livshits, Benjamin and Wang, Helen J and Ofek, Eyal},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {415--430},
title = {{Enabling Fine-Grained Permissions for Augmented Reality Applications with Recognizers}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/presentation/jana},
year = {2013}
}
@article{Wang2013c,
author = {Wang, Ruoyu and Shoshitaishvili, Yan and Kruegel, Christopher and Vigna, Giovanni},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {687--702},
title = {{Steal This Movie: Automatically Bypassing DRM Protection in Streaming Media Services}},
url = {https://www.usenix.org/conference/usenixsecurity13/technical-sessions/paper/wang{\{}{\_}{\}}ruoyu},
year = {2013}
}
@article{Akhawe2013,
abstract = {We empirically assess whether browser security warn- ings are as ineffective as suggested by popular opinion and previous literature. We used Mozilla Firefox and Google Chrome’s in-browser telemetry to observe over 25 million warning impressions in situ. During our field study, users continued through a tenth of Mozilla Fire- fox’s malware and phishing warnings, a quarter of Google Chrome’s malware and phishing warnings, and a third of Mozilla Firefox’s SSL warnings. This demonstrates that security warnings can be effective in practice; security experts and system architects should not dismiss the goal of communicating security information to end users. We also find that user behavior varies acrosswarnings. In con- trast to the other warnings, users continued through 70.2{\{}{\%}{\}} of Google Chrome’s SSL warnings. This indicates that the user experience of a warning can have a significant impact on user behavior. Based on our findings, we make recommendations for warning designers and researchers.},
author = {Akhawe, Devdatta and Felt, Adrienne Porter},
isbn = {9781931971034},
journal = {usenix security},
pages = {257--272},
title = {{Alice in warningland: a large-scale field study of browser security warning effectiveness}},
year = {2013}
}
@article{Nelms2013,
abstract = {In this paper, we present ExecScent, a novel system that aims to mine new, previously unknown C{\{}{\&}{\}}C domain names from live enterprise network traffic. ExecScent automatically learns control protocol templates (CPTs) from examples of known C{\{}{\&}{\}}C communications. These CPTs are then adapted to the “background traffic” of the network where the templates are to be deployed. The goal is to generate hybrid templates that can self-tune to each specific deployment scenario, thus yielding a bet- ter trade-off between true and false positives for a given network environment. To the best of our knowledge, Ex- ecScent is the first system to use this type of adaptive C{\{}{\&}{\}}C traffic models. We implemented a prototype version of ExecScent, and deployed it in three different large networks for a period of two weeks. During the deployment, we discov- ered many new, previously unknown C{\{}{\&}{\}}C domains and hundreds of new infected machines, compared to using a large up-to-date commercial C{\{}{\&}{\}}C domain blacklist. Fur- thermore, we deployed the new C{\{}{\&}{\}}C domains mined by ExecScent to six large ISP networks, discovering more than 25,000 new infected machines.},
author = {Nelms, Terry and Perdisci, Roberto and Ahamad, Mustaque},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {589--604},
title = {{ExecScent: Mining for New C{\&}C Domains in Live Networks with Adaptive Control Protocol Templates}},
url = {http://www.people.vcu.edu/{\{}{~}{\}}cfung/bib/Botnet.pdf},
year = {2013}
}
@article{Wang2013d,
abstract = {Authomatic find vulns in login sdks using logic. Focus on Windows8},
author = {Wang, Rui and Zhou, Yuchen and Chen, Shuo and Qadeer, Shaz and Evans, David and Gurevich, Yuri},
isbn = {9781931971034},
journal = {usenix security},
number = {August},
pages = {14--16},
title = {{Explicating SDKs : Uncovering Assumptions Underlying Secure Authentication and Authorization University of Virginia}},
year = {2013}
}
@article{Octeau2013,
abstract = {Name: Epicc},
author = {Octeau, Damien and McDaniel, Patrick and Jha, Somesh and Bartel, Alexandre and Bodden, Eric and Klein, Jacques and Traon, Yves Le},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {543--558},
title = {{Effective Inter-Component Communication Mapping in Android with Epicc: An Essential Step Towards Holistic Security Analysis}},
year = {2013}
}
@article{Bhargavan2013,
abstract = {We present new attacks and robust countermeasures for security-sensitive components, such as single sign-on APIs and client-side cryptographic libraries, that need to be safely deployed on untrusted web pages. We show how failing to isolate such components leaves them vul-nerable to attacks both from the hosting website and other components running on the same page. These attacks are not prevented by browser security mecha-nisms alone, because they are caused by code interact-ing within the same origin. To mitigate these attacks, we propose to combine fine-grained component isola-tion at the JavaScript level with cryptographic mecha-nisms. We present Defensive JavaScript (DJS), a subset of the language that guarantees the behavior integrity of scripts even when loaded in a hostile environment. We give a sound type system, type inference tool, and build defensive libraries for cryptography and data encodings. We show the effectiveness of our solution by implement-ing several applications using defensive patterns that fix some of our original attacks. We present a model extrac-tion tool to analyze the security properties of our appli-cations using a cryptographic protocol verifier.},
author = {Bhargavan, Karthikeyan and Delignat-Lavaud, Antoine and Maffeis, Sergio},
isbn = {978-1-931971-03-4},
journal = {usenix security},
pages = {653--670},
title = {{Language-based Defenses Against Untrusted Browser Origins}},
url = {http://www.defensivejs.com/usenixsec13.pdf$\backslash$nhttp://dl.acm.org/citation.cfm?id=2534766.2534822},
year = {2013}
}
@article{Jiang2013,
abstract = {In this paper, we present the design of Greystar, an inno- vative defense system for combating the growing SMS spam traffic in cellular networks. By exploiting the fact that most SMS spammers select targets randomly from the finite phone number space, Greystar monitors phone numbers from the grey phone space (which are associ- ated with data only devices like laptop data cards and machine-to-machine communication devices like elec- tricity meters) and employs a novel statistical model to detect spam numbers based on their footprints on the grey phone space. Evaluation using five month SMS call detail records from a large US cellular carrier shows thatGreystar can detect thousands of spam numbers each month with very few false alarms and 15{\{}{\%}{\}} of the de- tected spam numbers have never been reported by spam recipients. Moreover, Greystar is much faster in detect- ing SMS spam than existing victim spam reports, reduc- ing spam traffic by 75{\{}{\%}{\}} during peak hours. 1},
author = {Jiang, Nan and Jin, Yu and Skudlark, Ann and Labs, T and Zhang, Zhi-li},
isbn = {9781931971034},
journal = {usenix security},
pages = {328--347},
title = {{Greystar : Fast and Accurate Detection of SMS Spam Numbers in Large Cellular Networks using Grey Phone Space Greystar : Fast and Accurate Detection of SMS Spam Numbers in Large}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-41284-4{\{}{\_}{\}}17},
volume = {7},
year = {2013}
}
@article{Rahman2012,
abstract = {Online social networks (OSNs) have become the new vec- tor for cybercrime, and hackers are finding new ways to propagate spam and malware on these platforms, which we refer to as socware. As we show here, socware cannot be identified with existing security mechanisms (e.g., URL blacklists), because it exploits different weaknesses and of- ten has different intentions. In this paper, we present MyPageKeeper, a Facebook ap- plication that we have developed to protect Facebook users from socware. Here, we present results from the perspective of over 12K users who have installed MyPageKeeper and their roughly 2.4 million friends. Our work makes three main contributions. First, to enable protection of users at scale, we design an efficient socware detection method which takes advantage of the social context of posts. We find that our classifier is both accurate (97{\{}{\%}{\}} of posts flagged by it are indeed socware and it incorrectly flags only 0.005{\{}{\%}{\}} of benign posts) and efficient (it requires 46 ms on average to classify a post). Second, we show that socware significantly differs from traditional email spam or web-based malware. For example, website blacklists identify only 3{\{}{\%}{\}} of the posts flagged by MyPageKeeper, while 26{\{}{\%}{\}} of flagged posts point to malicious apps and pages hosted on Facebook (which no current antivirus or blacklist is designed to detect). Third, we quantify the prevalence of socware by analyzing roughly 40 million posts over four months; 49{\{}{\%}{\}} of our users were exposed to at least one socware post in this period. Finally, we identify a new type of parasitic behavior, which we refer to as “Like-as-a-Service”, whose goal is to artificially boost the number of “Likes” of a Facebook page.},
author = {Rahman, Md Sazzadur and Huang, Ting-Kai and Madhyastha, Harsha V and Faloustos, Michalis},
isbn = {978-931971-95-9},
journal = {usenix security},
number = {October},
pages = {32},
title = {{Efficient and Scalable Socware Detection in Online Social Networks}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final84.pdf},
year = {2012}
}
@article{Carlini2012,
abstract = {Vulnerabilities in browser extensions put users at risk by providing a way for website and network attackers to gain access to users’ private data and credentials. Extensions can also introduce vulnerabilities into the websites that they modify. In 2009, Google Chrome introduced a new extension platform with several features intended to prevent and mitigate extension vulnerabilities: strong isolation between websites and extensions, privilege separation within an extension, and an extension permission system. We performed a security review of 100 Chrome extensions and found 70 vulnerabilities across 40 extensions. Given these vulnerabilities, we evaluate how well each of the security mechanisms defends against extension vulnerabilities. We find that the mechanismsmostly succeed at preventing direct web attacks on extensions, but new security mechanisms are needed to protect users from network attacks on extensions, website metadata attacks on extensions, and vulnerabilities that extensions add to websites. We propose and evaluate additional defenses, and we conclude that banning HTTP scripts and inline scriptswould prevent 47 of the 50 most severe vulnerabilities with only modest impact on developers.},
author = {Carlini, Nicholas and Felt, Ap and Wagner, David},
isbn = {978-931971-95-9},
issn = {<null>},
journal = {usenix security},
pages = {7},
title = {{An evaluation of the google chrome extension security architecture}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final177{\{}{\_}{\}}0.pdf},
year = {2012}
}
@article{Feldman2012,
abstract = {Today’s social networking services require users to trust the service provider with the confidentiality and integrity of their data. But with their history of data leaks and privacy controversies, these services are not always de- serving of this trust. Indeed, a malicious provider could not only violate users’ privacy, it could equivocate and show different users divergent views of the system’s state. Such misbehavior can lead to numerous harms including surreptitious censorship. In light of these threats, this paper presents Frientegrity, a framework for social networking applications that can be realized with an untrusted service provider. In Frientegrity, a provider observes only encrypted data and cannot devi- ate from correct execution without being detected. Prior secure social networking systems have either been decen- tralized, sacrificing the availability and convenience of a centralized provider, or have focused almost entirely on users’ privacy while ignoring the threat of equivocation. On the other hand, existing systems that are robust to equivocation do not scale to the needs social networking applications in which users may have hundreds of friends, and in which users are mainly interested the latest updates, not in the thousands that may have come before. To address these challenges, we present a novel method for detecting provider equivocation in which clients col- laborate to verify correctness. In addition, we introduce an access control mechanism that offers efficient revocation and scales logarithmically with the number of friends. We present a prototype implementation demonstrating that Frientegrity provides latency and throughput that meet the needs},
author = {Feldman, Aj and Blankstein, Aaron},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {31},
title = {{Social networking with frientegrity: privacy and integrity with an untrusted provider}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final67.pdf},
volume = {Vol. 12},
year = {2012}
}
@article{Borders2012,
abstract = {Intrusion detection systems play a vital role in network security. Central to these systems is the language used to express policies. Ideally, this language should be powerful, implementation-agnostic, and cross-platform. Unfortunately, today's popular intrusion detection systems fall short of this goal. Each has their own policy language in which expressing complicated logic requires implementation-specific code. Database systems have adapted SQL to handle streaming data, but have yet to achieve the efficiency and flexibility required for complex intrusion detection tasks. In this paper, we introduce Chimera, a declarative query language for network traffic processing that bridges the gap between powerful intrusion detection systems and a simple, platform-independent SQL syntax. Chimera extends streaming SQL languages to better handle network traffic by adding structured data types, first-class functions, and dynamic window boundaries. We show how these constructs can be applied to real-world scenarios, such as side-jacking detection and DNS feature extraction. Finally, we describe the implementation and evaluation of a compiler that translates Chimera queries into low-level code for the Bro event language.},
author = {Borders, Kevin and Springer, Jonathan and Burnside, Matthew},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {365--379},
title = {{Chimera: A Declarative Language for Streaming Network Traffic Analysis}},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/borders},
year = {2012}
}
@article{Heninger2012,
abstract = {RSA and DSA can fail catastrophically when used with malfunctioning random number generators, but the extent to which these problems arise in practice has never been comprehensively studied at Internet scale. We perform the largest ever network survey of TLS and SSH servers and present evidence that vulnerable keys are surprisingly widespread. We find that 0.75{\{}{\%}{\}} of TLS certificates share keys due to insufficient entropy during key generation, and we suspect that another 1.70{\{}{\%}{\}} come from the same faulty implementations and may be susceptible to compromise. Even more alarmingly, we are able to obtain RSA private keys for 0.50{\{}{\%}{\}} of TLS hosts and 0.03{\{}{\%}{\}} of SSH hosts, because their public keys shared nontrivial common factors due to entropy problems, and DSA private keys for 1.03{\{}{\%}{\}} of SSH hosts, because of insufficient signature randomness. We cluster and investigate the vulnerable hosts, finding that the vast majority appear to be headless or embedded devices. In experiments with three software components commonly used by these devices, we are able to reproduce the vulnerabilities and identify specific software behaviors that induce them, including a boot-time entropy hole in the Linux random number generator. Finally, we suggest defenses and draw lessons for developers, users, and the security community.},
author = {Heninger, Nadia and Durumeric, Zakir and Wustrow, Eric and Halderman, J Alex},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {35},
title = {{Mining your Ps and Qs: detection of widespread weak keys in network devices}},
url = {http://dl.acm.org/citation.cfm?id=2362793.2362828},
year = {2012}
}
@article{Martinovic2012,
abstract = {Brain computer interfaces (BCI) are becoming in- creasingly popular in the gaming and entertainment in- dustries. Consumer-grade BCI devices are available for a few hundred dollars and are used in a variety of appli- cations, such as video games, hands-free keyboards, or as an assistant in relaxation training. There are application stores similar to the ones used for smart phones, where application developers have access to an API to collect data from the BCI devices. The security risks involved in using consumer-grade BCI devices have never been studied and the impact of malicious software with access to the device is unex- plored. We take a first step in studying the security impli- cations of such devices and demonstrate that this upcom- ing technology could be turned against users to reveal their private and secret information. We use inexpensive electroencephalography (EEG) based BCI devices to test the feasibility of simple, yet effective, attacks. The cap- tured EEG signal could reveal the users private informa- tion about, e.g., bank cards, PIN numbers, area of living, the knowledge of the known persons. This is the first attempt to study the security implications of consumer- grade BCI devices. We show that the entropy of the pri- vate information is decreased on the average by approx- imately 15{\{}{\%}{\}} - 40{\{}{\%}{\}} compared to random guessing at- tacks.},
author = {Martinovic, Ivan and Davies, Doug and Frank, Mario and Perito, Daniele and Ros, Tomas and Song, Dawn},
isbn = {978-931971-95-9},
issn = {0733-8716},
journal = {usenix security},
pages = {1--16},
title = {{On the Feasibility of Side-Channel Attacks with Brain-Computer Interfaces}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final56.pdf},
year = {2012}
}
@article{Kim2012,
author = {Kim, Taesoo and Peinado, Marcus and Mainar-Ruiz, Gloria},
journal = {usenix security},
pages = {1--16},
title = {{StealthMem: System-Level Protection Against Cache-Based Side Channel Attacks in the Cloud}},
url = {https://www.usenix.org/conference/usenixsecurity12/tech-schedule/technical-sessions papers3://publication/uuid/DFBC49F2-2210-4A34-9E81-5CA33359DFA9},
year = {2012}
}
@article{Stringhini2012,
author = {Stringhini, Gianluca and Egele, Manuel and Zarras, Apostolis and Holz, Thorsten and Kruegel, Christopher and Vigna, Giovanni},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {1--16},
title = {{B@bel: Leveraging Email Delivery for Spam Mitigation}},
url = {http://www.ei.rub.de/forschung/veroeffentlichungen/babel/$\backslash$npapers3://publication/uuid/191FA03E-9A48-4134-B00E-ACD8B44E06ED},
year = {2012}
}
@article{Argyros2012,
abstract = {We provide a number of practical techniques and algorithms for exploiting randomness vulnerabilities in PHP applications.We focus on the predictability of password reset tokens and demonstrate how an attacker can take over user accounts in a web application via pre- dicting or algorithmically derandomizing the PHP core randomness generators. While our techniques are designed for the PHP language, the principles behind our techniques and our algorithms are independent of PHP and can readily apply to any system that utilizes weak randomness generators or low entropy sources. Our results include: algorithms that reduce the entropy of time variables, identifying and exploiting vulnerabilities of the PHP system that enable the recovery or reconstruction of PRNG seeds, an experimental analysis of the H˚ astad-Shamir framework for breaking truncated linear variables, an optimized online Gaussian solver for large sparse linear systems, and an algorithm for recovering the state of the Mersenne twister generator from any level of truncation. We demonstrate the gravity of our attacks via a number of case studies. Specifically, we show that a number of cur- rent widely used web applications can be broken using our techniques including Mediawiki, Joomla, Gallery, osCommerce and others.},
author = {Argyros, George and Kiayias, a},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {1--35},
title = {{I Forgot Your Password: Randomness Attacks Against PHP Applications.}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final218.pdf},
year = {2012}
}
@article{Doupe2012,
abstract = {Black-box web vulnerability scanners are a popular choice for finding security vulnerabilities in web applications in an automated fashion. These tools operate in a point-and-shootmanner, testing any web application-- regardless of the server-side language--for common security vulnerabilities. Unfortunately, black-box tools suffer from a number of limitations, particularly when interacting with complex applications that have multiple actions that can change the application's state. If a vulnerability analysis tool does not take into account changes in the web application's state, it might overlook vulnerabilities or completely miss entire portions of the web application. We propose a novel way of inferring the web application's internal state machine from the outside--that is, by navigating through the web application, observing differences in output, and incrementally producing a model representing the web application's state. We utilize the inferred state machine to drive a black-box web application vulnerability scanner. Our scanner traverses a web application's state machine to find and fuzz user-input vectors and discover security flaws. We implemented our technique in a prototype crawler and linked it to the fuzzing component from an open-source web vulnerability scanner. We show that our state-aware black-box web vulnerability scanner is able to not only exercise more code of the web application, but also discover vulnerabilities that other vulnerability scanners miss.},
author = {Doup{\'{e}}, Adam and Cavedon, Ludovico and Kruegel, Christopher and Vigna, Giovanni},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {523--538},
title = {{Enemy of the State: A State-Aware Black-Box Web Vulnerability Scanner}},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/doupe},
year = {2012}
}
@article{,
journal = {usenix security},
title = {{Clickjacking: Attacks and Defenses}},
year = {2012}
}
@article{Devet2012,
author = {Devet, Casey and Goldberg, Ian and Heninger, Nadia},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {269--283},
title = {{Optimally Robust Private Information Retrieval.}},
url = {http://www.cypherpunks.ca/{\{}{~}{\}}iang/pubs/hybridpir-pets.pdf$\backslash$nhttps://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final90.pdf},
year = {2012}
}
@article{Reardon2012,
abstract = {We propose the Data Node Encrypted File System (DNEFS), which uses on-the-fly encryption and decryption of file system data nodes to efficiently and securely delete data on flash memory systems. DNEFS is a generic modification of existing flash file systems or controllers that enables secure data deletion while preserving the underlying systems’ desirable properties: application-independence, fine-grained data access, wear-levelling, and efficiency. We describe DNEFS both abstractly and in the context of the flash file system UBIFS. We propose UBIFSec, which integrates DNEFS into UBIFS. We implement UBIFSec by extending UBIFS’s Linux implementation and we integrate UBIFSec in the Android operating system running on a Google Nexus One smartphone. We show that it is efficient and usable; Android OS and applications (including video and audio playback) run normally on top of UBIFSec. To the best of our knowledge, this work presents the first comprehensive and fully-implemented secure deletion solution that works within the specification of flash memory.},
author = {Reardon, Joel and Capkun, Srdjan and David, a},
isbn = {978-931971-95-9},
journal = {usenix security},
title = {{Data node encrypted file system: Efficient secure deletion for flash memory}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final74.pdf},
year = {2012}
}
@article{McCoy2012,
author = {McCoy, D and Pitsillidis, a and Jordan, G and Weaver, N and Kreibich, C and Krebs, B and Voelker, G M and Savage, S and Levchenko, K},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {1--16},
title = {{PharmaLeaks: Understanding the Business of Online Pharmaceutical Affiliate Programs}},
url = {papers://9934fd52-194f-4a2f-b130-d9de48bdab09/Paper/p253},
year = {2012}
}
@article{Kontaxis2012,
abstract = {The widespread adoption of social plugins, such as Face- book’s Like and Google’s +1 buttons, has raised con- cerns about their implications to user privacy, as they en- able social networking services to track a growing part of their members’ browsing activity. Existing mitigations in the form of browser extensions can prevent social plugins from tracking user visits, but inevitably disable any kind of content personalization, ruining the user experience. In this paper we propose a novel design for privacy- preserving social plugins that decouples the retrieval of user-specific content from the loading of a social plugin. In contrast to existing solutions, this design preserves the functionality of existing social plugins by delivering the same personalized content, while it protects user privacy by avoiding the transmission of user-identifying infor- mation at load time. We have implemented our design in SafeButton, an add-on for Firefox that fully supports seven out of the nine social plugins currently provided by Facebook, including the Like button, and partially due to API restrictions the other two. As privacy-preserving so- cial plugins maintain the functionality of existing social plugins, we envisage that they could be adopted by social networking services themselves for the benefit of their members. To that end, we also present a pure JavaScript design that can be offered transparently as a service with- out the need to install any browser add-ons.},
author = {Kontaxis, Georgios and Polychronakis, Michalis and Keromytis, Angelos D and Markatos, Evangelos P},
isbn = {978-931971-95-9},
journal = {usenix security},
keywords = {Privay,Social},
title = {{Privacy-Preserving Social Plugins}},
year = {2012}
}
@article{Shekhar2012,
abstract = {A wide variety of smartphone applications today rely on third-party advertising services, which provide libraries that are linked into the hosting application. This situation is undesirable for both the application author and the advertiser. Advertising libraries require additional permissions, resulting in additional permission requests to users. Likewise, a malicious application could simulate the behavior of the advertising library, forging the user's interaction and effectively stealing money from the advertiser. This paper describes AdSplit, where we extended Android to allow an application and its advertising to run as separate processes, under separate user-ids, eliminating the need for applications to request permissions on behalf of their advertising libraries. We also leverage mechanisms from Quire to allow the remote server to validate the authenticity of client-side behavior. In this paper, we quantify the degree of permission bloat caused by advertising, with a study of thousands of downloaded apps. AdSplit automatically recompiles apps to extract their ad services, and we measure minimal runtime overhead. We also observe that most ad libraries just embed an HTML widget within and describe how AdSplit can be designed with this in mind to avoid any need for ads to have native code.},
archivePrefix = {arXiv},
arxivId = {1202.4030},
author = {Shekhar, Shashi and Dietz, Michael and Wallach, Dan S},
eprint = {1202.4030},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {28},
title = {{AdSplit: Separating smartphone advertising from applications}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final101.pdf$\backslash$nhttp://arxiv.org/abs/1202.4030},
year = {2012}
}
@article{Riva2012,
abstract = {Abstract Mobile users are often faced with a trade-off between security and convenience. Either users do not use any security lock and risk compromising their data, or they use security locks but then have to inconveniently authenticate every time they use the device. ... $\backslash$n},
author = {Riva, O and Qin, C and Strauss, K},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {1--16},
title = {{Progressive authentication: deciding when to authenticate on mobile phones}},
url = {https://www.usenix.org/sites/default/files/conference/protected-files/riva{\{}{\_}{\}}usenixsecurity12{\{}{\_}{\}}slides.pdf$\backslash$npapers3://publication/uuid/6A9A5626-79EB-4A19-901C-BD29F80E2194},
year = {2012}
}
@article{Kreuter2012,
abstract = {The goal of this paper is to assess the feasibility of two-party secure computation in the presence of a malicious adversary. Prior work has shown the feasibility of billion-gate circuits in the semi-honest model, but only the 35k-gate AES circuit in the malicious model, in part because security in the malicious model is much harder to achieve. We show that by incorporating the best known techniques and parallelizing almost all steps of the resulting protocol, evaluating billion-gate circuits is feasible in the malicious model. Our results are in the standard model (i.e., no common reference strings or PKIs) and, in contrast to prior work, we do not use the random oracle model which has well-established theoretical shortcomings.},
author = {Kreuter, B and Shelat, a. and Shen, C},
doi = {10.1007/978-3-642-20465-4{\{}{\_}{\}}22},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {14--30},
title = {{Billion-Gate Secure Computation with Malicious Adversaries}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final202.pdf},
year = {2012}
}
@article{Wu2012,
abstract = {Information security and privacy in general are major concerns that impede enterprise adaptation of shared or public cloud computing. Specifically, the concern of virtual machine (VM) physical co-residency stems from the threat that hostile tenants can leverage various forms of side channels (such as cache covert channels) to exfiltrate sensitive information of victims on the same physical system. However, on virtualized ×86 systems, covert channel attacks have not yet proven to be practical, and thus the threat is widely considered a "potential risk". In this paper, we present a novel covert channel attack that is capable of high-bandwidth and reliable data transmission in the cloud. We first study the application of existing cache channel techniques in a virtualized environment, and uncover their major insufficiency and difficulties. We then overcome these obstacles by (1) redesigning a pure timing-based data transmission scheme, and (2) exploiting the memory bus as a high-bandwidth covert channel medium. We further design and implement a robust communication protocol, and demonstrate realistic covert channel attacks on various virtualized ×86 systems. Our experiments show that covert channels do pose serious threats to information security in the cloud. Finally, we discuss our insights on covert channel mitigation in virtualized environments.},
author = {Wu, Zhenyu and Xu, Zhang and Wang, Haining},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {9},
title = {{Whispers in the hyper-space: high-speed covert channel attacks in the cloud}},
url = {http://dl.acm.org/citation.cfm?id=2362793.2362802},
year = {2012}
}
@article{Dietz2012,
abstract = {Client authentication on the web has remained in the internet-equivalent of the stone ages for the last two decades. Instead of adopting modern public-key-based authentication mechanisms, we seem to be stuck with passwords and cookies. In this paper, we propose to break this stalemate by presenting a fresh approach to public-key-based client authentication on the web. We describe a simple TLS extension that allows clients to establish strong authenticated channels with servers and to bind existing authentication tokens like HTTP cookies to such channels. This allows much of the existing infrastructure of the web to remain unchanged, while at the same time strengthening client authentication considerably against a wide range of attacks. We implemented our system in Google Chrome and Google's web serving infrastructure, and provide a performance evaluation of this implementation.},
author = {Dietz, Michael and Czeskis, Alexei and Wallach, Dan S},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {16},
title = {{Origin-Bound Certificates : A Fresh Approach to Strong Client Authentication for the Web}},
url = {http://dl.acm.org/citation.cfm?id=2362793.2362809},
year = {2012}
}
@article{Giuffrida2012,
abstract = {n recent years, the deployment of many application-level countermeasures against memory errors and the increasing number of vulnerabilities discovered in the kernel has fostered a renewed interest in kernel-level exploitation. Unfortunately, no comprehensive and well-established mechanism exists to protect the operating system from arbitrary attacks, due to the relatively new development of the area and the challenges involved. In this paper, we propose the first design for fine-grained address space randomization (ASR) inside the operating system (OS), providing an efficient and comprehensive countermeasure against classic and emerging attacks, such as return-oriented programming. To motivate our design, we investigate the differences with application-level ASR and find that some of the well-established assumptions in existing solutions are no longer valid inside the OS; above all, perhaps, that information leakage becomes a major concern in the new context. We show that our ASR strategy outperforms state-of-the-art solutions in terms of both performance and security without affecting the software distribution model. Finally, we present the first comprehensive live rerandomization strategy, which we found to be particularly important inside the OS. Experimental results demonstrate that our techniques yield low run-time performance overhead (less than 5{\{}{\%}{\}} on average on both SPEC and syscall-intensive benchmarks) and limited run-time memory footprint increase (around 15{\{}{\%}{\}} during the execution of our benchmarks). We believe our techniques can greatly enhance the level of OS security without compromising the performance and reliability of the OS.},
author = {Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, As},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {16},
title = {{Enhanced operating system security through efficient and fine-grained address space randomization}},
url = {https://www.usenix.org/sites/default/files/conference/protected-files/giuffrida{\{}{\_}{\}}usenixsecurity12{\{}{\_}{\}}slides.pdf},
year = {2012}
}
@article{Bojinov2012,
abstract = {Cryptographic systems often rely on the secrecy of cryptographic keys given to users. Many schemes, however, cannot resist coercion attacks where the user is forcibly asked by an attacker to reveal the key. These attacks, known as rubber hose cryptanalysis, are often the easiest way to defeat cryptography. We present a defense against coercion attacks using the concept of implicit learning from cognitive psychology. Implicit learning refers to learning of patterns without any conscious knowledge of the learned pattern. We use a carefully crafted computer game to plant a secret password in the participant’s brain without the participant having any conscious knowledge of the trained password. While the planted secret can be used for authentication, the participant cannot be coerced into revealing it since he or she has no conscious knowledge of it. We performed a number of user studies using Amazon’s Mechanical Turk to verify that participants can successfully reauthenticate over time and that they are unable to reconstruct or even recognize short fragments of the planted secret.},
author = {Bojinov, Hristo (Stanford University) and Sanchez, Daniel (Northwestern University) and Reber, Paul (Northwestern University) and Boneh, Dan (Stanford University) and Lincoln, Patrick (Sri)},
doi = {10.1145/2594445},
isbn = {978-931971-95-9},
issn = {0001-0782},
journal = {usenix security},
pages = {1--13},
title = {{Neuroscience Meets Cryptography : Designing Crypto Primitives Secure Against Rubber Hose Attacks}},
year = {2012}
}
@article{Ur2012,
author = {Ur, Blase and Kelley, Patrick Gage and Komanduri, Saranga and Lee, Joel and Maass, Michael and Mazurek, Michelle L and Passaro, Timothy and Shay, Richard and Vidas, Timothy and Bauer, Lujo and Christin, Nicolas and Cranor, Lorrie Faith},
isbn = {978-931971-95-9},
journal = {usenix security},
title = {{How Does Your Password Measure Up? The Effect of Strength Meters on Password Creation}},
year = {2012}
}
@article{Akhawe2012,
abstract = {The standard approach for privilege separation in web applications is to execute application components in different web origins. This limits the practicality of privilege separation since each web origin has financial and administrative cost. In this paper, we propose a new design for achieving effective privilege separation in HTML5 applications that shows how applications can cheaply create arbitrary number of components. Our approach utilizes standardized abstractions already implemented in modern browsers. We do not advocate any changes to the underlying browser or require learning new high-level languages, which contrasts prior approaches. We empirically show that we can retrofit our design to real-world HTML5 applications (browser extensions and rich client-side applications) and achieve reduction of 6x to 10000x in TCB for our case studies. Our mechanism requires less than 13 lines of application-specific code changes and considerably improves auditability.},
author = {Akhawe, Devdatta and Saxena, Prateek and Song, Dawn},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {23},
title = {{Privilege Separation in HTML5 Applications}},
year = {2012}
}
@article{Jacob2012,
author = {Jacob, Gregoire and Kirda, Engin and Kruegel, Christopher and Vigna, Giovanni},
journal = {usenix security},
pages = {1--16},
title = {{PubCrawl: Protecting Users and Businesses from CRAWLers}},
url = {https://www.usenix.org/conference/usenixsecurity12/tech-schedule/technical-sessions papers3://publication/uuid/94967329-C6E6-47DE-8EAC-5F80AFEAB709},
year = {2012}
}
@article{Setty2012,
abstract = {We describe GINGER, a built system for un- conditional, general-purpose, and nearly practical verifi- cation of outsourced computation. GINGER is based on PEPPER, which uses the PCP theorem and cryptographic techniques to implement an efficient argument system (a kind of interactive protocol). GINGER slashes the query size and costs via theoretical refinements that are of in- dependent interest; broadens the computational model to include (primitive) floating-point fractions, inequality comparisons, logical operations, and conditional control flow; and includes a parallel GPU-based implementation that dramatically reduces latency.},
author = {Setty, Srinath and Vu, Victor and Panpalia, Nikhil and Braun, Benjamin},
isbn = {978-931971-95-9},
journal = {usenix security},
title = {{Taking proof-based verified computation a few steps closer to practicality}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final26{\{}{\_}{\}}0.pdf},
year = {2012}
}
@article{Santos2012,
abstract = {Accidental or intentional mismanagement of cloud software by administrators poses a serious threat to the integrity and confidentiality of customer data hosted by cloud services. Trusted computing provides an important foundation for designing cloud services that are more resilient to these threats. However, current trusted computing technology is ill-suited to the cloud as it exposes too many internal details of the cloud infrastructure, hinders fault tolerance and load-balancing flexibility, and performs poorly. We present Excalibur, a system that addresses these limitations by enabling the design of trusted cloud services. Excalibur provides a new trusted computing abstraction, called policy-sealed data, that lets data be sealed (i.e., encrypted to a customer-defined policy) and then unsealed (i.e., decrypted) only by nodes whose configurations match the policy. To provide this abstraction, Excalibur uses attribute-based encryption, which reduces the overhead of key management and improves the performance of the distributed protocols employed. To demonstrate that Excalibur is practical, we incorporated it in the Eucalyptus open-source cloud platform. Policy-sealed data can provide greater confidence to Eucalyptus customers that their data is not being mismanaged.},
author = {Santos, Nuno and Rodrigues, Rodrigo and Gummadi, Krishna P and Saroiu, Stefan},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {175--188},
title = {{Policy-sealed data: A new abstraction for building trusted cloud services}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final22.pdf},
year = {2012}
}
@article{Kemerlis2012,
abstract = {Return-to-user (ret2usr) attacks exploit the operating system kernel, enabling local users to hijack privileged execution paths and execute arbitrary code with elevated privileges. Current defenses have proven to be inadequate, as they have been repeatedly circumvented, incur considerable overhead, or rely on extended hypervi- sors and special hardware features. We present kGuard, a compiler plugin that augments the kernel with compact inline guards, which prevent ret2usr with low performance and space overhead. kGuard can be used with any operating system that features a weak separation between kernel and user space, requires no modifications to the OS, and is applicable to both 32- and 64-bit architectures. Our evaluation demonstrates that Linux kernels compiled with kGuard become impervious to a variety of control-flow hijacking exploits. kGuard exhibits lower overhead than previouswork, imposing on average an overhead of 11.4{\{}{\%}{\}} on system call and I/O latency on x86 OSs, and 10.3{\{}{\%}{\}} on x86-64. The size of a kGuard- protected kernel grows between 3.5{\{}{\%}{\}} and 5.6{\{}{\%}{\}}, due to the inserted checks, while the impact on real-life applications is minimal (≤1{\{}{\%}{\}}).},
author = {Kemerlis, Vasileios P and Portokalidis, Georgios and Keromytis, Angelos D},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {459--474},
title = {{kGuard : Lightweight Kernel Protection against Return-to-user Attacks}},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/kemerlis},
year = {2012}
}
@article{Lin2012,
author = {Lin, Zi and Hopper, Nicholas},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {381--396},
title = {{New Attacks on Timing-based Network Flow Watermarks}},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/zin},
year = {2012}
}
@article{Dasgupta2012,
author = {Dasgupta, Anirban and Punera, Kunal and Rao, Justin M and Wang, Xuanhui},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {33--48},
title = {{Impact of Spam Exposure on User Engagement}},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/dasgupta},
year = {2012}
}
@article{,
journal = {usenix security},
title = {{Gone in 360 Seconds: Hijacking with Hitag2}},
year = {2012}
}
@article{Holler2012,
abstract = {Fuzz testing is an automated technique providing random data as input to a software system in the hope to expose a vulnerability. In order to be effective, the fuzzed input must be common enough to pass elementary consistency checks; a JavaScript interpreter, for instance, would only accept a semantically valid program. On the other hand, the fuzzed input must be uncommon enough to trigger exceptional behavior, such as a crash of the interpreter. The LangFuzz approach resolves this conflict by using a grammar to randomly generate valid programs; the code fragments, however, partially stem from programs known to have caused invalid behavior before. LangFuzz is an effective tool for security testing: Applied on the Mozilla JavaScript interpreter, it discovered a total of 105 new severe vulnerabilities within three months of operation (and thus became one of the top security bug bounty collectors within this period); applied on the PHP interpreter, it discovered 18 new defects causing crashes.},
author = {Holler, Christian and Herzig, Kim and Zeller, Andreas},
isbn = {978-931971-95-9},
journal = {usenix security},
keywords = {fuzz testing,grammar,security,security testing},
pages = {38},
title = {{Fuzzing with Code Fragments}},
url = {http://dl.acm.org/citation.cfm?id=2362793.2362831},
year = {2012}
}
@article{Rahmati2012,
abstract = {Lack of a locally trustworthy clock makes security protocols challenging to implement on batteryless embedded devices such as contact smartcards, contactless smartcards, and RFID tags. A device that knows how much time has elapsed between queries from an untrusted reader could better protect against attacks that depend on the existence of a rate-unlimited encryption oracle. The TARDIS (Time and Remanence Decay in SRAM) helps locally maintain a sense of time elapsed without power and without special-purpose hardware. The TARDIS software computes the expiration state of a timer by analyzing the decay of existing on-chip SRAM. The TARDIS enables coarse-grained, hourglass-like timers such that cryptographic software can more deliberately decide how to throttle its response rate. Our experiments demonstrate that the TARDIS can measure time ranging from seconds to several hours depending on hardware parameters. Key challenges to implementing a practical TARDIS include compensating for temperature and handling variation across hardware. Our contributions are (1) the algorithmic building blocks for computing elapsed time from SRAM decay; (2) characterizing TARDIS behavior under different temperatures, capacitors, SRAM sizes, and chips; and (3) three proof-of-concept implementations that use the TARDIS to enable privacy-preserving RFID tags, to deter double swiping of contactless credit cards, and to increase the difficulty of brute-force attacks against e-passports.},
author = {Rahmati, Amir and Salajegheh, Mastooreh},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {36},
title = {{TARDIS: Time and remanence decay in SRAM to implement secure protocols on embedded devices without clocks}},
url = {http://dl.acm.org/citation.cfm?id=2362793.2362829$\backslash$nhttps://spqr.eecs.umich.edu/papers/rahmati-usenix12.pdf$\backslash$nhttps://spqr.eecs.umich.edu/tardis/tardis{\{}{\_}{\}}usenix12.pdf$\backslash$nhttps://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final71.pdf},
year = {2012}
}
@article{Somorovsky2012,
abstract = {The Security Assertion Markup Language (SAML) is a widely adopted language for making security statements about subjects. It is a critical component for the develop- ment of federated identity deployments and Single Sign- On scenarios. In order to protect integrity and authentic- ity of the exchanged SAML assertions, the XML Signa- ture standard is applied. However, the signature verifica- tion algorithm is much more complex than in traditional signature formats like PKCS{\{}{\#}{\}}7. The integrity protection can thus be successfully circumvented by application of different XML Signature specific attacks, under a weak adversarial model. In this paper we describe an in-depth analysis of 14 major SAML frameworks and show that 11 of them, including Salesforce, Shibboleth, and IBM XS40, have critical XML Signature wrapping (XSW) vulnerabilities. Based on our analysis, we developed an automated pen- etration testing tool for XSW in SAML frameworks. Its feasibility was proven by additional discovery of a new XSW variant. We propose the first framework to an- alyze such attacks, which is based on the information flow between two components of the Relying Party. Sur- prisingly, this analysis also yields efficient and practical countermeasures.},
author = {Somorovsky, Juraj and Mayer, Andreas},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {16},
title = {{On Breaking SAML: Be Whoever You Want to Be.}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final91-8-23-12.pdf},
year = {2012}
}
@article{Jang2012,
author = {Jang, Dongseok and Tatlock, Zachary and Lerner, Sorin},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {8},
title = {{Establishing browser security guarantees through formal shim verification}},
url = {http://dl.acm.org/citation.cfm?id=2362801$\backslash$npapers2://publication/uuid/05BF6374-AECA-4ACE-B4E8-B4EE616BFDA8},
year = {2012}
}
@article{Cui2012,
author = {Cui, Weidong and Peinado, Marcus and Xu, Zhilei and Chan, Ellick},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {601--615},
title = {{Tracking Rootkit Footprints with a Practical Memory Analysis System}},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/cui},
year = {2012}
}
@article{,
journal = {usenix security},
title = {{Privacy Enhancing Technologies and Network Traffic Analysis Throttling Tor Bandwidth Parasites}},
year = {2012}
}
@article{Xu2012,
abstract = {We explore the robustness and usability of moving-image object recognition (video) captchas, designing and implementing auto- mated attacks based on computer vision techniques. Our approach is suitable for broad classes of moving-image captchas involving rigid ob- jects.We first present an attack that defeats instances of such a captcha (NuCaptcha) representing the state-of-the-art, involving dynamic text strings called codewords. We then consider design modifications to mitigate the attacks (e.g., overlapping characters more closely, randomly changing the font of individual characters, or even randomly varying the number of characters in the codeword). We implement the modified captchas and test if designs modified for greater robustness maintain usability. Our lab-based studies show that the modified captchas fail to offer viable usability, even when the captcha strength is reduced below acceptable targets. Worse yet, our GPU-based implementation shows that our automated approach can decode these captchas faster than hu- mans can, and we can do so at a relatively low cost of roughly 50 cents per 1000 captchas solved based on Amazon EC2 rates circa 2012. To further demonstrate the challenges in designing usable captchas, we also implement and test another variant of moving text strings using the known emerging images concept. This variant is resilient to our attacks and also offers similar usability to commercially available approaches. We explain why fundamental elements of the emerging images idea resist our current attack where others fail.},
author = {Xu, Y and Reynaga, G and Chiasson, Sonia and Frahm, J-m and Monrose, Fabian and van Oorschot, Paul},
doi = {10.1109/TDSC.2013.52},
isbn = {978-931971-95-9},
issn = {1545-5971},
journal = {usenix security},
keywords = {CAPTCHAs,computer vision,security,usability},
pages = {49--64},
title = {{Security and Usability Challenges of Moving-Object CAPTCHAs: Decoding Codewords in Motion}},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/xu{\{}{\_}{\}}y},
year = {2012}
}
@article{Antonakakis2012,
author = {Antonakakis, Manos and Perdisci, Roberto and Nadji, Yacin and Vasiloglou, Nikolaos and Abu-Nimeh, Saeed and Lee, Wenke and Dagon, David},
journal = {usenix security},
pages = {1--16},
title = {{From Throw-Away Traffic to Bots: Detecting the Rise of DGA-Based Malware}},
url = {http://www.google.co.kr/url?sa=t{\{}{\&}{\}}rct=j{\{}{\&}{\}}q={\{}{\&}{\}}esrc=s{\{}{\&}{\}}source=web{\{}{\&}{\}}cd=2{\{}{\&}{\}}ved=0CDcQFjAB{\{}{\&}{\}}url=http://roberto.perdisci.com/publications/publication-files/USENIX-NXD.pdf{\{}{\&}{\}}ei=21zxT7XSEKeviQeEqsiRDQ{\{}{\&}{\}}usg=AFQjCNFd{\{}{\_}{\}}MBH3GFUVy94zoyi{\{}{\_}{\}}AHe4i3FuA{\{}{\&}{\}}sig2=5FRT},
year = {2012}
}
@article{Vijayakumar2012,
author = {Vijayakumar, Hayawardh and Schiffman, Joshua and Jaeger, Trent},
isbn = {978-931971-95-9},
journal = {usenix security},
title = {{STING : Finding Name Resolution Vulnerabilities in Programs}},
year = {2012}
}
@article{Maurer2012,
author = {Maurer, Matthew and Brumley, David},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {617--630},
title = {{Tachyon: Tandem Execution for Efficient Live Patch Testing}},
url = {https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/maurer},
year = {2012}
}
@article{Xu2012a,
abstract = {The increasing popularity of Google’s mobile platform Android makes it the prime target of the latest surge in mobile malware. Most research on enhancing the platform’s security and privacy controls requires extensive modification to the operating system, which has significant usability issues and hinders efforts for widespread adoption. We develop a novel solution called Aurasium that bypasses the need to modify the Android OS while providing much of the security and privacy that users de- sire. We automatically repackage arbitrary applications to attach user-level sandboxing and policy enforcement code, which closely watches the application’s behavior for security and privacy violations such as attempts to retrieve a user’s sensitive information, send SMS covertly to premium numbers, or access malicious IP addresses. Aurasium can also detect and prevent cases of privilege escalation attacks. Experiments show that we can apply this solution to a large sample of benign and malicious applications with a near 100 percent success rate, with- out significant performance and space overhead. Aura- sium has been tested on three versions of the Android OS, and is freely available.},
author = {Xu, Rubin and Sa{\"{\i}}di, Hassen and Anderson, Ross and Saıdi, Hassen},
file = {:home/hero/documents/mendeley/2012 - Aurasium Practical Policy Enforcement for Android Applications.pdf:pdf},
isbn = {978-931971-95-9},
journal = {usenix security},
month = {aug},
pages = {27},
title = {{Aurasium: Practical Policy Enforcement for Android Applications}},
url = {https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final60.pdf$\backslash$nhttp://dl.acm.org/citation.cfm?id=2362793.2362820},
year = {2012}
}
@article{Yan2012,
abstract = {The prevalence of mobile platforms, the large market share of Android, plus the openness of the Android Mar- ket makes it a hot target for malware attacks. Once a mal- ware sample has been identified, it is critical to quickly reveal its malicious intent and inner workings. In this paper we present DroidScope, an Android analysis plat- form that continues the tradition of virtualization-based malware analysis. Unlike current desktop malware anal- ysis platforms, DroidScope reconstructs both the OS- level and Java-level semantics simultaneously and seam- lessly. To facilitate custom analysis, DroidScope ex- ports three tiered APIs that mirror the three levels of an Android device: hardware, OS and Dalvik Virtual Ma- chine. On top of DroidScope, we further developed sev- eral analysis tools to collect detailed native and Dalvik instruction traces, profile API-level activity, and track in- formation leakage through both the Java and native com- ponents using taint analysis. These tools have proven to be effective in analyzing realworld malware samples and incur reasonably low performance overheads.},
author = {Yan, Lk and Yin, H},
doi = {10.1016/B978-1-59749-305-5.00006-2},
file = {:home/hero/documents/mendeley/2012 - DroidScope Seamlessly Reconstructing the OS and Dalvik Semantic Views for Dynamic Android Malware Analysis.pdf:pdf},
isbn = {978-931971-95-9},
journal = {usenix security},
pages = {145--189},
title = {{DroidScope: Seamlessly Reconstructing the OS and Dalvik Semantic Views for Dynamic Android Malware Analysis}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9781597493055000062 https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final107.pdf$\backslash$nhttp://dl.acm.org/citation.cfm?id=2362793.2362822},
year = {2012}
}
@article{Wustrow2011,
abstract = {In this paper, we present Telex, a new approach to resisting state-level Internet censorship. Rather than at- tempting to win the cat-and-mouse game of finding open proxies, we leverage censors unwillingness to completely block day-to-day Internet access. In effect, Telex converts innocuous, unblocked websites into proxies, without their explicit collaboration. We envision that friendly ISPs would deploy Telex stations on paths between censors networks and popular, uncensored Internet destinations. Telex stations would monitor seemingly innocuous flows for a special tag and transparently divert them to a for- bidden website or service instead. We propose a new cryptographic scheme based on elliptic curves for tagging TLS handshakes such that the tag is visible to a Telex station but not to a censor. In addition, we use our tagging scheme to build a protocol that allows clients to connect to Telex stations while resisting both passive and active at- tacks. We also present a proof-of-concept implementation that demonstrates the feasibility of our system. 1 Introduction The events of the Arab Spring have vividly demonst},
author = {Wustrow, Eric},
doi = {10.1016/j.mib.2007.05.002},
issn = {13695274},
journal = {usenix security},
number = {August},
pages = {1--15},
title = {{Telex : Anticensorship in the Network Infrastructure}},
url = {http://scholar.google.com/scholar?hl=en{\{}{\&}{\}}btnG=Search{\{}{\&}{\}}q=intitle:Telex+:+Anticensorship+in+the+Network+Infrastructure{\{}{\#}{\}}0},
volume = {10},
year = {2011}
}
@article{Meiklejohn2011,
abstract = {In recent years, privacy-preserving toll collection has been proposed as a way to resolve the tension between the de- sire for sophisticated road pricing schemes and drivers interest in maintaining the privacy of their driving pat- terns. Two recent systems in particular, VPriv (USENIX Security 2009) and PrETP (USENIX Security 2010), use modern cryptographic primitives to solve this problem. In order to keep drivers honest in paying for their usage of the roads, both systems rely on unpredictable spot checks (e.g., by hidden roadside cameras or roaming police vehi- cles) to catch potentially cheating drivers. In this paper we identify large-scale driver collusion as a threat to the necessary unpredictability of these spot checks. Most directly, the VPriv and PrETP audit pro- tocols both reveal to drivers the locations of spot-check camerasinformation that colluding drivers can then use to avoid paying road fees. We describe Milo, a new privacy-preserving toll collection system based on PrETP, whose audit protocol does not have this information leak, even when drivers misbehave and collude. We then evalu- ate the additional cost of Milo and find that, when com- pared to na{\{}{\"{\i}}{\}}ve methods to protect against cheating drivers, Milo offers a significantly more cost-effective approach.},
author = {Meiklejohn, Sarah and Mowery, Keaton and Checkoway, Stephen and Shacham, Hovav},
journal = {usenix security},
pages = {491--506},
title = {{The Phantom Tollbooth : Privacy-Preserving Electronic Toll Collection in the Presence of Driver Collusion}},
url = {http://cseweb.ucsd.edu/users/smeiklejohn/files/usenix11.pdf},
year = {2011}
}
@article{Hooimeijer2011,
abstract = {Web applications often use special string-manipulating sanitizers on untrusted user data, but it is difficult to reason manually about the behavior of these functions, leading to errors. For example, the Internet Explorer cross-site scripting filter turned out to transform some web pages without JavaScript into web pages with valid Java-Script, enabling attacks. In other cases, sanitizers may fail to commute, rendering one order of application safe and the other dangerous. BEK is a language and system for writing sanitizers that enables precise analysis of sanitizer behavior, including checking idempotence, commutativity, and equivalence. For example, BEK can determine if a target string, such as an entry on the XSS Cheat Sheet, is a valid output of a sanitizer. If so, our analysis synthesizes an input string that yields that target. Our language is expressive enough to capture real web sanitizers used in ASP.NET, the Internet Explorer XSS Filter, and the Google AutoEscape framework, which we demonstrate by porting these sanitizers to BEK. Our analyses use a novel symbolic finite automata representation to leverage fast satisfiability modulo theories (SMT) solvers and are quick in practice, taking fewer than two seconds to check the commutativity of the entire set of Internet Exporer XSS filters, between 36 and 39 seconds to check implementations of HTMLEncode against target strings from the XSS Cheat Sheet, and less than ten seconds to check equivalence between all pairs of a set of implementations of HTMLEncode. Programs written in BEK can be compiled to traditional languages such as JavaScript and C{\{}{\#}{\}}, making it possible for web developers to write sanitizers supported by deep analysis, yet deploy the analyzed code directly to real applications.},
author = {Hooimeijer, Pieter and Livshits, Benjamin and Molnar, David and Saxena, Prateek and Veanes, Margus},
doi = {10.1.1.220.7309},
journal = {usenix security},
pages = {1--16},
title = {{Fast and Precise Sanitizer Analysis with BEK}},
url = {http://static.usenix.org/events/sec11/tech/full{\{}{\_}{\}}papers/Hooimeijer.pdf},
year = {2011}
}
@article{Motoyama2011,
abstract = {Modern Web services inevitably engender abuse, as attackers find ways to exploit a service and its user base. However, while defending against such abuse is generally considered a technical endeavor, we argue that there is an increasing role played by human labor markets. Using over seven years of data from the popular crowd-sourcing site Freelancer.com, as well data from our own active job solicitations, we characterize the labor market involved in service abuse. We identify the largest classes of abuse work, including account creation, social networking link generation and search engine optimization support, and characterize how pricing and demand have evolved in supporting this activity.},
author = {Motoyama, Marti and McCoy, Damon and Levchenko, Kirill and Savage, Stefan and Voelker, Geoffrey M},
journal = {usenix security},
pages = {14},
title = {{Dirty Jobs: The Role of Freelance Labor in Web Service Abuse}},
url = {http://dl.acm.org/citation.cfm?id=2028081},
year = {2011}
}
@article{Mittal2011,
abstract = {Existing anonymous communication systems like Tor do not scale well as they require all users to maintain up-to-date information about all available Tor relays in the system. Current proposals for scaling anonymous communication advocate a peer-to-peer (P2P) approach. While the P2P paradigm scales to millions of nodes, it provides new opportunities to compromise anonymity. In this paper, we step away from the P2P paradigm and advocate a client-server approach to scalable anonymity. We propose PIR-Tor, an architecture for the Tor network in which users obtain information about only a few onion routers using private information retrieval techniques. Obtaining information about only a few onion routers is the key to the scalability of our approach, while the use of private retrieval information techniques helps preserve client anonymity. The security of our architecture depends on the security of PIR schemes which are well understood and relatively easy to analyze, as opposed to peer-to-peer designs that require analyzing extremely complex and dynamic systems. In particular, we demonstrate that reasonable parameters of our architecture provide equivalent security to that of the Tor network. Moreover, our experimental results show that the overhead of PIR-Tor is manageable even when the Tor network scales by two orders of magnitude.},
author = {Mittal, Prateek and Olumofin, Femi and Troncoso, Carmela and Borisov, Nikita and Goldberg, Ian},
journal = {usenix security},
title = {{PIR-Tor: Scalable Anonymous Communication Using Private Information Retrieval}},
url = {http://www.usenix.org/events/sec/tech/full{\{}{\_}{\}}papers/Mittal.pdf},
year = {2011}
}
@article{Jacob2011,
abstract = {A dis­tin­gu­is­hing cha­rac­te­ris­tic of a bot is its abi­li­ty to es­ta­blish a com­mand and con­trol (C{\{}{\&}{\}}C) chan­nel. The ty­pi­cal ap­proach to build de­tec­tion mo­dels for C{\{}{\&}{\}}C traf­fic and to iden­ti­fy C{\{}{\&}{\}}C end­points (IPs and do­mains of C{\{}{\&}{\}}C ser­vers) is to exe­cu­te a bot in a con­trol­led en­vi­ron­ment and mo­ni­tor its out­go­ing net­work con­nec­tions. Using the bot traf­fic, one can then craft si­gna­tu­res that match C{\{}{\&}{\}}C con­nec­tions or black­list the IPs or do­mains that the pa­ckets are sent to. Un­for­t­u­n­a­te­ly, this pro­cess is not as easy as it seems. For ex­amp­le, bots often open a large num­ber of ad­di­tio­nal con­nec­tions to le­gi­ti­ma­te sites (to per­form click fraud or to query for the cur­rent time), and a bot can de­li­be­ra­te­ly pro­du­ce "noise" – bogus con­nec­tions that make the ana­ly­sis more dif­fi­cult. Thus, be­fo­re one can build a model for C{\{}{\&}{\}}C traf­fic or black­list IPs/do­mains, one first has to pick the C{\{}{\&}{\}}C con­nec­tions among all the net­work traf­fic that a bot pro­du­ces. In this paper, we pre­sent JACK­STRAWS, a sys­tem that ac­cu­ra­te­ly iden­ti­fies C{\{}{\&}{\}}C con­nec­tions. To this end, we le­ver­a­ge host-ba­sed in­for­ma­ti­on that pro­vi­des in­sights into which data is sent over each net­work con­nec­tion as well as the ways in which a bot pro­ces­ses in­for­ma­ti­on that it re­cei­ves. More pre­cise­ly, we as­so­cia­te with each net­work con­nec­tion a be­ha­vi­or graph that cap­tu­res the sys­tem calls that lead to a net­work con­nec­tion, as well as the sys­tem calls that ope­ra­te on data that is re­tur­ned. By using ma­chi­ne le­arning tech­ni­ques and a trai­ning set of graphs that are as­so­cia­ted with known C{\{}{\&}{\}}C con­nec­tions, we au­to­ma­ti­cal­ly extract and ge­ne­ra­li­ze graph tem­pla­tes that cap­tu­re the core of dif­fe­rent types of C{\{}{\&}{\}}C ac­tivi­ty. Later, we can use these C{\{}{\&}{\}}C tem­pla­tes to match against be­ha­vi­or graphs pro­du­ced by other bots. Our re­sults show that JACK­STRAWS can ac­cu­ra­te­ly de­tect C{\{}{\&}{\}}C con­nec­tions, even for novel bot fa­mi­lies that were not used for tem­pla­te ge­ne­ra­ti­on.},
author = {Jacob, Gregoire and Hund, Ralf and Bochum, Ruhr-university and Kruegel, Christopher and Holz, Thorsten},
journal = {usenix security},
pmid = {11553279},
title = {{JACKSTRAWS : Picking Command and Control Connections from Bot Traffic}},
year = {2011}
}
@article{Sun2011,
abstract = {Access control vulnerabilities, which cause privilege escalations, are among the most dangerous vulnerabilities in web applications. Unfortunately, due to the difficulty in designing and implementing perfect access checks, web applications often fall victim to access control attacks. In contrast to traditional injection flaws, access control vulnerabilities are application-specific, rendering it challenging to obtain precise specifications for static and runtime enforcement. On one hand, writing specifications manually is tedious and time-consuming, which leads to non-existent, incomplete or erroneous specifications. On the other hand, automatic probabilistic-based specification inference is imprecise and computationally expensive in general. This paper describes the first static analysis that automatically detects access control vulnerabilities in web applications. The core of the analysis is a technique that statically infers and enforces implicit access control assumptions. Our insight is that source code implicitly documents intended accesses of each role and any successful forced browsing to a privileged page is likely a vulnerability. Based on this observation, our static analysis constructs sitemaps for different roles in a web application, compares per-role sitemaps to find privileged pages, and checks whether forced browsing is successful for each privileged page. We implemented our analysis and evaluated our tool on several real-world web applications. The evaluation results show that our tool is scalable and detects both known and new access control vulnerabilities with few false positives.},
author = {Sun, F and Xu, L and Su, Z},
journal = {usenix security},
title = {{Static Detection of Access Control Vulnerabilities in Web Applications.}},
url = {http://static.usenix.org/event/sec11/tech/full{\{}{\_}{\}}papers/Sun.pdf},
year = {2011}
}
@article{Mulazzani2011,
abstract = {During the past few years, a vast number of online file storage services have been introduced. While several of these services provide basic functionality such as upload- ing and retrieving files by a specific user, more advanced services offer features such as shared folders, real-time collaboration, minimization of data transfers or unlim- ited storage space. Within this paper we give an overview of existing file storage services and examine Dropbox, an advanced file storage solution, in depth. We analyze the Dropbox client software as well as its transmission protocol, show weaknesses and outline possible attack vectors against users. Based on our results we show that Dropbox is used to store copyright-protected files from a popular filesharing network. Furthermore Dropbox can be exploited to hide files in the cloud with unlimited stor- age capacity. We define this as online slack space. We conclude by discussing security improvements for mod- ern online storage services in general, and Dropbox in particular. To prevent our attacks cloud storage opera- tors should employ data possession proofs on clients, a technique which has been recently discussed only in the context of assessing trust in cloud storage operators.},
author = {Mulazzani, Martin and Schrittwieser, Sebastian and Weippl, Edgar and Leithner, Manuel and Huber, Markus},
journal = {usenix security},
pages = {11},
title = {{Dark Clouds on the Horizon : Using Cloud Storage as Attack Vector and Online Slack Space}},
url = {http://research.securityresearch.at/wp-content/uploads/publications/dropboxUSENIX2011.pdf},
volume = {8},
year = {2011}
}
@article{Kanich2011,
author = {Kanich, Chris and Weavery, Nicholas and McCoy, Damon and Halvorson, Tristan and Kreibichy, Christian and Levchenko, Kirill and Paxson, Vern and Voelker, Geoffrey M and Savage, Stefan},
journal = {usenix security},
pages = {15},
title = {{Show Me the Money: Characterizing Spam-advertised Revenue}},
year = {2011}
}
@article{VanDeursen2011,
author = {van Deursen, T and Mauw, S and Radomirovi{\'{c}}, S},
journal = {usenix security},
pages = {107--121},
title = {{m{\{}{\{}{\}}C{\{}{\}}{\}}arve: {\{}{\{}{\}}C{\{}{\}}{\}}arving attributed dump sets}},
year = {2011}
}
@article{Checkoway2011,
abstract = {Modern automobiles are pervasively computerized, and hence potentially vulnerable to attack. However, while previous research has shown that the internal networks within some modern cars are insecure, the associated threat model requiring prior physical access has justifiably been viewed as unrealistic. Thus, it remains an open question if automobiles can also be susceptible to remote compromise. Our work seeks to put this question to rest by systematically analyzing the external attack surface of a modern automobile. We discover that remote exploitation is feasible via a broad range of attack vectors (including mechanics tools, CD players, Bluetooth and cellular radio), and further, that wireless communications channels allow long distance vehicle control, location tracking, in-cabin audio exfiltration and theft. Finally, we discuss the structural characteristics of the automotive ecosystem that give rise to such problems and highlight the practical challenges in mitigating them.},
author = {Checkoway, Stephen and Mccoy, Damon and Kantor, Brian and Anderson, Danny and Shacham, Hovav and Savage, Stefan and Koscher, Karl and Czeskis, Alexei and Roesner, Franziska and Kohno, Tadayoshi},
journal = {usenix security},
pages = {6},
title = {{Comprehensive Experimental Analyses of Automotive Attack Surfaces}},
url = {http://www.usenix.org/events/security/tech/full{\{}{\_}{\}}papers/Checkoway.pdf},
year = {2011}
}
@article{Gollakota2011,
abstract = {This paper presents the first wireless pairing protocol that works in- band , with no pre-shared keys, and protects against MITM attacks. The main innovation is a new key exchange message constructed in a manner that ensures an adversary can neither hide the fact that a ...},
author = {Gollakota, S and Ahmed, N},
journal = {usenix security},
title = {{Secure in-band wireless pairing}},
url = {http://people.csail.mit.edu/nickolai/papers/gollakota-tep.pdf$\backslash$npapers2://publication/uuid/AEE90464-B382-4169-BCE3-FEA6A8568807},
year = {2011}
}
@article{Schwartz2011,
abstract = {Prior work has shown that return oriented programming (ROP) can be used to bypass WX, a software defense that stops shellcode, by reusing instructions from large libraries such as libc. Modern operating systems have since enabled address randomization (ASLR), which randomizes the location of libc, making these techniques unusable in practice. However, modern ASLR implementations leave smaller amounts of executable code unrandomized and it has been unclear whether an attacker can use these small code fragments to construct payloads in the general case. In this paper, we show defenses as currently deployed can be bypassed with new techniques for automatically creating ROP payloads from small amounts of unrandomized code. We propose using semantic program verification techniques for identifying the functionality of gadgets, and design a ROP compiler that is resistant to missing gadget types. To demonstrate our techniques, we build Q, an end-to-end system that automatically generates ROP payloads for a given binary. Q can produce payloads for 80{\{}{\%}{\}} of Linux /usr/bin programs larger than 20KB. We also show that Q can automatically perform exploit hardening: given an exploit that crashes with defenses on, Q outputs an exploit that bypasses both WX and ASLR. We show that Q can harden nine real-world Linux and Windows exploits, enabling an attacker to automatically bypass defenses as deployed by industry for those programs.},
author = {Schwartz, Ej and Avgerinos, Thanassis and Brumley, David},
doi = {10.1016/j.coph.2007.12.010},
isbn = {1471-4892},
issn = {14714892},
journal = {usenix security},
number = {3},
pages = {25},
pmid = {18243052},
title = {{Q: Exploit hardening made easy}},
url = {http://www.usenix.org/event/sec11/tech/full{\{}{\_}{\}}papers/Schwartz.pdf},
volume = {8},
year = {2011}
}
@article{Walls2011,
abstract = {We present DEC0DE, a system for recovering information from phones with unknown storage formats, a critical problem for forensic triage. Because phones have myriad custom hardware and software, we examine only the stored data. Via flexible descriptions of typical data structures, and using a classic dynamic programming algorithm, we are able to identify call logs and address book entries in phones across varied models and manufacturers. We designed DEC0DE by examining the formats of one set of phone models, and we evaluate its performance on other models. Overall, we are able to obtain high performance for these unexamined models: an average recall of 97{\{}{\%}{\}} and precision of 80{\{}{\%}{\}} for call logs; and average recall of 93{\{}{\%}{\}} and precision of 52{\{}{\%}{\}} for address books. Moreover, at the expense of recall dropping to 14{\{}{\%}{\}}, we can increase precision of address book recovery to 94{\{}{\%}{\}} by culling results that don't match between call logs and address book entries on the same phone.},
author = {Walls, Robert J and Learned-Miller, Erik and Levine, Brian Neil},
journal = {usenix security},
pages = {7},
title = {{Forensic Triage for Mobile Phones with DEC0DE}},
url = {http://dl.acm.org/citation.cfm?id=2028067.2028074},
year = {2011}
}
@article{Cho2011,
abstract = {Programstate-space exploration is central to software security, testing, and verification. In this paper, we propose a novel technique for state-space exploration of software that maintains an ongoing interaction with its environment. Our technique uses a combination of symbolic and concrete execution to build an abstract model of the analyzed application, in the form of a finite-state automaton, and uses the model to guide further state-space exploration. Through exploration, MACE further refines the abstract model. Using the abstract model as a scaffold, our technique wields more control over the search process. In particular: (1) shifting search to different parts of the search-space becomes easier, resulting in higher code coverage, and (2) the search is less likely to get stuck in small local state-subspaces (e.g., loops) irrelevant to the application's interaction with the environment. Preliminary experimental results show significant increases in the code coverage and exploration depth. Further, our approach found a number of new deep vulnerabilities.},
author = {Cho, C Y and Babic, D and Poosankam, P and Chen, K Z and Wu, E X J and Song, D},
journal = {usenix security},
pages = {10},
title = {{MACE: model-inference-assisted concolic exploration for protocol and vulnerability discovery}},
url = {https://www.usenix.org/events/sec11/tech/full{\{}{\_}{\}}papers/Cho.pdf$\backslash$npapers2://publication/uuid/B6E55BA7-E623-4BBF-9AF0-234DC4627A34},
year = {2011}
}
@article{Green2011,
abstract = {Attribute-based encryption (ABE) is a new vision for public key encryption that allows users to encrypt and decrypt messages based on user attributes. For example, a user can create a ciphertext that can be decrypted only by other users with attributes satisfying ("Faculty" OR ("PhD Student" AND "Quals Completed")). Given its expressiveness, ABE is currently being considered for many cloud storage and computing applications. However, one of the main efficiency drawbacks of ABE is that the size of the ciphertext and the time required to decrypt it grows with the complexity of the access formula. In this work, we propose a new paradigm for ABE that largely eliminates this overhead for users. Suppose that ABE ciphertexts are stored in the cloud. We show how a user can provide the cloud with a single transformation key that allows the cloud to translate any ABE ciphertext satisfied by that user's attributes into a (constant-size) El Gamal-style ciphertext, without the cloud being able to read any part of the user's messages. To precisely define and demonstrate the advantages of this approach, we provide new security definitions for both CPA and replayable CCA security with outsourcing, several new constructions, an implementation of our algorithms and detailed performance measurements. In a typical configuration, the user saves significantly on both bandwidth and decryption time, without increasing the number of transmissions.},
author = {Green, Matthew and Hohenberger, Susan and Waters, Brent},
journal = {usenix security},
pages = {34},
title = {{Outsourcing the Decryption of ABE Ciphertexts}},
year = {2011}
}
@article{Politz2011,
abstract = {Web sites routinely incorporate JavaScript programs from several sources into a single page. These sources must be protected from one another, which requires robust sandboxing. The many entry-points of sandboxes and the subtleties of JavaScript demand},
author = {Politz, Joe Gibbs and Eliopoulos, Spiridon Aristides and Guha, Arjun and Krishnamurthi, Shriram},
doi = {10.1145/2420950.2420952},
isbn = {9781450313124},
journal = {usenix security},
title = {{ADsafety: type-based verification of JavaScript Sandboxing}},
url = {http://portal.acm.org/citation.cfm?id=2028067.2028079{\{}{\&}{\}}coll=DL{\{}{\&}{\}}dl=GUIDE{\{}{\&}{\}}CFID=175250063{\{}{\&}{\}}CFTOKEN=64334255$\backslash$npapers2://publication/uuid/5667537F-F445-4FC9-B777-0D18B5352D24},
year = {2011}
}
@article{Haeberlen2011,
author = {Haeberlen, Andreas and Pierce, Benjamin C and Narayan, Arjun},
journal = {usenix security},
pages = {33},
title = {{Differential privacy under fire}},
url = {http://dl.acm.org/citation.cfm?id=2028067.2028100},
year = {2011}
}
@article{Caballero2011,
abstract = {Recent years have seen extensive diversification of the underground economy associated with malware and the subversion of Internet-connected systems. This trend to- wards specialization has compelling forces driving it: mis- creants readily apprehend that tackling the entire value-chain from malware creation to monetization in the presence of ever-evolving countermeasures poses a daunting task requir- ing highly developed skills and resources. As a result, entrepreneurial-minded miscreants have formed pay-per-install (PPI) servicesspecialized organizations that focus on the in- fection of victims systems. In this work we perform a measurement study of the PPI market by infiltrating four PPI services. We develop infrastruc- ture that enables us to interact with PPI services and gather and classify the resulting malware executables distributed by the services. Using our infrastructure, we harvested over a million client executables using vantage points spread across 15 coun- tries. We find that of the worlds top 20 most prevalent fami- lies of malware, 12 employ PPI services to buy infections. In addition we analyze the targeting of specific countries by PPI clients, the repacking of executables to evade detection, and the duration of malware distribution.},
author = {Caballero, Juan and Grier, Chris and Kreibich, Christian and Paxson, Vern and Berkeley, U C},
isbn = {9781450310000},
journal = {usenix security},
pages = {13},
title = {{Measuring Pay-per-Install : The Commoditization of Malware Distribution}},
url = {http://www.icir.org/vern/papers/ppi-usesec11.pdf$\backslash$nhttps://www.usenix.org/legacy/events/sec11/tech/full{\{}{\_}{\}}papers/Caballero.pdf},
year = {2011}
}
@article{Stringhini2011,
abstract = {Unsolicited bulk email (spam) is used by cybercriminals to lure users into scams and to spread malware infections. Most of these unwanted messages are sent by spam botnets, which are networks of compromised machines under the control of a single (malicious) entity. Often, these botnets are rented out to particular groups to carry out spam campaigns, in which similar mail messages are sent to a large group of Internet users in a short amount of time. Tracking the bot-infected hosts that participate in spam campaigns, and attributing these hosts to spam botnets that are active on the Internet, are challenging but important tasks. In particular, this information can improve blacklist-based spam defenses and guide botnet mitigation efforts. In this paper, we present a novel technique to support the identiﬁcation and tracking of bots that send spam. Our technique takes as input an initial set of IP addresses that are known to be associated with spam bots, and learns their spamming behavior. This initial set is then “magniﬁed” by analyzing large-scale mail delivery logs to identify other hosts on the Internet whose behavior is similar to the behavior previously modeled. We implemented our technique in a tool, called BOTMAGNIFIER, and applied it to several data streams related to the delivery of email trafﬁc. Our results show that it is possible to identify and track a substantial number of spam bots by using our magniﬁcation technique. We also perform attribution of the identiﬁed spam hosts and track the evolution and activity of well-known spamming botnets over time. Moreover, we show that our results can help to improve state-of-the-art spam blacklist},
author = {Stringhini, Gianluca and Holz, Thorsten and Stone-gross, Brett},
journal = {usenix security},
title = {{BOTMAGNIFIER : Locating Spambots on the Internet}},
year = {2011}
}
@article{Calandrino2011,
abstract = {Fill-in-the-bubble forms are widely used for surveys, election ballots, and standardized tests. In these and other scenarios, use of the forms comes with an implicit assumption that individuals’ bubble markings them- selves are not identifying. This work challenges this assumption, demonstrating that fill-in-the-bubble forms could convey a respondent’s identity even in the absence of explicit identifying information. We develop methods to capture the unique features of a marked bubble and use machine learning to isolate characteristics indicative of its creator. Using surveys from more than ninety indi- viduals, we apply these techniques and successfully re- identify individuals from markings alone with over 50{\{}{\%}{\}} accuracy. This bubble-based analysis can have either positive or negative implications depending on the ap- plication. Potential applications range from detection of cheating on standardized tests to attacks on the secrecy of election ballots. To protect against negative conse- quences, we discuss mitigation techniques to remove a bubble’s identifying characteristics. We suggest addi- tional tests using longitudinal data and larger datasets to further explore the potential of our approach in real- world applications.},
author = {Calandrino, Joseph a. and Clarkson, William and Felten, Edward W},
journal = {usenix security},
pages = {267--280},
title = {{Bubble Trouble: Off-Line De-Anonymization of Bubble Forms}},
url = {http://www.usenix.org/events/sec11/tech/full{\{}{\_}{\}}papers/Calandrino.pdf},
year = {2011}
}
@article{Gourdin2011,
abstract = {We address the challenge of building secure embedded web interfaces by proposing WebDroid: the first framework specifically dedicated to this purpose. Our design extends the Android Framework, and enables developers to create easily secure web interfaces for their applications. To motivate ourwork, we perform an in-depth study of the security of web interfaces embedded in consumer electronics devices, uncover significant vulnerabilities in all the devices examined, and categorize the vulnerabilities. We demonstrate how our framework's security mechanisms prevent embedded applications from suffering the vulnerabilities exposed by our audit. Finally we evaluate the efficiency of our framework in terms of performance and security.},
author = {Gourdin, B and Soman, C},
journal = {usenix security},
title = {{Toward secure embedded web interfaces}},
url = {http://www.lsv.ens-cachan.fr/{\{}{~}{\}}gourdin/?l=fr$\backslash$nhttp://www.usenix.org/event/sec11/tech/full{\{}{\_}{\}}papers/Gourdin.pdf},
year = {2011}
}
@article{Muller2011,
abstract = {Current disk encryption techniques store necessary keys in RAM and are therefore susceptible to attacks that tar- get volatile memory, such as Firewire and cold boot at- tacks. We present TRESOR, a Linux kernel patch that implements the AES encryption algorithm and its key management solely on the microprocessor. Instead of us- ing RAM, TRESOR ensures that all encryption states as well as the secret key and any part of it are only stored in processor registers throughout the operational time of the system, thereby substantially increasing its security. Our solution takes advantage of Intel’s new AES-NI in- struction set and exploits the x86 debug registers in a non-standard way, namely as cryptographic key storage. TRESOR is compatible with all modern Linux distribu- tions, and its performance is on a par with that of stan- dard AES implementations.},
author = {M{\"{u}}ller, Tilo and Freiling, Felix C and Dewald, Andreas},
journal = {usenix security},
pages = {17},
title = {{TRESOR runs encryption securely outside RAM}},
url = {http://dl.acm.org/citation.cfm?id=2028067.2028084},
year = {2011}
}
@article{Felt2011,
author = {Felt, Adrienne Porter and Wang, Helen J and Moshchuk, Alexander and Hanna, Steve and Chin, Erika},
journal = {usenix security},
title = {{Permission Re-Delegation: Attacks and Defenses.}},
year = {2011}
}
@article{Curtsinger2011,
abstract = {JavaScript malware-based attacks account for a large fraction of successful mass-scale exploitation happening today. Attackers like JavaScript-based attacks because they can be mounted against an unsuspecting user visit- ing a seemingly innocent web page. While several tech- niques for addressing these types of exploits have been proposed, in-browser adoption has been slow, in part be- cause of the performance overhead these methods incur. In this paper, we propose ZOZZLE, a low-overhead so- lution for detecting and preventing JavaScript malware that is fast enough to be deployed in the browser. Our approach uses Bayesian classification of hier- archical features of the JavaScript abstract syntax tree to identify syntax elements that are highly predictive of malware. Our experimental evaluation shows that ZOZZLE is able to detect JavaScript malware through mostly static code analysis effectively. ZOZZLE has an extremely low false positive rate of 0.0003{\{}{\%}{\}}, which is less than one in a quarter million. Despite this high ac- curacy, the ZOZZLE classifier is fast, with a throughput of over one megabyte of JavaScript code per second.},
author = {Curtsinger, Charlie and Livshits, Benjamin and Zorn, Benjamin and Seifert, Christian},
journal = {usenix security},
pages = {3},
title = {{ZOZZLE: fast and precise in-browser JavaScript malware detection}},
url = {http://dl.acm.org.oca.korea.ac.kr/citation.cfm?id=2028067.2028070},
year = {2011}
}
@article{Huang2011,
author = {Huang, Yan and Evans, David and Katz, Jonathan and Malka, Lior},
journal = {usenix security},
pages = {35},
title = {{Faster secure two-party computation using garbled circuits}},
url = {http://dl.acm.org/citation.cfm?id=2028067.2028102},
year = {2011}
}
@article{Leontiadis2011,
abstract = {We investigate the manipulation of web search re- sults to promote the unauthorized sale of prescription drugs. We focus on search-redirection attacks, where miscreants compromise high-ranking websites and dy- namically redirect traffic to different pharmacies based upon the particular search terms issued by the consumer. We constructed a representative list of 218 drug-related queries and automatically gathered the search results on a daily basis over nine months in 2010-2011. We find that about one third of all search results are one of over 7000 infected hosts triggered to redirect to a few hundred pharmacy websites. Legitimate pharmacies and health resources have been largely crowded out by search-redirection attacks and blog spam. Infections per- sist longest on websites with high PageRank and from .edu domains. 96{\{}{\%}{\}} of infected domains are connected through traffic redirection chains, and network analysis reveals that a few concentrated communities link many otherwise disparate pharmacies together. We calculate that the conversion rate of web searches into sales lies between 0.3{\{}{\%}{\}} and 3{\{}{\%}{\}}, and that more illegal drugs sales are facilitated by search-redirection attacks than by email spam. Finally, we observe that concentration in both the source infections and redirectors presents an opportunity for defenders to disrupt online pharmacy sales.},
author = {Leontiadis, Nektarios and Moore, Tyler and Christin, Nicolas},
journal = {usenix security},
pages = {1--17},
title = {{Measuring and Analyzing Search-Redirection Attacks in the Illicit Online Prescription Drug Trade}},
url = {http://www.securityvibes.com/servlet/JiveServlet/previewBody/1383-102-1-1388/usenix11.pdf},
year = {2011}
}
@article{Mulliner2011,
abstract = {Mobile communication is an essential part of our daily lives. Therefore, it needs to be secure and reliable. In this paper, we study the security of feature phones, the most common type of mobile phone in the world. We built a framework to analyze the security of SMS clients of feature phones. The framework is based on a small GSM base station, which is readily available on the market. Through our analysis we discovered vulnerabilities in the feature phone platforms of all major manufacturers. Using these vulnerabilities we designed attacks against end-users as well as mobile operators. The threat is serious since the attacks can be used to prohibit communication on a large scale and can be carried out from anywhere in the world. Through further analysis we determined that such attacks are amplified by certain configurations of the mobile network. We conclude our research by providing a set of countermeasures.},
author = {Mulliner, Collin and Golde, Nico and Seifert, Jp},
journal = {usenix security},
title = {{SMS of Death: from analyzing to attacking mobile phones on a large scale}},
url = {http://static.usenix.org/events/sec11/tech/full{\{}{\_}{\}}papers/Mulliner.pdf},
year = {2011}
}
@article{Antonakakis2011,
abstract = {In recent years Internet miscreants have been leveraging the DNS to build malicious network infrastructures for malware command and control. In this paper we pro- pose a novel detection system called Kopis for detecting malware-related domain names. Kopis passively moni- tors DNS traffic at the upper levels of the DNS hierar- chy, and is able to accurately detect malware domains by analyzing global DNS query resolution patterns.Compared to previous DNS reputation systems such as Notos 3 and Exposure 4, which rely on monitor- ing traffic from local recursive DNS servers, Kopis offers a new vantage point and introduces new traffic features specifically chosen to leverage the global visibility ob- tained by monitoring network traffic at the upper DNS hi- erarchy. Unlike previous work Kopis enables DNS oper- ators to independently (i.e., without the need of data from other networks) detect malware domains within their au- thority, so that action can be taken to stop the abuse. Moreover, unlike previous work, Kopis can detect mal- ware domains even when no IP reputation information is available.We developed a proof-of-concept version of Kopis, and experimented with eight months of real-world data. Our experimental results show that Kopis can achieve high detection rates (e.g., 98.4{\{}{\%}{\}}) and low false positive rates (e.g., 0.3{\{}{\%}{\}} or 0.5{\{}{\%}{\}}). In addition Kopis is able to detect new malware domains days or even weeks before they appear in public blacklists and security forums, and allowed us to discover the rise of a previously unknown DDoS botnet based in China.},
author = {Antonakakis, Manos and Perdisci, Roberto and Lee, Wenke and Ii, Nikolaos Vasiloglou and Dagon, David},
journal = {usenix security},
pages = {1--16},
title = {{Detecting Malware Domains at the Upper DNS Hierarchy}},
volume = {11},
year = {2011}
}
@article{Dunn2011,
abstract = {The Trusted Platform Module (TPM) is commonly thought of as hardware that can increase platform security. However, it can also be used for malicious purposes. The TPM, along with other hardware, can implement a cloaked computation, whose memory state cannot be observed by any other software, including the operating system and hypervisor. We show that malware can use cloaked computations to hide essential secrets (like the target of an attack) from a malware analyst. We describe and implement a protocol that establishes an encryption key under control of the TPM that can only be used by a specific infection program. An infected host then proves the legitimacy of this key to a remote malware distribution platform, and receives and executes an encrypted payload in a way that prevents software visibility of the decrypted payload. We detail how malware can benefit from cloaked computations and discuss defenses against our protocol. Hardening legitimate uses of the TPM against attack improves the resilience of our malware, creating a Catch-22 for secure computing technology.},
author = {Dunn, Alan M and Hofmann, Owen S and Waters, Brent and Witchel, Emmett},
journal = {usenix security},
pages = {26},
title = {{Cloaking Malware with the Trusted Platform Module}},
year = {2011}
}
@article{Snow2011,
abstract = {The availability of off-the-shelf exploitation toolkits for compromising hosts, coupled with the rapid rate of exploit discovery and disclosure, has made exploit or vulnerability-based detection far less effective than it once was. For instance, the increasing use of metamorphic and polymorphic techniques to deploy code injection attacks continues to confound signature-based detection techniques. The key to detecting these attacks lies in the ability to discover the presence of the injected code (or, shellcode). One promising technique for doing so is to examine data (be that from network streams or buffers of a process) and efficiently execute its content to find what lurks within. Unfortunately, current approaches for achieving this goal are not robust to evasion or scalable, primarily because of their reliance on software-based CPU emulators. In this paper, we argue that the use of software-based emulation techniques are not necessary, and instead propose a new framework that leverages hardware virtualization to better enable the detection of code injection attacks. We also report on our experience using this framework to analyze a corpus of malicious Portable Document Format (PDF) files and network-based attacks.},
author = {Snow, Kevin Z and Krishnan, Srinivas and Monrose, Fabian and Provos, Niels},
journal = {usenix security},
pages = {9},
title = {{SHELL OS : Enabling Fast Detection and Forensic Analysis of Code Injection Attacks}},
url = {http://dl.acm.org/citation.cfm?id=2028067.2028076},
year = {2011}
}
@article{Clark2011,
abstract = {APCO Project 25 (P25) is a suite of wireless com- munications protocols used in the US and elsewhere for public safety two-way (voice) radio systems. The proto- cols include security options in which voice and data traf- fic can be cryptographically protected from eavesdrop- ping. This paper analyzes the security of P25 systems against both passive and active adversaries. We found a number of protocol, implementation, and user interface weaknesses that routinely leak information to a passive eavesdropper or that permit highly efficient and difficult to detect active attacks. We introduce new selective sub- frame jamming attacks against P25, in which an active attacker with very modest resources can prevent specific kinds of traffic (such as encrypted messages) from be- ing received, while emitting only a small fraction of the aggregate power of the legitimate transmitter. We also found that even the passive attacks represent a serious practical threat. In a study we conducted over a two year period in several US metropolitan areas, we found that a significant fraction of the encrypted P25 tactical ra- dio traffic sent by federal law enforcement surveillance operatives is actually sent in the clear, in spite of their users belief that they are encrypted, and often reveals such sensitive data as the names of informants in crimi- nal investigations.},
author = {Clark, Sandy and Xu, Kevin},
isbn = {9781931971874},
journal = {usenix security},
number = {August 10-12},
pages = {4},
title = {{Why ( Special Agent ) Johnny ( Still ) Can ’ t Encrypt : A Security Analysis of the APCO Project 25 Two-Way Radio System}},
url = {http://dl.acm.org/citation.cfm?id=2028071},
year = {2011}
}
@article{Dietz2011,
author = {Dietz, Michael and Shekhar, Shashi and Pisetsky, Yuliy and Shu, Anhei and Wallach, Dan S.},
journal = {usenix security},
month = {aug},
pages = {23},
title = {{Quire: lightweight provenance for smart phone operating systems}},
url = {http://dl.acm.org/citation.cfm?id=2028067.2028090},
year = {2011}
}
@article{Enck2011,
author = {Enck, William and Octeau, Damien and McDaniel, Patrick and Chaudhuri, Swarat},
journal = {usenix security},
month = {aug},
pages = {21},
title = {{A study of android application security}},
url = {http://dl.acm.org/citation.cfm?id=2028067.2028088},
year = {2011}
}
@article{Nagaraja2010,
abstract = {A key feature that distinguishes modern botnets from earlier counterparts is their increasing use of structured overlay topologies. This lets them carry out sophisticated coordinated activities while being resilient to churn, but it can also be used as a point of detection. In this work, we devise techniques to localize botnet members based on the unique communication patterns arising from their overlay topologies used for command and control. Experimental results on synthetic topologies embedded within Internet traffic traces from an ISP's backbone network indicate that our techniques (i) can localize the majority of bots with low false positive rate, and (ii) are resilient to incomplete visibility arising from partial deployment of monitoring systems and measurement inaccuracies from dynamics of background traffic.},
author = {Nagaraja, Shishir and Mittal, Prateek and Hong, Chi-Yao and Caesar, Matthew and Borisov, Nikita},
doi = {10.1.1.172.8756},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
pages = {7},
title = {{BotGrep: finding P2P bots with structured graph analysis}},
url = {http://static.usenix.org/event/sec10/tech/full{\{}{\_}{\}}papers/Nagaraja.pdf},
year = {2010}
}
@article{Marchenko2010,
abstract = {Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.},
archivePrefix = {arXiv},
arxivId = {0521865719 9780521865715},
author = {Marchenko, P and Karp, B},
doi = {10.1109/LPT.2009.2020494},
eprint = {0521865719 9780521865715},
isbn = {0521865719},
issn = {13864564},
journal = {usenix security},
keywords = {keyword},
pages = {1},
pmid = {10575050},
title = {{Structuring Protocol Implementations to Protect Sensitive Data.}},
url = {http://dspace.cusat.ac.in/dspace/handle/123456789/2538$\backslash$nhttps://www.usenix.org/legacy/event/sec10/tech/full{\{}{\_}{\}}papers/Marchenko.pdf},
year = {2010}
}
@article{Das2010,
abstract = {Maintaining correct access control to shared resources such as file servers, wikis, and databases is an important part of enterprise network management. A combination of many factors, including high rates of churn in organi- zational roles, policy changes, and dynamic information- sharing scenarios, can trigger frequent updates to user permissions, leading to potential inconsistencies. With Baaz, we present a distributed system that monitors up- dates to access control metadata, analyzes this informa- tion to alert administrators about potential security and accessibility issues, and recommends suitable changes. Baaz detectsmisconfigurations thatmanifest as small in- consistencies in user permissions that are different from what their peers are entitled to, and prevents integrity and confidentiality vulnerabilities that could lead to insider attacks. In a deployment of our system on an organiza- tional file server that stored confidential data, we found 10 high level security issues that impacted 1639 out of 105682 directories. These were promptly rectified},
author = {Das, Tathagata and Bhagwan, R and Naldurg, P},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
title = {{Baaz: A System for Detecting Access Control Misconfigurations.}},
url = {http://static.usenix.org/event/sec10/tech/full{\{}{\_}{\}}papers/Das.pdf},
year = {2010}
}
@article{Akritidis2010,
abstract = {Use-after-free vulnerabilities exploiting so-called dangling pointers to deallocated objects are just as dangerous as buffer overflows: they may enable arbitrary code execution. Unfortunately, state-of-the-art defenses against use-after-free vulnerabilities require compiler support, pervasive source code modifications, or incur high performance overheads. This paper presents and evaluates Cling, a memory allocator designed to thwart these attacks at runtime. Cling utilizes more address space, a plentiful resource on modern machines, to prevent type-unsafe address space reuse among objects of different types. It infers type information about allocated objects at runtime by inspecting the call stack of memory allocation routines. Cling disrupts a large class of attacks against use-after-free vulnerabilities, notably including those hijacking the C++ virtual function dispatch mechanism, with low CPU and physical memory overhead even for allocation intensive applications.},
author = {Akritidis, Periklis},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
pages = {177--192},
title = {{Cling: A Memory Allocator to Mitigate Dangling Pointers.}},
year = {2010}
}
@article{Antonakakis2010,
abstract = {The Domain Name System (DNS) is an essential protocol used by both legitimate Internet applications and cyber attacks. For example, botnets rely on DNS to support agile command and control infrastructures. An effective way to disrupt these attacks is to place malicious domains on a blocklist (or blacklist) or to add a filtering rule in a firewall or network intrusion detection system. To evade such security countermeasures, attackers have used DNS agility, e.g., by using new domains daily to evade static blacklists and firewalls. In this paper we propose Notos, a dynamic reputation system for DNS. The premise of this system is that malicious, agile use of DNS has unique characteristics and can be distinguished from legitimate, professionally provisioned DNS services. Notos uses passive DNS query data and analyzes the network and zone features of domains. It builds models of known legitimate domains and malicious domains, and uses these models to compute a reputation score for a new domain indicative of whether the domain is malicious or legitimate. We have evaluated Notos in a large ISPs network with DNS traffic from 1.4 million users. Our results show that Notos can identify malicious domains with high accuracy (true positive rate of 96.8{\{}{\%}{\}}) and low false positive rate (0.38{\{}{\%}{\}}), and can identify these domains weeks or even months before they appear in public blacklists.},
author = {Antonakakis, Manos and Perdisci, Roberto and Dagon, David and Lee, Wenke and Feamster, Nick},
isbn = {8887666655554},
journal = {usenix security},
pages = {1--17},
title = {{Building a Dynamic Reputation System for DNS}},
url = {http://www.usenix.org/events/sec10/tech/full{\{}{\_}{\}}papers/Antonakakis.pdf},
year = {2010}
}
@article{Watson2010,
abstract = {Capsicum is a lightweight operating system capability and sandbox framework planned for inclusion in FreeBSD 9. Capsicum extends, rather than replaces, UNIX APIs, providing new kernel primitives (sandboxed capability mode and capabilities) and a userspace sandbox API. These tools support compartmentalisation of monolithic UNIX applications into logical applications, an increasingly common goal supported poorly by discretionary and mandatory access control. We demonstrate our approach by adapting core FreeBSD utilities and Google's Chromium web browser to use Capsicum primitives, and compare the complexity and robustness of Capsicum with other sandboxing techniques.},
author = {Watson, Robert N M and Anderson, Jonathan and Laurie, Ben and Kennaway, Kris},
doi = {10.1145/2093548.2093572},
isbn = {888-7-6666-5555-4},
issn = {03601315},
journal = {usenix security},
number = {Figure 1},
pages = {3},
title = {{Capsicum: practical capabilities for UNIX}},
url = {http://dl.acm.org/citation.cfm?id=1929820.1929824},
year = {2010}
}
@article{Ensafi2010,
abstract = {Protocol Stacks Using Model Checking Ensafi, Jong Chun Park, Deepak Kapur, and Jedidiah R. Crandall University of New Mexico, Dept. Abstract port scanning uses side-channel attacks to bounce off of a “zombie” host to stealthily a victim IP address },
author = {Ensafi, Roya and Park, Jong Chun and Kapur, Deepak and Crandall, Jedidiah R},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
pages = {17},
title = {{Idle port scanning and non-interference analysis of network protocol stacks using model checking}},
url = {http://dl.acm.org/citation.cfm?id=1929820.1929843},
year = {2010}
}
@article{Gupta2010,
author = {Gupta, Payas and Gao, Debin},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
title = {{Fighting Coercion Attacks in Key Generation using Skin Conductance}},
year = {2010}
}
@article{Paleari2010,
abstract = {Despite the widespread deployment of malware-detection software, in many situations it is difficult to preemptively block a malicious program from infecting a system. Rather, signatures for detection are usually available only after malware have started to infect a large group of systems. Ideally, infected systems should be reinstalled from scratch. However, due to the high cost of reinstallation, users may prefer to rely on the remediation capabilities of malware detectors to revert the effects of an infection. Unfortunately, current malware detectors perform this task poorly, leaving users' systems in an unsafe or unstable state. This paper presents an architecture to automatically generate remediation procedures from malicious programs--procedures that can be used to remediate all and only the effects of the malware's execution in any infected system. We have implemented a prototype of this architecture and used it to generate remediation procedures for a corpus of more than 200 malware binaries. Our evaluation demonstrates that the algorithm outperforms the remediation capabilities of top-rated commercial malware detectors.},
author = {Paleari, Roberto and Martignoni, Lorenzo and Passerini, Emanuele and Davidson, Drew and Fredrikson, Matt and Giffin, Jonathon T and Jha, Somesh},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
pages = {419--434},
title = {{Automatic Generation of Remediation Procedures for Malware Infections}},
year = {2010}
}
@article{Meiklejohn2010,
abstract = {In recent years, many advances have been made in cryptography, as well as in the performance of communication networks and processors. As a result, many advanced cryptographic protocols are now efficient enough to be considered practical, yet research in the area remains largely theoretical and little work has been done to use these protocols in practice, despite a wealth of potential applications. This paper introduces a simple description language, ZKPDL, and an interpreter for this language. ZKPDL implements non-interactive zero-knowledge proofs of knowledge, a primitive which has received much attention in recent years. Using our language, a single program may specify the computation required by both the prover and verifier of a zero-knowledge protocol, while our interpreter performs a number of optimizations to lower both computational and space overhead. Our motivating application for ZKPDL has been the efficient implementation of electronic cash. As such, we have used our language to develop a cryptographic library, Cashlib, that provides an interface for using e-cash and fair exchange protocols without requiring expert knowledge from the programmer.},
author = {Meiklejohn, Sarah and Erway, C Chris and Hinkle, Theodora and Lysyanskaya, Anna},
journal = {usenix security},
pages = {193--206},
title = {{ZKPDL : A Language-Based System for Efficient Zero-Knowledge Proofs and Electronic Cash}},
url = {http://www.usenix.org/events/sec10/},
year = {2010}
}
@article{Balasch2010,
abstract = {Current Electronic Toll Pricing (ETP) implementa- tions rely on on-board units sending fine-grained loca- tion data to the service provider. We present PrETP, a privacy-preserving ETP system in which on-board units can prove that they use genuine data and perform cor- rect operations while disclosing the minimum amount of location data. PrETP employs a cryptographic proto- col, Optimistic Payment, which we define in the ideal- world/real-world paradigm, construct, and prove secure under standard assumptions. We provide an efficient im- plementation of this construction and build an on-board unit on an embedded microcontroller which is, to the best of our knowledge, the first self-contained prototype that supports remote auditing. We thoroughly analyze our system from a security, legal and performance perspec- tive and demonstrate that PrETP is suitable for low-cost commercial applications.},
author = {Balasch, Josep and Rial, Alfredo and Troncoso, Carmela and Preneel, Bart and Verbauwhede, Ingrid and Leuven, Ibbt-k U and Cosic, Esat and Geuens, Christophe and Leuven, K U and Leuven, B},
isbn = {8887666655554},
journal = {usenix security},
pages = {63--78},
title = {{PrETP : Privacy-Preserving Electronic Toll Pricing}},
url = {http://www.usenix.org/event/sec10/tech/full{\{}{\_}{\}}papers/Balasch.pdf},
year = {2010}
}
@article{Sehr2010,
abstract = {Software Fault Isolation (SFI) is an effective approach to sandboxing binary code of questionable provenance, an interesting use case for native plugins in a Web browser. We present software fault isolation schemes for ARM and x86-64 that provide control-flow and memory integrity with average performance overhead of under 5{\{}{\%}{\}} on ARM and 7{\{}{\%}{\}} on x86-64. We believe these are the best known SFI implementations for these architectures, with significantly lower overhead than previous systems for similar architectures. Our experience suggests that these SFI implementations benefit from instruction-level parallelism, and have particularly small impact for workloads that are data memory-bound, both properties that tend to reduce the impact of our SFI systems for future CPU implementations.},
author = {Sehr, David and Muth, Robert and Biffle, Cliff and Khimenko, Victor and Pasko, Egor and Schimpf, Karl and Yee, Bennet and Chen, Bradley J},
isbn = {8887666655554},
journal = {usenix security},
pages = {1--12},
title = {{Adapting software fault isolation to contemporary CPU architectures}},
url = {http://www.usenix.org/events/sec10/tech/full{\{}{\_}{\}}papers/Sehr.pdf},
year = {2010}
}
@article{,
journal = {usenix security},
title = {{Re: CAPTCHAs—Understanding CAPTCHA-Solving Services in an Economic Context}},
year = {2010}
}
@article{Kim2010,
abstract = {UserFS provides egalitarian OS protection mechanisms in Linux. UserFS allows any user--not just the system administrator--to allocate Unix user IDs, to use chroot, and to set up firewall rules in order to confine untrusted code. One key idea in UserFS is representing user IDs as files in a /proc-like file system, thus allowing applications to manage user IDs like any other files, by setting permissions and passing file descriptors over Unix domain sockets. UserFS addresses several challenges in making user IDs egalitarian, including accountability, resource allocation, persistence, and UID reuse. We have ported several applications to take advantage of UserFS; by changing just tens to hundreds of lines of code, we prevented attackers from exploiting application-level vulnerabilities, such as code injection or missing ACL checks in a PHP-based wiki application. Implementing UserFS requires minimal changes to the Linux kernel--a single 3,000-line kernel module--and incurs no performance overhead for most operations, making it practical to deploy on real systems.},
author = {Kim, Taesoo and Zeldovich, N},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
pages = {2},
title = {{Making Linux protection mechanisms egalitarian with UserFS}},
url = {http://dspace.mit.edu/handle/1721.1/62806},
year = {2010}
}
@article{Yu2010,
author = {Yu, Fang and John, John P and Xie, Yinglian and Abadi, Martin and Krishnamurthy, Arvind},
isbn = {9783540743194},
journal = {usenix security},
pages = {1--16},
title = {{Searching the Searchers with SearchAudit}},
url = {http://www.google.co.kr/search?sourceid=chrome{\{}{\&}{\}}ie=UTF-8{\{}{\&}{\}}q=Searching+the+searchers+with+searchaudit$\backslash$npapers3://publication/uuid/EBFF1584-430B-4104-B844-336540568B31},
year = {2010}
}
@article{Cavedon2010,
abstract = {Web applications are the most common way to make ser- vices and data available on the Internet. Unfortunately, with the increase in the number and complexity of these applications, there has also been an increase in the num- ber and complexity of vulnerabilities. Current techniques to identify security problems in web applications have mostly focused on input validation flaws, such as cross- site scripting and SQL injection, with much less attention devoted to application logic vulnerabilities. Application logic vulnerabilities are an important class of defects that are the result of faulty application logic. These vulnerabilities are specific to the functionality of particular web applications, and, thus, they are extremely difficult to characterize and identify. In this paper, we propose a first step toward the automated detection of application logic vulnerabilities. To this end, we first use dynamic analysis and observe the normal operation of a web application to infer a simple set of behavioral spe- cifications. Then, leveraging the knowledge about the typical execution paradigm of web applications, we filter the learned specifications to reduce false positives, and we use model checking over symbolic input to identify program paths that are likely to violate these specifica- tions under specific conditions, indicating the presence of a certain type of web application logic flaws. We de- veloped a tool, called Waler, based on our ideas, and we applied it to a number of web applications, finding previously-unknown logic vulnerabilities.},
author = {Cavedon, Ludovico and Vigna, Giovanni},
isbn = {8887666655554},
journal = {usenix security},
pages = {10},
title = {{Toward Automated Detection of Logic Vulnerabilities in Web Applications}},
url = {http://portal.acm.org/citation.cfm?id=1929820.1929834},
year = {2010}
}
@article{,
journal = {usenix security},
title = {{VEX: Vetting Browser Extensions for Security Vulnerabilities}},
year = {2010}
}
@article{Louw2010,
abstract = {Web publishers frequently integrate third-party advertisements into web pages that also contain sensitive publisher data and end-user personal data. This practice exposes sensitive page content to confidentiality and integrity attacks launched by advertisements. In this paper, we propose a novel framework for addressing security threats posed by third-party advertisements. The heart of our framework is an innovative isolation mechanism that enables publishers to transparently interpose between advertisements and end users. The mechanism supports finegrained policy specification and enforcement, and does not affect the user experience of interactive ads. Evaluation of our framework suggests compatibility with several mainstream ad networks, security from many threats from advertisements and acceptable performance overheads.},
author = {Louw, Mike Ter and Ganesh, Karthik Thotta and Venkatakrishnan, V N},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
keywords = {AdJail},
pages = {24},
title = {{AdJail: practical enforcement of confidentiality and integrity policies on web advertisements}},
url = {http://dl.acm.org/citation.cfm?id=1929820.1929852},
year = {2010}
}
@article{Burkhart2010,
abstract = {Secure multiparty computation (MPC) allows joint privacy-preserving computations on data of multiple parties. Although MPC has been studied substantially, building solutions that are practical in terms of computation and communication cost is still a major challenge. In this paper, we investigate the practical usefulness of MPC for multi-domain network security and monitoring. We first optimize MPC comparison operations for processing high volume data in near real-time. We then design privacy-preserving protocols for event correlation and aggregation of network traffic statistics, such as addition of volume metrics, computation of feature entropy, and distinct item count. Optimizing performance of parallel invocations, we implement our protocols along with a complete set of basic operations in a library called SEPIA. We evaluate the running time and bandwidth requirements of our protocols in realistic settings on a local cluster as well as on PlanetLab and show that they work in near real-time for up to 140 input providers and 9 computation nodes. Compared to implementations using existing general-purpose MPC frameworks, our protocols are significantly faster, requiring, for example, 3 minutes for a task that takes 2 days with general-purpose frameworks. This improvement paves the way for new applications of MPC in the area of networking. Finally, we run SEPIA's protocols on real traffic traces of 17 networks and show how they provide new possibilities for distributed troubleshooting and early anomaly detection.},
author = {Burkhart, Martin and Strasser, Mario and Many, Dilip and Dimitropoulos, Xenofontas},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
keywords = {compiler,cryptography,mpc,sepia},
pages = {15},
title = {{SEPIA: Privacy-preserving Aggregation of Multi-domain Network Events and Statistics}},
url = {https://www.usenix.org/conference/usenixsecurity10/sepia-privacy-preserving-aggregation-multi-domain-network-events-and},
year = {2010}
}
@article{Djeric2010,
abstract = {Web browsers are increasingly designed to be extensible to keep up with the Web's rapid pace of change. This extensibility is typically implemented using script-based extensions. Script extensions have access to sensitive browser APIs and content from untrusted web pages. Unfortunately, this powerful combination creates the threat of privilege escalation attacks that grant web page scripts the full privileges of extensions and control over the entire browser process. This paper makes two contributions. First, it describes the pitfalls of script-based extensibility based on our study of the Firefox web browser. We find that script-based extensions can lead to arbitrary code injection and execution control, the same types of vulnerabilities found in unsafe code. Second, we propose a taint-based system to track the spread of untrusted data in the browser and to detect the characteristic signatures of privilege escalation attacks. We evaluate this approach by using exploits from the Firefox bug database and show that our system detects the vast majority of attacks with almost no false alarms.},
author = {Djeric, Vladan and Goel, Ashvin},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
keywords = {javascript,pldi12},
pages = {23},
title = {{Securing script-based extensibility in web browsers}},
url = {http://portal.acm.org/citation.cfm?id=1929851},
year = {2010}
}
@article{Carback2010,
abstract = {On November 3, 2009, voters in Takoma Park, Maryland, cast ballots for the mayor and city council members using the Scantegrity II voting system--the first time any end-to-end (E2E) voting system with ballot privacy has been used in a binding governmental election. This case study describes the various efforts that went into the election--including the improved design and implementation of the voting system, streamlined procedures, agreements with the city, and assessments of the experiences of voters and poll workers. The election, with 1728 voters from six wards, involved paper ballots with invisible-ink confirmation codes, instant-runoff voting with write-ins, early and absentee (mail-in) voting, dual-language ballots, provisional ballots, privacy sleeves, any-which-way scanning with parallel conventional desktop scanners, end-to-end verifiability based on optional web-based voter verification of votes cast, a full hand recount, thresholded authorities, three independent outside auditors, fully-disclosed software, and exit surveys for voters and pollworkers. Despite some glitches, the use of Scantegrity II was a success, demonstrating that E2E cryptographic voting systems can be effectively used and accepted by the general public.},
author = {Carback, Richard and Chaum, David and Clark, Jeremy and Conway, John and Essex, Aleksander and Herrnson, Paul S and Mayberry, Travis and Popoveniuc, Stefan and Rivest, Ronald L and Shen, Emily and Sherman, Alan T and Vora, Poorvi L},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
keywords = {ballot,cryptography,election,mpc,voting},
pages = {19},
title = {{Scantegrity II municipal election at Takoma Park: the first E2E binding governmental election with ballot privacy}},
url = {http://portal.acm.org/citation.cfm?id=1929846},
year = {2010}
}
@article{Rasmussen2010,
abstract = {One of the main obstacles for the wider deployment of radio (RF) distance bounding is the lack of platforms that implement these protocols. We address this problem and we build a prototype system that demonstrates that radio distance bounding protocols can be implemented to match the strict processing that these protocols require. Our system implements a prover that is able to receive, process and transmit signals in less than 1ns. The security guarantee that a distance bounding protocol built on top of this system therefore provides is that a malicious prover can, at most, pretend to be about 15cm closer to the verifier than it really is. To enable such fast processing at the prover, we use specially implemented concatenation as the prover’s processing function and show how it can be integrated into a distance bounding protocol. Finally, we show that functions such as XOR and the comparison function, that were used in a number of previously proposed distance bounding protocols, are not best suited for the implementation of radio distance bounding.},
author = {Rasmussen, Kasper Bonne and Capkun, Srdjan},
journal = {usenix security},
title = {{Realization of RF distance bounding}},
url = {http://www.usenix.org/event/sec10/tech/full{\{}{\_}{\}}papers/Rasmussen.pdf},
year = {2010}
}
@article{Rouf2010,
abstract = {Wireless networks are being integrated into the modern automobile. The security and privacy implications of such in-car networks, however, have are not well understood as their transmissions propagate beyond the con- nes of a car's body. To understand the risks associated with these wireless systems, this paper presents a privacy and security evaluation of wireless Tire Pressure Monitoring Systems using both laboratory experiments with isolated tire pressure sensor modules and experiments with a complete vehicle system. We show that eavesdropping is easily possible at a distance of roughly 40m from a passing vehicle. Further, reverse-engineering of the underlying protocols revealed static 32 bit identi- ers and that messages can be easily triggered remotely, which raises privacy concerns as vehicles can be tracked through these identiers. Further, current protocols do not employ authentication and vehicle implementations do not perform basic input validation, thereby allowing for remote spoong of sensor messages. We validated this experimentally by triggering tire pressure warning messages in a moving vehicle from a customized software radio attack platform located in a nearby vehicle. Finally, the paper concludes with a set of recommendations for improving the privacy and security of tire pressure monitoring systems and other forthcoming in-car wireless sensor networks.},
author = {Rouf, Ishtiaq and Miller, Rob and Mustafa, Hossen and Taylor, Travis and Oh, Sangho and Xu, Wenyuan and Grutese, Marco and Trappe, Wade and Seskar, Ivan},
doi = {10.1177/004057368303900411},
isbn = {888-7-6666-5555-4},
issn = {0040-5736},
journal = {usenix security},
number = {4},
pages = {11--13},
title = {{Security and privacy vulnerabilities of in-car wireless networks: A tire pressure monitoring system case study.}},
volume = {39},
year = {2010}
}
@article{Duan2010,
author = {Duan, Yitao and Zhan, Justin},
journal = {usenix security},
title = {{P4P : Practical Large-Scale Privacy-Preserving Distributed Computation Robust against Malicious Users}},
url = {papers3://publication/uuid/FB356E1D-7C7F-4452-AF25-C6AC55CB3D2F},
year = {2010}
}
@article{Aggarwal2010,
abstract = {We study the security and privacy of private browsing modes recently added to all major browsers. We first propose a clean definition of the goals of private browsing and survey its implementation in different browsers. We conduct a measurement study to determine how often it is used and on what categories of sites. Our results suggest that private browsing is used differently from how it is marketed. We then describe an automated technique for testing the security of private browsing modes and report on a few weaknesses found in the Firefox browser. Finally, we show that many popular browser extensions and plugins undermine the security of private browsing. We propose and experiment with a workable policy that lets users safely run extensions in private browsing mode.},
author = {Aggarwal, G and Bursztein, E},
doi = {10.1109/ISSA.2013.6641058},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
pages = {1--8},
title = {{An Analysis of Private Browsing Modes in Modern Browsers.}},
url = {http://www.collinjackson.com/research/private-browsing.pdf$\backslash$nhttp://cdn.ly.tl/publications/private{\{}{\_}{\}}browsing{\{}{\_}{\}}mode-slides-usenix-security.pdf$\backslash$nhttp://ieeexplore.ieee.org/ielx7/6621627/6641027/06641058.pdf?tp={\{}{\&}{\}}arnumber=6641058{\{}{\&}{\}}isnumber=6641027$\backslash$nhttp:/},
year = {2010}
}
@article{Meiners2010,
author = {Meiners, C R and Patel, J and Norige, E and Torng, E and ...},
journal = {usenix security},
title = {{Fast regular expression matching using small TCAMs for network intrusion detection and prevention systems}},
url = {http://dl.acm.org/citation.cfm?id=1929831},
year = {2010}
}
@article{Bittau2010,
abstract = {Today, Internet traffic is encrypted only when deemed necessary. Yet modern CPUs could feasibly encrypt most traffic. Moreover, the cost of doing so will only drop over time. Tcpcrypt is a TCP extension designed to make end-to-end encryption of TCP traffic the default, not the exception. To facilitate adoption tcpcrypt provides backwards compatibility with legacy TCP stacks and middle-boxes. Because it is implemented in the transport layer, it protects legacy applications. However, it also provides a hook for integration with application-layer authentication, largely obviating the need for applications to encrypt their own network traffic and minimizing the need for duplication of functionality. Finally, tcpcrypt minimizes the cost of key negotiation on servers; a server using tcpcrypt can accept connections at 36 times the rate achieved using SSL.},
author = {Bittau, Andrea and Hamburg, Michael and Handley, Mark and Mazi{\`{e}}res, David and Boneh, Dan},
journal = {usenix security},
title = {{The case for ubiquitous transport-level encryption}},
url = {http://www.usenix.org/events/sec10/tech/full{\{}{\_}{\}}papers/Bittau.pdf},
year = {2010}
}
@article{Burnett2010,
abstract = {Oppressive regimes and even democratic governments restrict Internet access. Existing anti-censorship systems often require users to connect through proxies, but these systems are relatively easy for a censor to discover and block. This paper offers a possible next step in the cen- sorship arms race: rather than relying on a single system or set of proxies to circumvent censorship firewalls, we explore whether the vast deployment of sites that host user-generated content can breach these firewalls. To ex- plore this possibility, we have developed Collage, which allows users to exchange messages through hidden chan- nels in sites that host user-generated content. Collage has two components: a message vector layer for embedding content in cover traffic; and a rendezvous mechanism to allow parties to publish and retrieve messages in the cover traffic. Collage uses user-generated content (e.g., photo-sharing sites) as drop sites for hidden messages. To send a message, a user embeds it into cover traffic and posts the content on some site, where receivers retrieve this content using a sequence of tasks. Collage makes it difficult for a censor to monitor or block these messages by exploiting the sheer number of sites where users can exchange messages and the variety of ways that a mes- sage can be hidden. Our evaluation of Collage shows that the performance overhead is acceptable for sending small messages (e.g.,Web articles, email). We showhow Collage can be used to build two applications: a direct messaging application, and a Web content delivery sys- tem.},
author = {Burnett, Sam and Feamster, Nick and Vempala, Santosh},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
pages = {29},
title = {{Chipping Away at Censorship Firewalls with User-Generated Content}},
url = {http://scholar.google.com/scholar?hl=en{\{}{\&}{\}}btnG=Search{\{}{\&}{\}}q=intitle:Chipping+Away+at+Censorship+Firewalls+with+User-Generated+Content{\{}{\#}{\}}0},
year = {2010}
}
@article{Gill2010,
abstract = {Many applications of IP geolocation can benefit from geolocation that is robust to adversarial clients. These include applications that limit access to online content to a specific geographic region and cloud computing, where some organizations must ensure their virtual machines stay in an appropriate geographic region. This paper studies the applicability of current IP geolocation techniques against an adversary who tries to subvert the techniques into returning a forged result. We propose and evaluate attacks on both delay-based IP geolocation techniques and more advanced topology-aware techniques. Against delay-based techniques, we find that the adversary has a clear trade-off between the accuracy and the detectability of an attack. In contrast, we observe that more sophisticated topology-aware techniques actually fare worse against an adversary because they give the adversary more inputs to manipulate through their use of topology and delay information.},
author = {Gill, Phillipa and Ganjali, Yashar and Wong, Bernard and Lie, David},
isbn = {8887666655554},
journal = {usenix security},
pages = {16},
title = {{Dude, where’s that IP?: circumventing measurement-based IP geolocation}},
url = {http://dl.acm.org/citation.cfm?id=1929820.1929842},
year = {2010}
}
@article{Backes2010,
author = {Backes, Michael and D{\"{u}}rmuth, M and Gerling, Sebastian},
isbn = {888-7-6666-5555-4},
journal = {usenix security},
pages = {307--322},
title = {{Acoustic Side-Channel Attacks on Printers}},
year = {2010}
}
