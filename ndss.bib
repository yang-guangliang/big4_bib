@article{helli,
author = {Lee, Sangho and Kim, Hyungsub and Kim, Jong},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Identifying Cross-origin Resource Status Using Application Cache}},
year = {2015}
}
@article{helli,
author = {Vissers, Thomas and Joosen, Wouter and Nikiforakis, Nick},
doi = {10.14722/ndss.2015.23053},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Parking Sensors : Analyzing and Detecting Parked Domains}},
year = {2015}
}
@article{helli,
author = {Agten, Pieter and Joosen, Wouter and Piessens, Frank and Nikiforakis, Nick},
doi = {10.14722/ndss.2015.23058},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Seven Months ’ Worth of Mistakes : A Longitudinal Study of Typosquatting Abuse}},
year = {2015}
}
@article{helli,
author = {Kranch, Michael and Bonneau, Joseph},
isbn = {189156238X},
journal = {ndss},
keywords = {HTTPS},
number = {February},
pages = {8--11},
title = {{Upgrading HTTPS in Mid-Air : An Empirical Study of Strict Transport Security and Key Pinning}},
year = {2015}
}
@article{helli,
author = {Pan, Xiang and Cao, Yinzhi and Chen, Yan},
doi = {10.14722/ndss.2015.23163},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{I Do Not Know What You Visited Last Summer : Protecting Users from Third-party Web Tracking with TrackingFree Browser}},
year = {2015}
}
@article{helli,
journal = {ndss},
title = {{ Information Flow Analysis of Android Applications in DroidSafe }},
year = {2015}
}
@article{helli,
author = {Demetriou, Soteris and Zhou, Xiaoyong and Naveedy, Muhammad and Leez, Yeonjoon and Yuanz, Kan and Wangz, XiaoFeng and Gunter, Carl A.},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{What's in Your Dongle and Bank Account? Mandatory and Discretionary Protection of Android External Resources}},
year = {2015}
}
@article{helli,
abstract = {—A wealth of recent research proposes static data flow analysis for the security analysis of Android applications. One of the building blocks that these analysis systems rely upon is the computation of a precise control flow graph. The callback mechanism provided and orchestrated by the Android framework makes the correct generation of the control flow graph a challenging endeavor. From the analysis’ point of view, the invocation of a callback is an implicit control flow transition facilitated by the framework. Existing static analysis tools model callbacks through either manually curated lists or ad-hoc heuristics. This work demonstrates that both approaches are insufficient, and allow malicious applications to evade detection by state-of-the-art analysis systems. To address the challenge of implicit control flow transitions (i.e., callbacks) through the Android framework, we are the first to propose, implement, and evaluate a systematic treatment of this aspect. Our implementation, called EDGEMINER, statically analyzes the entire Android framework to automatically generate API summaries that describe implicit control flow transitions through the Android framework.We use EDGEMINER to analyze three major versions of the Android framework. EDGEMINER identified 19,647 callbacks in Android 4.2, suggesting that a manual treatment of this challenge is likely infeasible. Our evaluation demonstrates that the current insufficient treatment of callbacks in state-of-the-art analysis tools results in unnecessary imprecision. For example, FlowDroid misses a variety of leaks of privacy sensitive data from benign off-the-shelf Android applications because of its inaccurate handling of callbacks. Of course, malicious applications can also leverage this blind spot in current analysis systems to evade detection at will. To alleviate these drawbacks, we make our results publicly available and demonstrate how these results can easily be integrated into existing state-of-the-art analysis tools. Our work allows existing tools to comprehensively address the challenge of callbacks and identify previously undetected leakage of privacy sensitive data.},
author = {Cao, Yinzhi and Fratantonio, Yanick and Bianchi, Antonio and Egele, Manuel},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{EdgeMiner : Automatically Detecting Implicit Control Flow Transitions through the Android Framework}},
year = {2015}
}
@article{helli,
abstract = {{\#}copperdroid.},
author = {Tam, Kimberly and Khan, Salahuddin J and Fattori, Aristide and Cavallaro, Lorenzo},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{CopperDroid: Automatic Reconstruction of Android Malware Behaviors}},
year = {2015}
}
@article{helli,
abstract = {{\#}deepdroid.},
author = {Wang, Xueqiang and Sun, Kun and Wang, Yuewu and Jing, Jiwu},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{DeepDroid: Dynamically Enforcing Enterprise Policy on Android Devices}},
year = {2015}
}
@article{helli,
author = {Zhang, Chao and Song, Chengyu and Chen, Kevin Zhijie and Chen, Zhaofeng and Song, Dawn},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{VTint : Protecting Virtual Function Tables ’ Integrity}},
year = {2015}
}
@article{helli,
author = {Gupta, Payas and Srinivasan, Bharat and Balasubramaniyan, Vijay and Ahamad, Mustaque},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Phoneypot : Data-driven Understanding of Telephony Threats}},
year = {2015}
}
@article{helli,
abstract = {ARM TrustZone, which provides a Trusted Exe- cution Environment (TEE), normally plays a role in keeping security-sensitive resources safe. However, to properly control access to the resources, it is not enough to just isolate them from the Rich Execution Environment (REE). In addition to the isolation, secure communication should be guaranteed between security-critical resources in the TEE and legitimate REE pro- cesses that are permitted to use them. Even though there is a TEE security solution — namely, a kernel-integrity monitor — it aims to protect the REE kernel’s static regions, not to secure communication between the REE and TEE. We propose SeCReT to ameliorate this problem. SeCReT is a framework that builds a secure channel between the REE and TEE by enabling REE processes to use session keys in the REE that is regarded as unsafe region. SeCReT provides the session key to a requestor process only when the requestor’s code and control flow integrity are verified. To prevent the key from being exposed to an attacker who already compromised the REE kernel, SeCReT flushes the key from the memory every time the processor switches into kernel mode. In this paper, we present the design and implementation of SeCReT to show how it protects the key in the REE. Our prototype is implemented on Arndale board, which offers a Cortex-A15 dual-core processor with TrustZone as its security extension. We performed a security analysis by using a kernel rootkit and also ran LMBench microbenchmark to evaluate the performance overhead imposed by SeCReT.},
author = {Jang, Jinsoo and Kong, Sunjune and Kim, Minsu and Kim, Daegyeong and Kang, Brent Byunghoon},
doi = {10.14722/ndss.2015.23189},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{SeCReT : Secure Channel between Rich Execution Environment and Trusted Execution Environment}},
year = {2015}
}
@article{helli,
author = {Younan, Yves},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{FreeSentry : protecting against use-after-free vulnerabilities due to dangling pointers}},
year = {2015}
}
@article{helli,
abstract = {The emergence of exploit kits is one of the most important developments in modern cybercrime. Much of cybersecurity research in the recent years has been devoted towards defending citizens from harm delivered through exploit kits. In this paper, we examine an alternate, counter-offensive strategy towards combating cybercrime launched through exploit kits. Towards this goal, we survey a wide range of 30 real-world exploit kits and analyze a counter-offensive adversarial model against the kits and kit operator. Guided by our analysis, we present a systematic methodology for examining a given kit to determine where vulnerabilities may reside within its serverside implementation. In our experiments, we found over 180 vulnerabilities among 16 exploit kits of those surveyed, and were able to automatically synthesize exploits for infiltrating 6 of them. The results validate our hypothesis that exploit kits largely lack sophistication necessary to resist counter-offensive activities. We then propose the design of EKHUNTER, a system that is capable of automatically detecting the presence of exploit vulnerabilities and deriving laboratory test cases that can compromise both the integrity o},
author = {Eshete, Birhanu and Alhuzali, Abeer and Monshizadeh, Maliheh and Porras, Phillip and Venkatakrishnan, V.N. and Yegneswaran, Vinod},
isbn = {189156238X},
journal = {ndss},
keywords = {exploit kits,offensive technologies,web malware},
number = {February},
pages = {8--11},
title = {{EKHUNTER: A Counter-Offensive Toolkit for Exploit Kit Infiltration}},
year = {2015}
}
@article{helli,
author = {Zhao, Lianying and Mannan, Mohammad},
isbn = {189156238X},
journal = {ndss},
title = {{Gracewipe : Secure and Verifiable Deletion under Coercion}},
year = {2015}
}
@article{helli,
abstract = {A credit network models trust between agents in a distributed environment and enables payments between arbitrary pairs of agents. With their flexible design and robustness against intrusion, credit networks form the basis of several Sybil-tolerant social networks, spam-resistant communication protocols, and payment systems. Existing systems, however, expose agents’ trust links as well as the existence and volumes of payment transactions, which is considered sensitive information in social environments or in the financial world. This raises a challenging privacy concern, which has largely been ignored by the research on credit networks so far. This paper presents PrivPay, the first provably secure privacy- preserving payment protocol for credit networks. The distinguish- ing feature of PrivPay is the obliviousness of transactions, which entails strong privacy guarantees for payments. PrivPay does not require any trusted third party, maintains a high accuracy of the transactions, and provides an economical solution to network service providers. It is also general-purpose trusted hardware- based solution applicable to all credit network-based systems. We implemented PrivPay and demonstrated its practicality by pri- vately emulating transactions performed in the Ripple payment system over a period of four months.},
author = {Moreno-sanchez, Pedro and Kate, Aniket and Maffei, Matteo and Pecina, Kim},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Privacy Preserving Payments in Credit Networks Enabling trust with privacy in online marketplaces}},
year = {2015}
}
@article{helli,
abstract = {Serious concerns have been raised about steahlthy disclosures of pricate user data in smartphone apps, and recent research efforts in mobile security have studied various machanisms to detect privacy disclosures. However, existing approaches are not effective in informin users and security analysts about potential privacy leakage threats. This is because these methods largely fail to 1) provide highly accurate and inclusive detections of privacy disclosures, and 2) filter out legitimate privacy disclosures that usaually dominate detection results and in turn obscure true threats. In this paper, we propose AAPL, an automated system that detects privacy leaks.},
author = {Lu, Kangjie and Li, Zhichun and Kemerlis, Vasileios and Wu, Zhenyu and Lu, Long and Zheng, Cong and Qian, Zhiyun and Lee, Wenke and Jiang, Guofei},
doi = {10.14722/ndss.2015.23287},
isbn = {189156238X},
journal = {ndss},
title = {{Checking More and Alerting Less: Detecting Privacy Leakages via Enhanced Data-flow Analysis and Peer Voting}},
year = {2015}
}
@article{helli,
author = {Peters, Timothy M and Poly, Cal and Obispo, San Luis and Gondree, Mark A and Poly, Cal and Obispo, San Luis},
isbn = {189156238X},
journal = {ndss},
title = {{DEFY : A Deniable , Encrypted File System for Log-Structured Storage}},
year = {2015}
}
@article{helli,
abstract = {—Many system components and network applications are written in languages that are prone to memory corruption vulnerabilities. There have been countless cases where simple mistakes by developers resulted in memory corruption vulnera-bilities and consequently security exploits. While there have been tremendous research efforts to mitigate these vulnerabilities, use-after-free still remains one of the most critical and popular attack vectors because existing proposals have not adequately addressed the challenging program analysis and runtime performance issues. In this paper we present DANGNULL, a system that detects temporal memory safety violations—in particular, use-after-free and double-free—during runtime. DANGNULL relies on the key observation that the root cause of these violations is that pointers are not nullified after the target object is freed. Based on this observation, DANGNULL automatically traces the object's rela-tionships via pointers and automatically nullifies all pointers when the target object is freed. DANGNULL offers several benefits. First, DANGNULL addresses the root cause of temporal memory safety violations. It does not rely on the side effects of violations, which can vary and may be masked by attacks. Thus, DANGNULL is ef-fective against even the most sophisticated exploitation techniques. Second, DANGNULL checks object relationship information using runtime object range analysis on pointers, and thus is able to keep track of pointer semantics more robustly even in complex and large scale software. Lastly, DANGNULL does not require numerous explicit sanity checks on memory accesses because it can detect a violation with implicit exception handling, and thus its detection capabilities only incur moderate performance overhead.},
author = {Lee, Byoungyoung and Song, Chengyu and Jang, Yeongjin and Wang, Tielei},
doi = {10.14722/ndss.2015.23238},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Preventing Use-after-free with Dangling Pointers Nullification}},
year = {2015}
}
@article{helli,
author = {Chen, Xi and Slowinska, Asia and Andriesse, Dennis and Bos, Herbert and Giuffrida, Cristiano},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{StackArmor : Comprehensive Protection from Stack-based Memory Error Vulnerabilities for Binaries}},
year = {2015}
}
@article{helli,
author = {Davi, Lucas and Liebchen, Christopher and Sadeghi, Ahmad-reza and Snow, Kevin Z and Monrose, Fabian},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Isomeron : Code Randomization Resilient to ( Just-In-Time ) Return-Oriented Programming}},
year = {2015}
}
@article{helli,
author = {Crane, Stephen and Homescu, Andrei and Brunthaler, Stefan and Larsen, Per and Franz, Michael},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Thwarting Cache Side-Channel Attacks Through Dynamic Software Diversity}},
year = {2015}
}
@article{helli,
author = {Juba, Brendan and Musco, Christopher and Long, Fan and Sidiroglou-douskos, Stelios and Rinard, Martin},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Principled Sampling for Anomaly Detection}},
year = {2015}
}
@article{helli,
author = {{Ell Massad}, Mohamed and Garg, Siddharth and Tripunitara, Mahesh V},
journal = {ndss},
pages = {1--14},
title = {{Integrated Circuit ( IC ) Decamouflaging : Reverse Engineering Camouflaged ICs within Minutes ( Not Years )}},
year = {2015}
}
@article{helli,
abstract = {A new binary software randomization and Control- Flow Integrity (CFI) enforcement system is presented, which is the first to efficiently resist code-reuse attacks launched by informed adversaries who possess full knowledge of the in- memory code layout of victim programs. The defense mitigates a recent wave of implementation disclosure attacks , by which adver- saries can exfiltrate in-memory code details in order to prepare code-reuse attacks (e.g., Return-Oriented Programming (ROP) attacks) that bypass fine-grained randomization defenses. Such implementation-aware attacks defeat traditional fine-grained ran- domization by undermining its assumption that the randomized locations of abusable code gadgets remain secret. Opaque CFI (O-CFI) overcomes this weakness through a novel combination of fine-grained code-randomization and coarse- grained control-flow integrity checking. It conceals the graph of hijackable control-flow edges even from attackers who can view the complete stack, heap, and binary code of the victim process. For maximal efficiency, the integrity checks are implemented using instructions that will soon be hardware-accelerated on commodity x86-x64 processors. The approach is highly practical since it does not require a modified compiler and can protect legacy binaries without access to source code. Experiments using our fully functional prototype implementation show that O-CFI provides significant probabilistic protection against ROP attacks launched by adversaries with complete code layout knowledge, and exhibits only 4.7{\%} mean performance overhead on current hardware (with further overhead reductions to follow on forth- coming Intel processors).},
author = {Mohan, Vishwath and Larsen, Per and Brunthaler, Stefan},
isbn = {189156238X},
journal = {ndss},
title = {{Opaque control-flow integrity}},
url = {http://www.utdallas.edu/{~}hamlen/mohan15ndss.pdf},
year = {2015}
}
@article{helli,
author = {Mor, Nitesh and Riva, Oriana},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Bloom Cookies: Web Search Personalization without User Tracking}},
year = {2015}
}
@article{helli,
author = {Goldberg, Sharon and Naor, Moni and Papadopoulos, Dimitrios and Reyzin, Leonid and Vasant, Sachin and Ziv, Asaf},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{NSEC5 : Provably Preventing DNSSEC Zone Enumeration}},
year = {2015}
}
@article{helli,
author = {Bilogrevic, Igor and Huguenin, Kevin and Mihaila, Stefan and Shokri, Reza and Hubaux, Jean-Pierre},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Predicting Users' Motivations behind Location Check-Ins and Utility Implications of Privacy Protection Mechanisms}},
year = {2015}
}
@article{helli,
author = {Ji, Shouling and Li, Weiqing and Gong, Neil Zhenqiang and Mittal, Prateek and Beyah, Raheem},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{On Your Social Network De-anonymizablity: Quantification and Large Scale Evaluation with Seed Knowledge}},
year = {2015}
}
@article{helli,
abstract = {Recent work on proof-based verifiable computation has resulted in built systems that employ tools from complexity theory and cryptography to address a basic problem in systems security: allowing a local computer to outsource the execution of a program while providing the local computer with a guarantee of integrity and the remote computer with a guarantee of privacy. However, support for programs that use RAM and control flow has been problematic. State of the art systems either restrict the use of these constructs (e.g., requiring static loop bounds), incur sizeable overhead on every step, or pay tremendous costs when the constructs are invoked.This paper describes Buffet, a built system that solves these problems by providing inexpensive "a la carte" RAM and dynamic control flow. Buffet composes an elegant prior approach to RAM with a novel adaptation of techniques from the compilers literature. Buffet allows the programmer to express programs in an expansive subset of C (disallowing only "goto" and function pointers), can handle essentially any example in the verifiable computation literature, and achieves the best performance in the area by multiple orders of magnitude.},
author = {Wahby, Riad S and Setty, Srinath and Ren, Zuocheng and Blumberg, Andrew J and Walfish, Michael},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Efficient RAM and Control Flow in Verifiable Outsourced Computation}},
year = {2015}
}
@article{helli,
author = {Boshmaf, Yazan and Logothetis, Dionysios and Siganos, Georgos and Ler{\'{\i}}a, Jorge},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{{\'{I}}ntegro : Leveraging Victim Prediction for Robust Fake Account Detection in OSNs}},
year = {2015}
}
@article{helli,
abstract = {We report on a user study that provides evidence that spaced repetition and a specific mnemonic technique enable users to successfully recall multiple strong passwords over time. Remote research participants were asked to memorize 4 Person- Action-Object (PAO) stories where they chose a famous person from a drop-down list and were given machine-generated random action-object pairs. Users were also shown a photo of a scene and asked to imagine the PAO story taking place in the scene (e.g., Bill Gates—swallowing—bike on a beach). Subsequently, they were asked to recall the action-object pairs when prompted with the associated scene-person pairs following a spaced repetition schedule over a period of 127+ days. While we evaluated several spaced repetition schedules, the best results were obtained when users initially returned after 12 hours and then in 1:5 increasing intervals: 77{\%} of the participants successfully recalled all 4 stories in 10 tests over a period of  158 days. Much of the forgetting happened in the first test period (12 hours): 89{\%} of participants who remembered their stories during the first test period successfully remembered them in every subsequent round. These findings, coupled with recent results on naturally rehearsing password schemes, suggest that 4 PAO stories could be used to create usable and strong passwords for 14 sensitive accounts following this spaced repetition schedule, possibly with a few extra upfront rehearsals. In addition, we find statistically significant evidence that with 8 tests over 64 days users who were asked to memorize 4 PAO stories outperform users who are given 4 random action-object pairs, but with 9 tests over 128 days the advantage is not significant. Furthermore, there is an interference effect across multiple PAO stories: the recall rate of 100{\%} (resp. 90{\%}) for participants who were asked to memorize 1 PAO story (resp. 2 PAO stories) is significantly better than the rate for participants who were asked to memorize 4 PAO stories. These findings yield concrete advice for improving constructions of password management schemes and future user studies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1410.1490v2},
author = {Blocki, Jeremiah and Komanduri, Saranga and Cranor, Lorrie and Datta, Anupam},
eprint = {arXiv:1410.1490v2},
isbn = {189156238X},
journal = {ndss},
title = {{Spaced Repetition and Mnemonics Enable Recall of Multiple Strong Passwords}},
url = {http://www.internetsociety.org/doc/spaced-repetition-and-mnemonics-enable-recall-multiple-strong-passwords},
year = {2015}
}
@article{helli,
author = {Demmler, Daniel and Schneider, Thomas and Zohner, Michael},
isbn = {189156238X},
journal = {ndss},
keywords = {and error-,ef-,ficient protocol design,mixed-protocols,prone,protocol has its own,secure two-party computation,since each secure computation,task becomes even more,tedious,time-consuming},
number = {February},
pages = {8--11},
title = {{ABY – A Framework for Efficient Mixed-Protocol Secure Two-Party Computation}},
year = {2015}
}
@article{helli,
author = {Eberz, Simon and Rasmussen, Kasper B and Lenders, Vincent and Martinovic, Ivan},
isbn = {1-891562-38-X},
journal = {ndss},
pages = {1--13},
title = {{Preventing Lunchtime Attacks: Fighting Insider Threats With Eye Movement Biometrics}},
year = {2015}
}
@article{helli,
abstract = {—We present Knock Yourself Out (KYO), a pass-word generator that enables secure authentication against a computationally unbounded adversary. Master passwords can be surprisingly short and may be re-used for multiple service accounts even in the event of client compromises and multiple server compromises. At the same time, KYO is transparent to service operators and backwards-compatible. Master passwords are fully client-manageable while secrets shared with service operators can be kept constant. Likewise, secrets can be changed without having to change one's passwords. KYO does not rely on collision-resistant hash functions and can be implemented with fast non-cryptographic hash functions. We detail the design of KYO and we analyze its security mathematically in a random hash function model. In our empirical evaluation we find that KYO remains secure even if small sets of hash functions are used instead, in other words, KYO requires minimal storage and is highly practical.},
author = {Guldenring, Benjamin and Roth, Volker and Ries, Lars},
doi = {10.14722/ndss.2015.23261},
isbn = {1-891562-38-X},
journal = {ndss},
pages = {1--14},
title = {{Knock Yourself Out: Secure Authentication with Short Re-Usable Passwords}},
url = {http://www.internetsociety.org/doc/knock-yourself-out-secure-authentication-short-re-usable-passwords$\backslash$npapers3://publication/doi/10.14722/ndss.2015.23261},
year = {2015}
}
@article{helli,
author = {{Karthikeyan Bhargavan, Antoine Delignat-Lavaud}, Alfredo Pironti},
journal = {ndss},
title = {{Verified Contributive Channel Bindings for Compound Authentication}},
url = {papers3://publication/doi/10.14722/ndss.2015.23277},
year = {2015}
}
@article{helli,
author = {Athanasakis, Michalis and Athanasopoulos, Elias and Polychronakis, Michalis and Portokalidis, Georgios and Ioannidis, Sotiris},
isbn = {1-891562-38-X},
journal = {ndss},
pages = {1--13},
title = {{The Devil is in the Constants: Bypassing Defenses in Browser JIT Engines}},
url = {http://www.internetsociety.org/doc/devil-constants-bypassing-defenses-browser-jit-engines$\backslash$npapers3://publication/doi/10.14722/ndss.2015.23209},
year = {2015}
}
@article{helli,
abstract = {Many mechanisms have been proposed and de- ployed to prevent exploits against software vulnerabilities. Among them, W⊕X is one of the most effective and efficient. W⊕X prevents memory pages from being simultaneously writable and executable, rendering the decades old shellcode injection technique infeasible. In this paper, we demonstrate that the traditional shellcode injection attack can be revived through a code cache injection technique. Specifically, dynamic code generation, a technique widely used in just-in-time (JIT) compilation and dynamic binary translation (DBT), generates and modifies code on the fly in order to promote performance or security. The dynamically generated code fragments are stored in a code cache, which is writable and executable either at the same time or alternately, resulting in an opportunity for exploitation. This threat is especially realistic when the generated code is multi-threaded, because switching between writable and executable leaves a time window for exploitation. To illustrate this threat, we have crafted a proof- of-concept exploit against modern browsers that support Web Workers. To mitigate this code cache injection threat, we propose a new dynamic code generation architecture. This new architecture relocates the dynamic code generator to a separate process, in which the code cache is writable. In the original process where the generated code executes, the code cache remains read- only. The code cache is synchronized across the writing process and the execution process through shared memory. Interaction between the code generator and the generated code is handled transparently through remote procedure calls (RPC). We have ported the Google V8 JavaScript engine and the Strata DBT to this new architecture. Our implementation experience showed that the engineering effort for porting to this new architecture is minimal. Evaluation of our prototype implementation showed that this new architecture can defeat the code cache injection attack with small performance overhead.},
author = {Song, Chengyu and Zhang, Chao and Wang, Tielei and Lee, Wenke and Melski, David},
doi = {10.14722/ndss.2015.23233},
isbn = {1-891562-38-X},
journal = {ndss},
pages = {8--11},
title = {{Exploiting and Protecting Dynamic Code Generation}},
url = {http://chao.100871.net/papers/NDSS2015-DCG-CR.pdf$\backslash$nhttp://www.internetsociety.org/doc/exploiting-and-protecting-dynamic-code-generation},
year = {2015}
}
@article{helli,
abstract = {—In the face of widespread DEP and ASLR deploy-ment, JIT spraying brings together the best of code injection and code reuse attacks to defeat both defenses. However, to date, JIT spraying has been an x86-only attack thanks to its reliance on variable-length, unaligned instructions. In this paper, we finally extend JIT spraying to a RISC architecture by introducing a novel technique called gadget chaining, whereby high level code invokes short sequences of unintended and intended instructions called gadgets just like a function call. We demonstrate gadget chaining in an end-to-end JIT spraying attack against WebKit's JavaScriptCore JS engine on ARM and found that existing JIT spray mitigations that were sufficient against the x86 version of the JIT spraying attack fall short in the face of gadget chaining.},
author = {Lian, Wilson and Shacham, Hovav and Savage, Stefan},
doi = {10.14722/ndss.2015.23288},
isbn = {1-891562-38-X},
journal = {ndss},
pages = {1--15},
title = {{Too LeJIT to Quit: Extending JIT Spraying to ARM}},
url = {http://www.internetsociety.org/doc/too-lejit-quit-extending-jit-spraying-arm$\backslash$npapers3://publication/doi/10.14722/ndss.2015.23288},
year = {2015}
}
@article{helli,
author = {Bauer, Lujo and Cai, Shaoying and Jia, Limin and Passaro, Timothy and Stroucken, Michael and Tian, Yuan},
doi = {10.14722/ndss.2015.23295},
isbn = {1-891562-38-X},
journal = {ndss},
pages = {1--15},
title = {{Run-time Monitoring and Formal Analysis of Information Flows in Chromium}},
url = {http://www.internetsociety.org/doc/run-time-monitoring-and-formal-analysis-information-flows-chromium$\backslash$npapers3://publication/doi/10.14722/ndss.2015.23295},
year = {2015}
}
@article{helli,
author = {Vervier, Pierre-antoine and Thonnard, Olivier and Dacier, Marc},
doi = {10.14722/ndss.2015.23035},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Mind Your Blocks : On the Stealthiness of Malicious BGP Hijacks}},
year = {2015}
}
@article{helli,
author = {Dhawan, Mohan and Poddar, Rishabh and Mahajan, Kshiteej and Mann, Vijay},
journal = {ndss},
title = {{SPHINX: Detecting security attacks in software-defined networks}},
year = {2015}
}
@article{helli,
journal = {ndss},
title = {{ Securing the Software Defined Network Control Layer }},
year = {2015}
}
@article{helli,
author = {Hong, Sungmin and Wang, Haopei},
doi = {10.14722/ndss.2015.23283},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Poisoning Network Visibility in Software-Defined Networks: New Attacks and Countermeasures}},
year = {2015}
}
@article{helli,
author = {Shoshitaishvili, Yan and Wang, Ruoyu and Hauser, Christophe and Kruegel, Christopher and Vigna, Giovanni},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{Firmalice - Automatic Detection of Authentication Bypass Vulnerabilities in Binary Firmware}},
year = {2015}
}
@article{helli,
author = {Prakash, Aravind},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{vfGuard : Strict Protection for Virtual Function Calls in COTS C ++ Binaries}},
year = {2015}
}
@article{helli,
author = {Kwon, Yonghwi and Peng, Fei and Kim, Dohyeong and Kim, Kyungtae and Zhang, Xiangyu and Xu, Dongyan},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{P2C : Understanding Output Data Files via On-the-Fly Transformation from Producer to Consumer Executions}},
year = {2015}
}
@article{helli,
author = {Yakdan, Khaled and Eschweiler, Sebastian and Gerhards-padilla, Elmar and Smith, Matthew},
isbn = {189156238X},
journal = {ndss},
number = {February},
pages = {8--11},
title = {{No More Gotos : Decompilation Using Pattern-Independent Control-Flow Structuring and Semantics-Preserving Transformations}},
year = {2015}
}
@article{helli,
author = {Guan, L and Lin, J and Luo, B and Jing, J},
isbn = {1891562355},
journal = {ndss},
keywords = {asymmetric cryptography implementation,cache-as-ram,cold-boot attack,key management},
number = {February},
pages = {23--26},
title = {{Copker: Computing with Private Keys without RAM}},
url = {https://www.internetsociety.org/sites/default/files/07{\_}1{\_}1.pdf},
year = {2014}
}
@article{helli,
author = {Stefanov, E},
isbn = {1891562355},
journal = {ndss},
keywords = {contained in the updated,document,e,g,in terms of space,in this paper we,linear in the,number of documents,or are inefficient,or search,revisit the dsse problem,update time,we propose},
number = {February},
pages = {23--26},
title = {{Practical Dynamic Searchable Encryption with Small Leakage.}},
url = {http://dl.acm.org/citation.cfm?id=2636328$\backslash$nhttp://web.rememberingemil.org/Research/Files/Publications/PrivateSearch.pdf},
year = {2014}
}
@article{helli,
abstract = {This work has been done by outstanding students and advisors. Especially the second author, man, he's a great guy.},
author = {Poeplau, Sebastian and Fratantonio, Yanick and Bianchi, Antonio and Kruegel, Christopher and Vigna, Giovanni},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Execute This! Analyzing Unsafe and Malicious Dynamic Code Loading in Android Applications}},
year = {2014}
}
@article{helli,
abstract = {Real-Time Bidding (RTB) and Cookie Matching (CM) are transforming the advertising landscape to an extremely dynamic market and make targeted advertising considerably permissive. The emergence of these technologies allows companies to exchange user data as a product and therefore raises important concerns from privacy perspectives. In this paper, we perform a privacy analysis of CM and RTB and quantify the leakage of users’ browsing histories due to these mechanisms. We study this problem on a corpus of users’ Web histories, and show that using these technologies, certain companies can significantly improve their tracking and profiling capabilities. We detect 41 companies serving ads via RTB and over 125 using Cookie Matching. We show that 91{\%} of users in our dataset were affected by CM and in certain cases, 27{\%} of users’ histories could be leaked to 3rd-party companies through RTB.We expose a design characteristic of RTB systems to observe the prices which advertisers pay for serving ads to Web users. We leverage this feature and provide important insights into these prices by analyzing different user profiles and visiting contexts. Our study shows the variation of prices according to context information including visiting site, time and user’s physical location. We experimentally confirm that users with known history are evaluated higher than new comers, that some user profiles are more valuable than others, and that users’ intents, such as looking for a commercial product, are sold at higher prices than users’ browsing histories. In addition, we show that there is a huge gap between users’ perception of the value of their personal information and its actual value on the market. A recent study by Carrascal et al. showed that, on average, users evaluate the price of the disclosure of their presence on a Web site to EUR 7. We show that user’s browsing history elements are routinely being sold off for less than {\$}0.0005.},
author = {Olejnik, Lukasz and Castelluccia, Claude and Minh-Dung, Tran},
doi = {10.14722/ndss.2014.23270},
isbn = {1-891562-35-5},
journal = {ndss},
keywords = {advertising,privacy},
pages = {1--14},
title = {{Selling Off Privacy at Auction}},
url = {https://hal.inria.fr/hal-01087557/},
year = {2014}
}
@article{helli,
abstract = {Millions of users are exposed to password-strength meters/checkers at highly popular web services that use user- chosen passwords for authentication. Recent studies have found evidence that some meters actually guide users to choose better passwords—which is a rare bit of good news in password research. However, these meters are mostly based on ad-hoc design. At least, as we found, most vendors do not provide any explanation of their design choices, sometimes making them appear to be a black box. We analyze password meters deployed in selected popular websites, by measuring the strength labels assigned to common passwords from several password dictio- naries. From this empirical analysis with millions of passwords, we report prominent characteristics of meters as deployed at popular websites. We shed light on how the server-end of some meters functions, provide examples of highly inconsistent strength outcomes for the same password in different meters, along with examples of many weak passwords being labeled as strong or even very strong. These weaknesses and inconsistencies may confuse users in choosing a stronger password, and thus may weaken the purpose of these meters. On the other hand, we believe these findings may help improve existing meters, and possibly make them an effective tool in the long run. I.},
author = {Carnavalet, Xavier De Carn{\'{e}} De and Mannan, Mohammad},
doi = {10.14722/ndss.2014.23268},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{From Very Weak to Very Strong : Analyzing Password-Strength Meters}},
year = {2014}
}
@article{helli,
author = {Friedman, Arik and Keren, Daniel},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Privacy-Preserving Distributed Stream Monitoring}},
year = {2014}
}
@article{helli,
abstract = {Hybrid mobile applications (apps) combine the features of Web applications and "native" mobile apps. Like Web applications, they are implemented in portable, platform-independent languages such as HTML and JavaScript. Like native apps, they have direct access to local device resources-file system, location, camera, contacts, etc. Hybrid apps are typically developed using hybrid application frameworks such as PhoneGap. The purpose of the framework is twofold. First, it provides an embedded Web browser (for example, WebView on Android) that executes the app's Web code. Second, it supplies "bridges" that allow Web code to escape the browser and access local resources on the device. We analyze the software stack created by hybrid frameworks and demonstrate that it does not properly compose the access-control policies governing Web code and local code, respectively. Web code is governed by the same origin policy, whereas local code is governed by the access-control policy of the operating system (for example, user-granted permissions in Android). The bridges added by the framework to the browser have the same local access rights as the entire application, but are not correctly protected by the same origin policy. This opens the door to fracking attacks, which allow foreign-origin Web content included into a hybrid app (e.g., ads confined in iframes) to drill through the layers and directly access device resources. Fracking vulnerabilities are generic: they affect all hybrid frameworks, all embedded Web browsers, all bridge mechanisms, and all platforms on which these frameworks are deployed. We study the prevalence of fracking vulnerabilities in free Android apps based on the PhoneGap framework. Each vulnerability exposes sensitive local resources-the ability to read and write contacts list, local files, etc.-to dozens of potentially malicious Web domains. We also analyze the defenses deployed by hybrid frameworks to prevent resource access by foreign-origin Web content and explain why they are ineffectual. We then present NoFrak, a capability-based defense against fracking attacks. NoFrak is platform-independent, compatible with any framework and embedded browser, requires no changes to the code of the existing hybrid apps, and does not break their advertising-supported business model.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Georgiev, Martin and Jana, Suman and Shmatikov, Vitaly},
doi = {10.1016/j.biotechadv.2011.08.021.Secreted},
eprint = {NIHMS150003},
isbn = {2122633255},
issn = {15378276},
journal = {ndss},
pages = {1--15},
pmid = {25485311},
title = {{Breaking and Fixing Origin-Based Access Control in Hybrid Web/Mobile Application Frameworks.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4254737{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2014},
year = {2014}
}
@article{helli,
author = {Cash, David and Jaeger, Joseph and Jarecki, Stanislaw and Jutla, Charanjit and Krawczyk, Hugo and Roşu, Marcel-Cătălin and Steiner, Michael},
doi = {10.14722/ndss.2014.23264},
isbn = {1-891562-35-5},
journal = {ndss},
pages = {1--32},
title = {{Dynamic Searchable Encryption in Very-Large Databases: Data Structures and Implementation}},
url = {http://www.internetsociety.org/doc/dynamic-searchable-encryption-very-large-databases-data-structures-and-implementation},
year = {2014}
}
@article{helli,
author = {Lin, Zhiqiang},
isbn = {1891562355},
journal = {ndss},
pages = {1--15},
title = {{Hybrid-Bridge: Efficiently Bridging the Semantic Gap in Virtual Machine Introspection via Decoupled Execution and Training Memoization}},
url = {http://www.internetsociety.org/doc/hybrid-bridge-efficiently-bridging-semantic-gap-virtual-machine-introspection-decoupled$\backslash$npapers3://publication/doi/10.14722/ndss.2014.23226},
year = {2014}
}
@article{helli,
abstract = {Several defenses have increased the cost of traditional, low-level attacks that corrupt control data, e.g. return addresses saved on the stack, to compromise program execution. In response, creative adversaries have begun circumventing these defenses by exploiting programming errors to manipulate pointers to virtual tables, or vtables, of C++ objects. These attacks can hijack program control flow whenever a virtual method of a corrupted object is called, potentially allowing the attacker to gain complete control of the underlying system. In this paper we present SAFEDISPATCH, a novel defense to prevent such vtable hijacking by statically analyzing C++ programs and inserting sufficient runtime checks to ensure that control flow at virtual method call sites cannot be arbitrarily influenced by an attacker. We implemented SAFEDISPATCH as a Clang++/LLVM extension, used our enhanced compiler to build a vtable-safe version of the Google Chromium browser, and measured the performance overhead of our approach on popular browser benchmark suites. By carefully crafting a handful of optimizations, we were able to reduce average runtime overhead to just 2.1{\%}.},
author = {Jang, Dongseok and Tatlock, Zachary and Lerner, Sorin},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{SAFEDISPATCH : Securing C ++ Virtual Calls from Memory Corruption Attacks}},
year = {2014}
}
@article{helli,
author = {Zhang, Qing and Wang, David Y and Voelker, Geoffrey M},
isbn = {1891562355},
journal = {ndss},
keywords = {and consequently attract more,identify duplicate,in web search results,pages with artificial backlinks,rank of the promoted,search engines seek to,sites,the page,the promoted sites,to penalize them in,traffic to,will increase the page},
number = {February},
pages = {23--26},
title = {{DSpin : Detecting Automatically Spun Content on the Web}},
year = {2014}
}
@article{helli,
abstract = {The security of computer systems often relies upon decisions and actions of end users. In this paper, we set out to investigate user-centered security by concentrating at the most fundamental component governing user behavior – the human brain. We introduce a novel neuroscience-based study methodology to inform the design of user-centered security systems. Specifically, we report on an fMRI study measuring users’ security performance and the underlying neural activity with respect to two critical security tasks: (1) distinguishing between a legitimate and a phishing website, and (2) heeding security (malware) warnings. At a higher level, we identify neural markers that might be controlling users’ performance in these tasks, and establish relationships between brain activity and behavioral performance as well as between users’ personality traits and security behavior. Our results provide a largely positive perspective towards users’ capability and performance vis-{\`{a}}-vis these crucial security tasks. First, we show that users exhibit significant brain activity in key regions associated with decision-making, attention, and problem-solving (phishing and malware warnings) as well as language comprehension and reading (malware warnings), which means that users are actively engaged in these security tasks. Second, we demonstrate that certain individual traits, such as impulsivity measured via an established questionnaire, can have a significant negative effect on brain activation in these tasks. Third, we discover a high degree of correlation in brain activity (in decision-making regions) across phishing detection and malware warnings tasks, which implies that users’ behavior in one task may potentially be predicted by their behavior in the other task. Finally, we discuss the broader impacts and implications of our work on the field of user-centered security, including the domain of security education, targeted security training, and security screening.},
author = {Neupane, Ajaya and Saxena, Nitesh and Kuruvilla, Keya and Georgescu, Michael and Kana, Rajesh},
doi = {10.14722/ndss.2014.23056},
journal = {ndss},
number = {February},
pages = {1--16},
title = {{Neural Signatures of User-Centered Security : An fMRI Study of Phishing , and Malware Warnings}},
year = {2014}
}
@article{helli,
abstract = {As mobile begins to overtake the fixed Internet access, ad networks have aggressively sought methods to track users on their mobile devices. While existing countermeasures and regulation focus on thwarting cookies and various device IDs, this paper submits a hypothesis that smartphone/tablet accelerometers possess unique fingerprints, which can be ex- ploited for tracking users.We believe that the fingerprints arise from hardware imperfections during the sensor manufacturing process, causing every sensor chip to respond differently to the same motion stimulus. The differences in responses are subtle enough that they do not affect most of the higher level func- tions computed on them. Nonetheless, upon close inspection, these fingerprints emerge with consistency, and can even be somewhat independent of the stimulus that generates them. Measurements and classification on 80 standalone accelerom- eter chips, 25 Android phones, and 2 tablets, show precision and recall upward of 96{\%}, along with good robustness to real- world conditions. Utilizing accelerometer fingerprints, a crowd- sourcing application running in the cloud could segregate sensor data for each device, making it easy to track a user over space and time. Such attacks are almost trivial to launch, while simple solutions may not be adequate to counteract them.},
author = {Dey, Sanorita and Roy, Nirupam and Xu, Wenyuan and Choudhury, Romit Roy and Nelakuditi, Srihari},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{AccelPrint: Imperfections of Accelerometers Make Smartphones Trackable}},
url = {http://web.engr.illinois.edu/{~}nroy8/PDF/AccelPrint{\_}Presentation.pdf},
year = {2014}
}
@article{helli,
abstract = {In distributed reflective denial-of-service (DRDoS) attacks, adversaries send requests to public servers (e.g., open recursive DNS resolvers) and spoof the IP address of a victim. These servers, in turn, flood the victim with valid responses and – unknowingly – exhaust its bandwidth. Recently, attackers launched DRDoS attacks with hundreds of Gb/s bandwidth of this kind. While the attack technique is well-known for a few protocols such as DNS, it is unclear if further protocols are vulnerable to similar or worse attacks. In this paper, we revisit popular UDP-based protocols of network services, online games, P2P filesharing networks and P2P botnets to assess their security against DRDoS abuse. We find that 14 protocols are susceptible to bandwidth amplification and multiply the traffic up to a factor 4670. In the worst case, attackers thus need only 0.02{\%} of the bandwidth that they want their victim(s) to receive, enabling far more dangerous attacks than what is known today. Worse, we identify millions of public hosts that can be abused as amplifiers. We then analyze more than 130 real-world DRDoS attacks. For this, we announce bait services to monitor their abuse and analyze darknet as well as network traffic from large ISPs. We use traffic analysis to detect both, victims and amplifiers, showing that attackers already started to abuse vulnerable protocols other than DNS. Lastly, we evaluate countermeasures against DRDoS attacks, such as preventing spoofing or hardening protocols and service configurations. We shows that carefully-crafted DRDoS attacks may evade poorly-designed rate limiting solutions. In addition, we show that some attacks evade packet-based filtering techniques, such as port-, content- or length-based filters},
author = {Rossow, Christian},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Amplification Hell: Revisiting Network Protocols for DDoS Abuse}},
url = {http://www.internetsociety.org/sites/default/files/01{\_}5.pdf},
year = {2014}
}
@article{helli,
abstract = {Cameras are now commonplace in our social and computing landscapes and embedded into consumer devices like smartphones and tablets. A new generation of wearable devices (such as Google Glass) will soon make ‘first-person’ cameras nearly ubiquitous, capturing vast amounts of imagery without deliberate human action. ‘Lifelogging’ devices and applications will record and share images from people’s daily lives with their social networks. These devices that automatically capture images in the background raise serious privacy concerns, since they are likely to capture deeply private information. Users of these devices need ways to identify and prevent the sharing of sensitive images. As a first step, we introduce PlaceAvoider, a technique for owners of first-person cameras to ‘blacklist’ sensitive spaces (like bathrooms and bedrooms). PlaceAvoider recognizes images captured in these spaces and flags them for review before the images are made available to applications. PlaceAvoider performs novel image analysis using both fine-grained image features (like specific objects) and coarse-grained, scene-level features (like colors and textures) to classify where a photo was taken. PlaceAvoider combines these features in a probabilistic framework that jointly labels streams of images in order to improve accuracy. We test the technique on five realistic firstperson image datasets and show it is robust to blurriness, motion, and occlusion.},
author = {Templeman, Robert and Korayem, Mohammed and Crandall, David and Apu, Kapadia},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{PlaceAvoider: Steering First-Person Cameras away from Sensitive Spaces}},
url = {https://www.cs.indiana.edu/{~}kapadia/papers/placeavoider-ndss14.pdf},
year = {2014}
}
@article{helli,
abstract = {Anonymous credentials provide a powerful tool for making assertions about identity while maintaining privacy. However, a limitation of today's anonymous credential systems is the need for a trusted credential issuer --- which is both a single point of failure and a target for compromise. Furthermore, the need for such a trusted issuer can make it challenging to deploy credential systems in practice, particularly in the ad hoc network setting (e.g., anonymous peer-to-peer networks) where no single party can be trusted with this responsibility. In this work we propose a novel anonymous credential scheme that eliminates the need for a trusted credential issuer. Our approach builds on recent results in the area of electronic cash and uses techniques --- such as the calculation of a distributed transaction ledger --- that are currently in widespread deployment in the Bitcoin payment system. Using this decentralized ledger and standard cryptographic primitives, we propose and provide a proof of security for a basic anonymous credential system that allows users to make flexible identity assertions with strong privacy guarantees. Finally, we discuss a number of practical applications for our techniques, including resource management in ad hoc networks and prevention of Sybil attacks. We implement our scheme and measure its efficiency.},
author = {Garman, Christina and Green, Matthew and Miers, Ian},
isbn = {1891562355},
journal = {ndss},
pages = {622},
title = {{Decentralized Anonymous Credentials.}},
volume = {2013},
year = {2014}
}
@article{helli,
author = {Shirvanian, Maliheh and Jarecki, Stanislaw and Nathan, Naveen},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Two-Factor Authentication Resilient to Server Compromise Using Mix-Bandwidth Devices}},
year = {2014}
}
@article{helli,
author = {Zaddach, Jonas and Bruno, Luca and Francillon, Aur{\'{e}}lien and Balzarotti, Davide},
doi = {10.14722/ndss.2014.23229},
isbn = {1-891562-35-5},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Avatar: A Framework to Support Dynamic Security Analysis of Embedded Systems' Firmwares}},
url = {http://dx.doi.org/10.14722/ndss.2014.23229},
year = {2014}
}
@article{helli,
abstract = {—In this paper, we systematically explore the widely held, anecdotal belief that mismanaged networks are responsible for a wide range of security incidents. Utilizing Internet-scale measurements of DNS resolvers, BGP routers, and SMTP, HTTP, and DNS-name servers, we find there are thousands of networks where a large fraction of network services are misconfigured. Combining global feeds of malicious activities including spam, phishing, malware, and scanning, we find a statistically significant correlation between networks that are mismanaged and networks that are responsible for maliciousness.},
author = {Zhang, Jing and Durumeric, Zakir and Bailey, Michael},
doi = {10.14722/ndss.2014.23057},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{On the Mismanagement and Maliciousness of Networks}},
url = {http://web.eecs.umich.edu/{~}jingzj/paper/jing{\_}ndss14.pdf},
year = {2014}
}
@article{helli,
author = {Dietz, Michael and Wallach, Ds},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Hardening Persona–Improving Federated Web Login}},
url = {http://www.internetsociety.org/sites/default/files/08{\_}2{\_}0.pdf},
year = {2014}
}
@article{helli,
author = {Sun, Fangqi},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Detecting Logic Vulnerabilities in E-Commerce Applications}},
year = {2014}
}
@article{helli,
abstract = {{\#}SMV-HUNTER. SMV= SSL MITM Vuln. Static analysis component to detect potentially vulneralbe apps. Dynamic component that checks how the "important" part behaves. Completely automatic.},
author = {Sounthiraraj, David and Sahs, Justin and Greenwood, Garret and Lin, Zhiqiang and Khan, Latifur},
doi = {10.14722/ndss.2014.23205},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{SMV-HUNTER: Large Scale, Automated Detection of SSL/TLS Man-in-the-Middle Vulnerabilities in Android Apps}},
year = {2014}
}
@article{helli,
abstract = {Decoy routing is a recently proposed approach for censorship circumvention. It relies on cooperating ISPs in the middle of the Internet to deploy the so called “decoy routers” that proxy network traffic from users in the censorship region. A recent study, published in an award-winning CCS 2012 paper [24], suggested that censors in highly connected countries like China can easily defeat decoy routing by selecting Internet routes that do not pass through the decoys. This attack is known as “routing around decoys” (RAD). In this paper, we perform an in-depth analysis of the true costs of the RAD attack, based on actual Internet data. Our analysis takes into account not just the Internet topology, but also business relationships between ISPs, monetary and performance costs of different routes, etc. We demonstrate that even for the most vulnerable decoy placement assumed in the RAD study, the attack is likely to impose tremendous costs on the censoring ISPs. They will be forced to switch to much more costly routes and suffer from degradation in the quality of service. We then demonstrate that a more strategic placement of decoys will further increase the censors’ costs and render the RAD attack ineffective. We also show that the attack is even less feasible for censors in countries that are not as connected as China since they have many fewer routes to choose from. The first lesson of our study is that defeating decoy routing by simply selecting alternative Internet routes is likely to be prohibitively expensive for the censors. The second, even more important lesson is that a fine-grained, data-driven approach is necessary for understanding the true costs of various route selection mechanisms. Analyses based solely on the graph topology of the Internetmay lead tomistaken conclusions about the feasibility of decoy routing and other censorship circumvention techniques based on interdomain routing.},
author = {Houmansadr, Amir and Wong, Edmund L and Shmatikov, Vitaly},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{No Direction Home: The True Cost of Routing Around Decoys}},
year = {2014}
}
@article{helli,
author = {Veras, Rafael and Collins, Christopher and Thorpe, Julie},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{On the Semantic Patterns of Passwords and their Security Impact}},
url = {http://www.internetsociety.org/doc/semantic-patterns-passwords-and-their-security-impact},
year = {2014}
}
@article{helli,
author = {Invernizzi, Luca and Miskovic, Stanislav and Torres, Ruben and Saha, Sabyasachi and Lee, Sung-Ju and Mellia, Marco and Kruegel, Christopher and Vigna, Giovanni},
isbn = {1891562355},
journal = {ndss},
pages = {1--16},
title = {{Nazca: Detecting Malware Distribution in Large-Scale Networks}},
url = {http://seclab.cs.ucsb.edu/academic/publishing/$\backslash$npapers3://publication/uuid/653F4B27-3700-4D2F-8CCE-4DA53A7C817C},
year = {2014}
}
@article{helli,
abstract = {Controlled sharing is fundamental to distributed systems; yet, on the Web, and in the Cloud, sharing is still based on rudimentary mechanisms. More flexible, decentralized cryptographic authorization credentials have not been adopted, largely because their mechanisms have not been incrementally deployable, simple enough, or efficient enough to implement across the relevant systems and devices. This paper introduces macaroons: flexible authorization cre- dentials for Cloud services that support decentralized delegation between principals. Macaroons are based on a construction that uses nested, chained MACs (e.g., HMACs [43]) in a manner that is highly efficient, easy to deploy, and widely applicable. Although macaroons are bearer credentials, like Web cookies, macaroons embed caveats that attenuate and contextually confine when, where, by who, and for what purpose a target service should authorize requests. This paper describes macaroons and motivates their design, compares them to other credential systems, such as cookies and SPKI/SDSI [14], evaluates and measures a prototype implementation, and discusses practical security and application considerations. In particular, it is considered how macaroons can enable more fine-grained authorization in the Cloud, e.g., by strengthening mechanisms like OAuth2 [17], and a formalization of macaroons is given in authorization logic.},
author = {Birgisson, Arnar and Politz, Joe Gibbs and Taly, Ankur and Vrable, Michael and Lentczner, Mark},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Macaroons : Cookies with Contextual Caveats for Decentralized Authorization in the Cloud}},
year = {2014}
}
@article{helli,
author = {Pellegrino, Giancarlo and Balzarotti, Davide},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Toward Black-Box Detection of Logic Flaws in Web Applications}},
url = {http://s3.eurecom.fr/docs/ndss14{\_}pellegrino.pdf},
year = {2014}
}
@article{helli,
author = {Bates, Adam and Leonard, Ryan and Pruse, Hannah and Lowd, Daniel and Butler, Kevin R B},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Leveraging USB to Establish Host Identity Using Commodity Devices}},
year = {2014}
}
@article{helli,
abstract = {he most widely used secure Internet communication standard TLS (Transport Layer Security) has an optional client certificate authentication feature that in theory has significant security advantages over HTML form-based password authenti- cation. In this paper we discuss practical security and usability issues related to TLS client certificate authentication stemming from the server-side and browser implementations. In particular, we analyze Apache’s mod{\_}ssl implementation on the server side and the most popular browsers – Mozilla Firefox, Google Chrome and Microsoft Internet Explorer on the client side. We complement our paper with a measurement study performed in Estonia where TLS client certificate authentication is widely used. We present our recommendations to improve the security and usability of TLS client certificate authentication},
author = {Parsovs, Arnis},
doi = {10.14722/ndss.2014.23036},
isbn = {1891562355},
journal = {ndss},
title = {{Practical Issues with TLS Client Certificate Authentication}},
url = {http://www.internetsociety.org/sites/default/files/12{\_}4{\_}1.pdf},
year = {2014}
}
@article{helli,
abstract = {Abstract—Recent research results on tree-based Oblivious RAM by Shi et al. [15] obtain communication complexity of O(l · log3(N)) in the worst-case for an N-capacity storage with blocks size l. The individual nodes in the tree, however, are constructed using traditional ORAMs which have worst-case communication complexity linear in their capacity and block size. PIR protocols are able to provide better worst-case bounds (decoupling capacity from block size), but have traditionally been less practical than ORAM due to the fact that they require O(N) computational complexity on the server. This paper presents Path-PIR, a hybrid ORAM construction, using techniques from PIR, that overcomes the individual weaknesses of each. Path-PIR significantly reduces communication complexity when the block size of the ORAM is large. Compared to existing work, this leads to smaller data transfer costs by orders of magnitude for practical sized databases and achieves worst-case communication complexity of O(l · log2 (N)) for large block sizes. Additionally, the typically high computational cost of PIR is negated by the tree structure of the ORAM, which requires only a small fraction of the database to be operated on for each query. We also investigate the concept of an ORAM’s latency, which is the amount of communication required before users receive the result of their query. We show that Path-PIR achieves lower latency than any existing scheme, only about four times the block size. Using Amazon EC2 as an example, we demonstrate that even with the additional cost of PIR computation, Path-PIR provides a significant monetary saving compared to related work.},
author = {Mayberry, T. and Blass, E.-O. and Chan, a. H.},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Efficient private file retrieval by combining ORAM and PIR}},
url = {https://eprint.iacr.org/2013/086.pdf},
year = {2014}
}
@article{helli,
author = {Ryan, Mark D},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Enhanced certificate transparency and end-to-end encrypted mail}},
url = {https://www.cs.bham.ac.uk/{~}mdr/research/papers/pdf/14-ndss-cert.pdf},
year = {2014}
}
@article{helli,
abstract = {Cybercriminals use different types of geographi-cally distributed servers to run their operations such as C{\&}C servers for managing their malware, exploit servers to distribute the malware, payment servers for monetization, and redirectors for anonymity. Identifying the server infrastructure used by a cybercrime operation is fundamental for defenders, as it enables take-downs that can disrupt the operation and is a critical step towards identifying the criminals behind it. In this paper, we propose a novel active probing approach fordetecting malicious servers and compromised hosts that listen for (and react to) incoming network requests. Our approach sends probes to remote hosts and examines their responses, determining whether the remote hosts are malicious or not. It identifies different malicious server types as well as malware that listens for incoming traffic such as P2P bots. Compared with existing defenses, our active probing approach is fast, cheap, easy to deploy, and achieves Internet scale. We have implemented our active probing approach in atool called CyberProbe. We have used CyberProbe to identify 151 malicious servers and 7,881 P2P bots through 24 localized and Internet-wide scans. Of those servers 75{\%} are unknown to publicly available databases of malicious servers, indicating that CyberProbe can achieve up to 4 times better coverage than existing techniques. Our results reveal an important provider locality property: operations hosts an average of 3.2 servers on the same hosting provider to amortize the cost of setting up a relationship with the provider.I.},
author = {Nappa, Antonio and Xu, Zhaoyan and Rafique, M Zubair and Caballero, Juan and Gu, Guofei},
doi = {10.14722/ndss.2014.23218},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{CyberProbe : Towards Internet-Scale Active Detection of Malicious Servers}},
year = {2014}
}
@article{helli,
author = {Mclaughlin, Stephen and Zonouz, Saman and Pohly, Devin and Mcdaniel, Patrick},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{A Trusted Safety Verifier for Process Controller Code}},
year = {2014}
}
@article{helli,
abstract = {Today’s Internet services rely heavily on text-based passwords for user authentication. The pervasiveness of these services coupled with the difficulty of remembering large numbers of secure passwords tempts users to reuse passwords at multiple sites. In this paper, we investigate for the first time how an attacker can leverage a known password from one site to more easily guess that user’s password at other sites. We study several hundred thousand leaked passwords from eleven web sites and conduct a user survey on password reuse; we estimate that 43- 51{\%} of users reuse the same password across multiple sites. We further identify a few simple tricks users often employ to transform a basic password between sites which can be used by an attacker to make password guessing vastly easier. We develop the first cross-site password-guessing algorithm, which is able to guess 30{\%} of transformed passwords within 100 attempts compared to just 14{\%} for a standard password-guessing algorithm without cross-site password knowledge.},
author = {Das, Anupam and Bonneau, Joseph and Caesar, Matthew and Borisov, Nikita and Wang, Xf},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{The Tangled Web of Password Reuse}},
url = {http://www.jbonneau.com/doc/DBCBW14-NDSS-tangled{\_}web.pdf},
year = {2014}
}
@article{helli,
abstract = {{\#}Appsealer. They do patching of component-hijacking vulnerabilities. Example: an attacker might specify a URL (in an intent) used by the application. They modify bytecode to do taint analysis. if something reaches the sink. boom!},
author = {Zhang, Mu and Yin, Heng},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{AppSealer: Automatic Generation of Vulnerability-Specific Patches for Preventing Component Hijacking Attacks in Android Applications}},
year = {2014}
}
@article{helli,
abstract = {Recent years have experienced explosive growth of smartphone sales. Inevitably, the rise in the popularity of smartphones also makes them an attractive target for attacks. In light of these threats, current mobile platform providers have developed various server-side vetting processes to block malicious applications (“apps”). While helpful, they are still far from ideal in achieving their goals. To make matters worse, the presence of alternative (less-regulated) mobile marketplaces also opens up new attack vectors, which necessitate client-side solutions (e.g., mobile anti-virus software) to run on mobile devices. However, existing client-side solutions still exhibit limitations in their capability or deployability. In this paper, we present AirBag, a lightweight OS-level virtualization approach to enhance the popular Android platform and boost our defense capability against mobile malware infection. Assuming a trusted smartphone OS kernel and the fact that untrusted apps will be eventually installed onto users’ phones, AirBag is designed to isolate and prevent them from infecting our normal systems (e.g., corrupting the phone firmware) or stealthily leaking private information. More specifically, by dynamically creating an isolated runtime environment with its own dedicated namespace and virtualized system resources, AirBag not only allows for transparent execution of untrusted apps, but also effectively mediates their access to various system resources or phone functionalities (e.g., SMSs or phone calls). We have implemented a proof-of-concept prototype on three representative mobile devices, i.e., Google Nexus One, Nexus 7, and Samsung Galaxy S III. The evaluation results with a number of untrusted apps, including real-world mobile malware, demonstrate its practicality and effectiveness},
author = {Wu, Chiachih and Zhou, Yajin and Patel, Kunal and Liang, Zhenkai and Jiang, Xuxian},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{AirBag: Boosting Smartphone Resistance to Malware Infection}},
url = {http://www.csc.ncsu.edu/faculty/jiang/pubs/NDSS14{\_}AIRBAG.pdf},
year = {2014}
}
@article{helli,
abstract = {{\#}SUSI. They do static analysis (machine learning) to detect sources and sinks, and they categorized them. Features: method name, parameters, value type, parameter type (is interface?), modifiers, class modifiers, name, dataflow to return, dataflow to return, to sink, abstract sink, required permission. For category, class name, method invocation, body contents, parameter type and return value type.},
author = {Rasthofer, Siegfried and Arzt, Steven and Bodden, Eric},
isbn = {1891562355},
journal = {ndss},
pages = {23--26},
title = {{A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks}},
year = {2014}
}
@article{helli,
author = {Kim, Yongdae and Park, Kyoungsoo},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Gaining Control of Cellular Traffic Accounting by Spurious TCP Retransmission}},
year = {2014}
}
@article{helli,
author = {Rasmussen, Kasper B},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Authentication Using Pulse-Response Biometrics}},
year = {2014}
}
@article{helli,
abstract = {{\#}Drebin. They do lightweight static analysis. Pretty fast (10 secs/app), and they explain their detection results. Detection: 94{\%}. FP: 1{\%}. Bunch of features: hardware components, requested permissions, app components, filtered intents, restricted API calls (for which permission is required, but the app doesn't. maybe it has a root exploit), used permissions, suspicious API calls, network addresses.},
author = {Arp, Daniel and Spreitzenbarth, Michael and Malte, Hubner and Gascon, Hugo and Rieck, Konrad},
doi = {10.14722/ndss.2014.23247},
isbn = {1891562355},
journal = {ndss},
pages = {23--26},
title = {{Drebin: Effective and Explainable Detection of Android Malware in Your Pocket}},
year = {2014}
}
@article{helli,
abstract = {The World Wide Web grew rapidly during the last decades and is used by millions of people every day for online shopping, banking, networking, and other activities. Many of these websites are developed with PHP, the most popular scripting language on the Web. However, PHP code is prone to different types of critical security vulnerabilities that can lead to data leakage, server compromise, or attacks against an application’s users. This problem can be addressed by analyzing the source code of the application for security vulnerabilities before the application is deployed on a web server. In this paper, we present a novel approach for the precise static analysis of PHP code to detect security vulnerabilities in web applications. As dismissed by previous work in this area, a comprehensive configuration and simulation of over 900 PHP built-in features allows us to precisely model the highly dynamic PHP language. By performing an intra- and inter-procedural data flow analysis and by creating block and function summaries, we are able to efficiently perform a backward-directed taint analysis for 20 different types of vulnerabilities. Furthermore, string analysis enables us to validate sanitization in a context-sensitive manner. Our method is the first to perform fine-grained analysis of the interaction between different types of sanitization, encoding, sources, sinks, markup contexts, and PHP settings. We implemented a prototype of our approach in a tool called RIPS. Our evaluation shows that RIPS is capable of finding severe vulnerabilities in popular real-world applications: we reported 73 previously unknown vulnerabilities in five well-known PHP applications such as phpBB, osCommerce, and the conference management software HotCRP.},
author = {Dahse, Johannes and Horst, G and Holz, Thorsten},
doi = {10.14722/ndss.2014.23262},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Simulation of Built-in PHP Features for Precise Static Code Analysis}},
year = {2014}
}
@article{helli,
author = {Cheng, Yueqiang and Zhou, Zongwei and Yu, Miao and Ding, Xuhua and Deng, Robert H},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{ROPecker : A Generic and Practical Approach for Defending Against ROP Attacks}},
year = {2014}
}
@article{helli,
abstract = {As protection mechanisms become increasingly ad- vanced, so too does the malware that seeks to circumvent them. Protection mechanisms such as secure boot, stack protection, heap protection, W⊕X, and address space layout randomization have raised the bar for system security. In turn, attack mechanisms have become increasingly sophisticated. Starting with simple instruction pointer manipulation aimed at executing shellcode on the stack, we are now seeing sophisticated attacks that combine complex heap exploitation with techniques such as return-oriented programming (ROP). ROP belongs to a family of exploitation techniques called data-only exploitation. This class of exploitation and the malware that is built around it makes use solely of data to manipulate the control flow of software without introducing any code. This advanced form of exploitation cir- cumvents many of the modern protection mechanisms presented above, however it has had, until now, one limitation. Due to the fact that it introduces no code, it is very difficult to achieve any sort of persistence. Placing a function hook is straightforward, but where should this hook point to if the malware introduces no code? There are many challenges that must first be overcome if one wishes to answer this question. In this paper, we present the first persistent data-only malware proof of concept in the form of a persistent rootkit. We also present several methods by which one can achieve persistence beyond our proof of concept.},
author = {Vogl, Sebastian and Pfoh, Jonas and Kittel, Thomas and Eckert, Claudia},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Persistent Data-only Malware: Function Hooks without Code}},
year = {2014}
}
@article{helli,
author = {Schulz, Matthias and Loch, Adrian and Hollick, Matthias},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Practical Known-Plaintext Attacks against Physical Layer Security in Wireless MIMO Systems}},
year = {2014}
}
@article{helli,
abstract = {Today’s smartphones can be armed with many types of external devices, such as medical devices and credit card readers, that enrich their functionality and enable them to be used in application domains such as healthcare and retail. This new development comes with new security and privacy challenges. Existing phone-based operating systems, Android in particular, are not ready for protecting authorized use of those external devices: indeed, any app on an Android phone that acquires permission to utilize communication channels like Bluetooth and Near Field Communications is automatically given the access to devices communicating with the phone on these channels.},
author = {Naveed, Muhammad and Zhou, Xiaoyong and Demetriou, Soteris},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Inside Job: Understanding and Mitigating the Threat of External Device Mis-Bonding on Android}},
url = {http://sharps.org/wp-content/uploads/NAVEED-NDSS.pdf},
year = {2014}
}
@article{helli,
author = {Park, Youngsam and Jones, Jackie and Mccoy, Damon and Shi, Elaine and Jakobsson, Markus},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Scambaiter : Understanding Targeted Nigerian Scams on Craigslist}},
year = {2014}
}
@article{helli,
author = {Arapinis, Myrto and Mancini, Loretta Ilaria and Ritter, Eike and Ryan, Mark},
doi = {10.14722/ndss.2014.23082},
isbn = {1-891562-35-5},
journal = {ndss},
title = {{Privacy through Pseudonymity in Mobile Telephony Systems}},
url = {http://www.internetsociety.org/doc/privacy-through-pseudonymity-mobile-telephony-systems},
year = {2014}
}
@article{helli,
abstract = {<p>A string of recent attacks against the global public key infrastructure (PKI)$\backslash$nhas brought to light weaknesses in the certification authority (CA) system. In$\backslash$nresponse, the CA/Browser Forum, a consortium of certification authorities and$\backslash$nbrowser vendors, published in 2011 a set of requirements applicable to all$\backslash$ncertificates intended for use on the Web and issued after July 1st, 2012,$\backslash$nfollowing the successful adoption of the extended validation guidelines in 2007.$\backslash$nWe evaluate the actual level of adherence to the CA/Browser Forum guidelines over$\backslash$ntime, as well as the impact of each violation, by inspecting a large collection$\backslash$nof certificates gathered from Web crawls. We further refine our analysis by$\backslash$nautomatically deriving profile templates that characterize the makeup of$\backslash$ncertificates per issuer. By integrating these templates with violation$\backslash$nstatistics, we are able to depict the practices of certification authorities$\backslash$nworldwide, and thus to monitor the PKI and proactively detect major violations.$\backslash$nOur method also provides new means of assessing the trustworthiness of SSL$\backslash$ncertificates used on the Web.</p>},
author = {Delignat-Lavaud, Antoine and Abadi, Martin and Birrell, Andrew and Mironov, Ilya and Wobber, Ted and Xie, Yinglian},
doi = {10.14722/ndss.2014.23305},
isbn = {1891562355},
journal = {ndss},
title = {{Web PKI: Closing the Gap between Guidelines and Practices}},
url = {http://research.microsoft.com/apps/pubs/default.aspx?id=206278},
year = {2014}
}
@article{helli,
author = {Jang, Yeongjin and Chung, Simon P and Payne, Bryan D and Lee, Wenke},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Gyrus : A Framework for User-Intent Monitoring of Text-Based Networked Applications}},
year = {2014}
}
@article{helli,
abstract = {Name-Screenmilker. They found that many apps on the store that say "we can do screenshots" were asking the user to install a component through ADB in an unsafe way. This leads to an unprivileged app able to take screenshots. They show how they can steal passwords.},
author = {Lin, Chia-chi and Li, Hongyang and Zhou, Xiaoyong and Wang, Xiaofeng},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Screenmilker: How to Milk Your Android Screen for Secrets}},
url = {http://www.internetsociety.org/doc/screenmilker-how-milk-your-android-screen-secrets$\backslash$npapers3://publication/uuid/86978FD8-3404-486B-890F-AC4F6566E314},
year = {2014}
}
@article{helli,
author = {Chen, Bo},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Auditable Version Control Systems}},
year = {2014}
}
@article{helli,
author = {Huang, Danny Yuxing and Dharmdasani, Hitesh and Meiklejohn, Sarah and Dave, Vacha and Grier, Chris and McCoy, Damon and Savage, Stefan and Weaver, Nicholas},
doi = {10.14722/ndss.2014.23044},
isbn = {1891562355},
journal = {ndss},
pages = {1--16},
title = {{Botcoin: Monetizing Stolen Cycles}},
url = {http://cryptosec.ucsd.edu/$\backslash$npapers3://publication/uuid/A53200AE-1204-4F77-A786-BEB96C351F1E},
year = {2014}
}
@article{helli,
abstract = {Tor is a distributed onion-routing network used for achieving anonymity and resisting censorship online. Because of Tor’s growing popularity, it is attracting increasingly larger threats against which it was not securely designed. In this paper, we present the Sniper Attack, an extremely low cost but highly destructive denial of service attack against Tor that an adversary may use to anonymously disable arbitrary Tor relays. The attack utilizes valid protocol messages to boundlessly consume memory by exploiting Tor’s end-to-end reliable data transport. We design and evaluate a prototype of the attack to show its feasibility and efficiency: our experiments show that an adversary may consume a victim relay’s memory by as much as 2187 KiB/s while using at most only 92 KiB/s of upstream bandwidth. We extend our experimental results to estimate the threat against the live Tor network and find that a strategic adversary could disable all of the top 20 exit relays in only 29 minutes, thereby reducing Tor’s bandwidth capacity by 35 percent. We also show how the attack enables the deanonymization of hidden services through selective denial of service by forcing them to choose guard nodes in control of the adversary. Finally, we discuss defenses against the Sniper Attack that provably render the attack ineffective, and suggest defenses against deanonymization by denial-of-service attacks in general that significantly mitigate the threat. I.},
author = {Jansen, Rob and Johnson, Aaron},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{The Sniper Attack : Anonymously Deanonymizing and Disabling the Tor Network}},
year = {2014}
}
@article{helli,
author = {Zhang, Xu and Wang, Haining and Xu, Zichen and Wang, Xiaorui},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Power Attack : An Increasing Threat to Data Centers}},
year = {2014}
}
@article{helli,
author = {Marforio, Claudio and Karapanos, Nikolaos and Soriente, Claudio},
isbn = {1891562355},
journal = {ndss},
number = {February},
pages = {23--26},
title = {{Smartphones as Practical and Secure Location Verification Tokens for Payments}},
year = {2014}
}
@article{helli,
author = {Bost, Raphael and Popa, Raluca Ada and Tu, Stephen and Goldwasser, Shafi},
journal = {ndss},
pages = {331},
title = {{Machine Learning Classification over Encrypted Data.}},
url = {http://eprint.iacr.org/2014/331$\backslash$npapers3://publication/uuid/5BBD0286-B601-4574-8351-32F80D866F5B},
year = {2014}
}
@article{helli,
author = {Mittal, Prateek and Wright, Matthew and Borisov, Nikita},
journal = {ndss},
title = {{Pisces: Anonymous Communication Using Social Networks}},
year = {2013}
}
@article{helli,
archivePrefix = {arXiv},
arxivId = {cs.CR/1208.6189},
author = {Mittal, Prateek and Song, Dawn},
eprint = {1208.6189},
journal = {ndss},
number = {Section 4},
primaryClass = {cs.CR},
title = {{Preserving Link Privacy in Social Network Based Systems}},
year = {2013}
}
@article{helli,
abstract = {gnuplot plot},
author = {Rajab, Moheeb Abu and Ballard, Lucas and Lutz, No{\'{e}} and Mavrommatis, Panayiotis and Provos, Niels},
journal = {ndss},
pages = {1--15},
title = {{CAMP: Content-Agnostic Malware Protection}},
url = {papers3://publication/uuid/9171D40B-4CF1-4450-A6F2-43BF1CFC397F},
year = {2013}
}
@article{helli,
abstract = {Abstract Much of the attention surrounding mobile malware has focused on the in-depth analysis of malicious applications. While bringing the community valuable information about the methods used and data targeted by malware writers, such work has not yet been able  ...},
author = {Lever, C and Antonakakis, M and Reaves, B and Traynor, P and Lee, W},
journal = {ndss},
title = {{The Core of the Matter: Analyzing Malicious Traffic in Cellular Carriers.}},
url = {http://internetsociety.org/doc/core-matter-analyzing-malicious-traffic-cellular-carriers$\backslash$npapers3://publication/uuid/5BCD1CDA-0C53-498B-88B5-82AF6B49E1E3},
year = {2013}
}
@article{helli,
abstract = {As social networking sites have risen in popularity, cyber-criminals started to exploit these sites to spread malware and to carry out scams. Previous work has extensively studied the use of fake (Sybil) accounts that attackers set up to distribute spam messages (mostly messages that contain links to scam pages or drive-by download sites). Fake accounts typically exhibit highly anomalous behavior, and hence, are relatively easy to detect. As a response, attackers have started to compromise and abuse legitimate accounts. Compromising legitimate accounts is very effective, as attackers can leverage the trust relationships that the account owners have established in the past. Moreover, compromised accounts are more difficult to clean up because a social network provider cannot simply delete the corresponding profiles. In this paper, we present a novel approach to detect compromised user accounts in social networks, and we apply it to two popular social networking sites, Twitter and Facebook. Our approach uses a composition of statistical modeling and anomaly detection to identify accounts that experience a sudden change in behavior. Since behavior changes can also be due to benign reasons (e.g., a user could switch her preferred client application or post updates at an unusual time), it is necessary to derive a way to distinguish between malicious and legitimate changes. To this end, we look for groups of accounts that all experience similar changes within a short period of time, assuming that these changes are the result of a malicious campaign that is unfolding. We developed a tool, called COMPA, that implements our approach, and we ran it on a large-scale dataset of more than 1.4 billion publicly-available Twitter messages, as well as on a dataset of 106 million Facebook messages},
archivePrefix = {arXiv},
arxivId = {1509.03531},
author = {Egele, Manuel and Stringhini, Gianluca and Kruegel, Christopher and Vigna, Giovanni},
doi = {10.1.1.363.6606},
eprint = {1509.03531},
issn = {1545-5971},
journal = {ndss},
title = {{COMPA: Detecting Compromised Accounts on Social Networks.}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.363.6606},
year = {2013}
}
@article{helli,
abstract = {Access-control policies in Web applications ensure that only authorized users can perform security-sensitive oper- ations. These policies usually check user credentials be- fore executing actions such as writing to the database or navigating to privileged pages. Typically, every Web ap- plication uses its own, hand-crafted program logic to en- force access control. Within a single application, this logic can vary between different user roles, e.g., administrator or regular user. Unfortunately, developers forget to include proper access-control checks, a lot. This paper presents the design and implementation of FIXMEUP, a static analysis and transformation tool that finds access-control errors of omission and produces can- didate repairs. FIXMEUP starts with a high-level specifi- cation that indicates the conditional statement of a correct access-control check and automatically computes an inter- procedural access-control template (ACT), which includes all program statements involved in this instance of access- control logic. The ACT serves as both a low-level policy specification and a program transformation template. FIX- MEUP uses the ACT to find faulty access-control logic that misses some or all of these statements, inserts only the miss- ing statements, and ensures that unintended dependences did not change the meaning of the access-control policy. FIXMEUP then presents the transformed program to the de- veloper, who decides whether to accept the proposed repair. Our evaluation on ten real-world PHP applications shows that FIXMEUP is capable of finding subtle access- control bugs and performing semantically correct repairs.},
author = {Son, Sooel and Mckinley, Kathryn S},
journal = {ndss},
title = {{Fix Me Up : Repairing Access-Control Bugs in Web Applications}},
year = {2013}
}
@article{helli,
author = {Zanetti, Davide and Capkun, Srdjan and Juels, Ari},
journal = {ndss},
title = {{Tailing RFID Tags for Clone Detection}},
year = {2013}
}
@article{helli,
author = {Houmansadr, A and Riedl, Thomas},
journal = {ndss},
keywords = {-internet censorship,circumvention,voip},
title = {{I want my voice to be heard: IP over Voice-over-IP for unobservable censorship circumvention}},
url = {http://www.freehaven.net/anonbib/cache/ndss13-freewave.pdf},
year = {2013}
}
@article{helli,
author = {Ateniese, G and Bianchi, G and Capossele, a and Petrioli, C},
journal = {ndss},
title = {{Low-cost Standard Signatures in Wireless Sensor Networks: A Case for Reviving Pre-computation Techniques?}},
url = {http://senseslab.di.uniroma1.it/administrator/components/com{\_}jresearch/files/publications/06{\_}5.pdf},
year = {2013}
}
@article{helli,
abstract = {Abstract—A web application today often utilizes web APIs to incorporate third-party services into its functionality. Such API integration, however, is full of security perils: recent studies show that popular web sites using high-profile web services, such as PayPal/Amazon  ...},
author = {Xing, L and Xing, Luyi and Chen, Yangyi and Chen, Y and Wang, XiaoFeng and Chen, Shuo and Wang, X F and Chen, S},
journal = {ndss},
title = {{InteGuard: Toward Automatic Protection of Third-Party Web Service Integrations.}},
url = {http://internetsociety.org/doc/integuard-toward-automatic-protection-third-party-web-service-integrations$\backslash$npapers3://publication/uuid/EA51108B-E9B8-458C-A8A5-3F7EE4581284},
year = {2013}
}
@article{helli,
author = {Cochran, Robert A and Reiter, Michael K},
journal = {ndss},
pages = {1--16},
title = {{Toward Online Verification of Client Behavior in Distributed Applications}},
url = {papers3://publication/uuid/14914D29-ACE3-425A-9E15-C72B21FD8AEB},
year = {2013}
}
@article{helli,
author = {Wang, Q and Lin, Z},
journal = {ndss},
title = {{rbridge: User reputation based tor bridge distribution with privacy preservation}},
url = {https://www.internetsociety.org/sites/default/files/09{\_}2{\_}0.pdf},
year = {2013}
}
@article{helli,
abstract = {Internet traffic is exposed to potential eavesdroppers. Standard encryption mechanisms do not provide sufficient protection: Features such as packet sizes and numbers re- main visible, opening the door to so-called side-channel at- tacks against web traffic. This paper develops a framework for the derivation of formal guarantees against traffic side-channels. We present a model which captures important characteristics of web traffic, and we define measures of security based on quanti- tative information flow. Leaning on the well-studied proper- ties of these measures, we provide an assembly kit for coun- termeasures and their security guarantees, and we show that security guarantees are preserved on lower levels of the protocol stack. We further propose a novel technique for the efficient derivation of security guarantees for web applications. The key novelty of this technique is that it provides guaran- tees that cover all execution paths in a web application, i.e. it achieves completeness. We demonstrate the utility of our techniques in two case studies, where we derive for- mal guarantees for the security of a medium-sized regional- language Wikipedia and an auto-complete input field},
author = {Kopf, Mbgdb},
journal = {ndss},
title = {{Preventing Side-Channel Leaks in Web Traffic: A Formal Approach}},
url = {http://internetsociety.org/sites/default/files/04{\_}2{\_}0.pdf},
year = {2013}
}
@article{helli,
abstract = {ContentScope. They detect apps that expose access to content providers. Two types of vulnerability: passive content leaks (an external app can access something contained in the content provider), content pollution (an external app can inject data in security-related content-provider). How: they detect "start" (ContentProvider.{\{}query,insert{\}}), and "terminals" SQLiteQueryBuilder.{\{}query,rawQuery{\}}. Implementation: "path-sensitive data-flow analysis along execution paths from start functions to terminal functions, so that we can automatically derive necessary constraints and prepare “appropriate” inputs to evaluate the presence of content leakage or pollution vulnerabilities."},
author = {Zhou, Yajin and Jiang, Xuxian},
journal = {ndss},
keywords = {Android,content pollution,exploitable content provider interface,passive content leaks,smartphone privacy,vulnerability},
number = {October},
title = {{Detecting Passive Content Leaks and Pollution in Android Applications}},
url = {http://internetsociety.org/doc/detecting-passive-content-leaks-and-pollution-android-applications$\backslash$npapers3://publication/uuid/6D9E29C4-6036-463C-9B8A-489E7854E597},
year = {2013}
}
@article{helli,
author = {Henry, Ryan and Huang, Yizhou and Goldberg, Ian},
journal = {ndss},
keywords = {oblivious transfer,privacy-enhancing technologies,private information retrieval,symmetric pir,usable pir,zero-knowledge proofs},
title = {{One (Block) Size Fits All: PIR and SPIR with Variable-Length Records via Multi-Block Queries.}},
year = {2013}
}
@article{helli,
author = {Cassola, Aldo and Robertson, William and Kirda, Engin and Noubir, Guevara},
journal = {ndss},
pages = {1--15},
title = {{A Practical, Targeted, and Stealthy Attack Against WPA Enterprise Authentication}},
url = {http://iseclab.org/publications.html$\backslash$npapers3://publication/uuid/1E0CC29B-B87E-4DB2-B044-2C9E1280B246},
year = {2013}
}
@article{helli,
abstract = {{\#}Pegasus. They have a system to generate a Permission Event Graph, which they construct with static analysis and query using model checking. PEG: A novel abstraction of the context in which events fire, and event-driven manner in which an Android application uses permissions.},
author = {Chen, Kevin Zhijie and Johnson, Noah and D'Silva, Vijay and Dai, Shuaifu and MacNamara, Kyle and Magrino, Tom and Wu, Edward and Rinard, Martin and Song, Dawn},
journal = {ndss},
title = {{Contextual Policy Enforcement in Android Applications with Permission Event Graphs}},
url = {http://internetsociety.org/doc/contextual-policy-enforcement-android-applications-permission-event-graphs$\backslash$npapers3://publication/uuid/AB4947D9-68A5-48A0-8967-B3EFF7C8C43B},
year = {2013}
}
@article{helli,
author = {Wacek, C and Tan, H and Bauer, K and Sherr, M},
journal = {ndss},
title = {{An Empirical Evaluation of Relay Selection in Tor}},
url = {http://www.freehaven.net/anonbib/cache/ndss13-relay-selection.pdf},
year = {2013}
}
@article{helli,
abstract = {Abstract Modern attackers increasingly exploit search engines as a vehicle to identify vulnerabilities and to gather information for launching new attacks. In this paper, we perform a large-scale quantitative analysis on bot queries received by the Bing search engine over  ...},
author = {Zhang, J and Xie, Y and Yu, F and Soukal, D and Lee, W},
journal = {ndss},
title = {{Intention and Origination: An Inside Look at Large-Scale Bot Queries.}},
url = {http://internetsociety.org/doc/intention-and-origination-inside-look-large-scale-bot-queries$\backslash$npapers3://publication/uuid/8408B0D8-A9C8-4F4A-B34F-C6027968469A},
year = {2013}
}
@article{helli,
author = {{\v{S}}rndic, N and Laskov, Pavel},
journal = {ndss},
title = {{Detection of Malicious PDF Files Based on Hierarchical Document Structure}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Detection+of+Malicious+PDF+Files+Based+on+Hierarchical+Document+Structure{\#}0},
year = {2013}
}
@article{helli,
abstract = {The ability to update firmware is a feature that is found in nearly all modern embedded systems. We demonstrate how this feature can be exploited to allow attackers to inject ma- licious firmware modifications into vulnerable embedded devices. We discuss techniques for exploiting such vulnerable functionality and the implementation of a proof of concept printer malware capable of network reconnaissance, data exfiltration and propa- gation to general purpose computers and other embedded device types.We present a case study of the HP-RFU (Remote Firmware Update) LaserJet printer firmware modification vulnerability, which allows arbitrary injection of malware into the printers firmware via standard printed documents. We show vulnerable population data gathered by continuously tracking all publicly accessible printers discovered through an exhaustive scan of IPv4 space. To show that firmware update signing is not the panacea of embedded defense, we present an analysis of known vulnerabilities found in third-party libraries in 373 LaserJet firmware images. Prior research has shown that the design flaws and vulnerabilities presented in this paper are found in other modern embedded systems. Thus, the exploitation techniques presented in this paper can be generalized to compromise other embedded systems.},
author = {Cui, Ang and Costello, Michael and Stolfo, Salvatore J},
journal = {ndss},
keywords = {embedded system exploitation,embedded system rootkit,firmware modifica,hp rfu vulnerability,networks,security our existing,tion attack,we present following},
title = {{When Firmware Modifications Attack : A Case Study of Embedded Exploitation}},
url = {http://ids.cs.columbia.edu/sites/default/files/ndss-2013.pdf},
year = {2013}
}
@article{helli,
abstract = {As smartphones become more pervasive, they are increasingly targeted bymalware. At the same time, each new generation of smartphone featuresincreasingly powerful onboard sensor suites. A new strain of sensor malware hasbeen developing that leverages these sensors to steal information from thephysical environment (e.g., researchers have recently demonstrated how malwarecan listen for spoken credit card numbers through the microphone, or feelkeystroke vibrations using the accelerometer). Yet the possibilities of whatmalware can see through a camera have been understudied. This paper introducesa novel visual malware called PlaceRaider, which allows remote attackers toengage in remote reconnaissance and what we call virtual theft. Throughcompletely opportunistic use of the camera on the phone and other sensors,PlaceRaider constructs rich, three dimensional models of indoor environments.Remote burglars can thus download the physical space, study the environmentcarefully, and steal virtual objects from the environment (such as financialdocuments, information on computer monitors, and personally identifiableinformation). Through two human subject studies we demonstrate theeffectiveness of using mobile devices as powerful surveillance and virtualtheft platforms, and we suggest several possible defenses against visualmalware.},
archivePrefix = {arXiv},
arxivId = {1209.5982},
author = {Templeman, Robert and Templeman, Robert and Rahman, Zahid and Crandall, David J and Rahman, Zahid and Kapadia, Apu and Crandall, David and Kapadia, Apu},
eprint = {1209.5982},
journal = {ndss},
title = {{PlaceRaider: Virtual Theft in Physical Spaces with Smartphones.}},
url = {http://internetsociety.org/doc/placeraider-virtual-theft-physical-spaces-smartphones$\backslash$npapers3://publication/uuid/9D67BC54-C275-4890-8DB8-1F6D645CDC6D},
volume = {cs.CR},
year = {2013}
}
@article{helli,
author = {Jager, Tibor and Paterson, Kenneth G and Somorovsky, Juraj},
journal = {ndss},
title = {{One Bad Apple: Backwards Compatibility Attacks on State-of-the-Art Cryptography}},
year = {2013}
}
@article{helli,
author = {Asghar, Hassan Jameel and Li, Shujun and Steinfeld, Ron and Pieprzyk, Josef},
journal = {ndss},
title = {{Does Counting Still Count? Revisiting the Security of Counting based User Authentication Protocols against Statistical Attacks.}},
url = {http://internetsociety.org/doc/does-counting-still-count-revisiting-security-counting-based-user-authentication-protocols$\backslash$npapers3://publication/uuid/E0B1C654-CCA1-4F4B-886F-C8F4E4A59C19},
year = {2013}
}
@article{helli,
author = {Tian, Jing and Qu, Chengzhang and Xu, Wenyuan and Wang, Song},
journal = {ndss},
title = {{KinWrite : Handwriting-Based Authentication Using Kinect}},
year = {2013}
}
@article{helli,
abstract = {Comment spam has become a popular means for spam- mers to attract direct visits to target websites, or to manip- ulate search ranks of the target websites. Through posting a small number of spam messages on each victim website (e.g., normal websites such as forums, wikis, guestbooks, and blogs, which we term as spam harbors in this paper) but spamming on a large variety of harbors, spammers can not only directly inherit some reputations from these harbors but also avoid content-based detection systems deployed on these harbors. To find such qualified harbors, spammers always have their own preferred ways based on their avail- able resources and the cost (e.g., easiness of automatic post- ing, chances of content sanitization on the website). As a result, they will generate their own relatively stable set of harbors proved to be easy and friendly to post their spam, which we refer to as their spamming infrastructure. Our measurement also shows that for different spammers, their spamming infrastructures are typically different, although sometimes with some overlap. This paper presents NEIGHBORWATCHER, a comment spam inference system that exploits spammers’ spamming infrastructure information to infer comment spam. At its core, NEIGHBORWATCHER runs a graph-based algorithm to characterize the spamming neighbor relationship, and re- ports a spam link when the same link also appears in the harbor’s clique neighbors. Starting from a small seed set of known spam links, our system inferred roughly 91,636 com- ment spam, and 16,694 spam harbors that are frequently utilized by comment spammers. Furthermore, our evalua- tion on real-world data shows that NEIGHBORWATCHER can keep inferring new comment spam and finding new spam harbors every day},
author = {Zhang, Jialong and Gu, Guofei},
journal = {ndss},
pages = {1--16},
title = {{NeighborWatcher: A Content-Agnostic Comment Spam Inference System}},
url = {http://faculty.cs.tamu.edu/guofei/$\backslash$npapers3://publication/uuid/C59BC7E5-566F-4F46-8577-91D056D77348},
year = {2013}
}
@article{helli,
abstract = {The postMessage mechanism in HTML5 enables Web content from different origins to communicate with each other, thus relaxing the same origin policy. It is especially popular in websites that include third-party content. Each message contains accurate information about its origin, but the receiver must check this information before accepting the message. The responsibility for preventing cross-origin attacks is thus partially delegated from the Web browser to the implementors of postMessage receiver functions. We collected postMessage receivers from the Alexa top 10,000 websites and found that many perform origin checks incorrectly or not at all. This results in exploitable vulner- abilities in 84 popular sites, including cross-site scripting and injection of arbitrary content into local storage. We propose two defenses. The first uses pseudo-random tokens to authenticate the source of messages and is in- tended for the implementors of third-party content. The second, based on a Content Security Policy extension, is intended for website owners. The two defenses are indepen- dent and can be deployed jointly or separately. 1},
author = {Son, Sooel and Shmatikov, Vitaly},
journal = {ndss},
title = {{The postman always rings twice: Attacking and defending postMessage in HTML5 websites}},
url = {https://www.cs.utexas.edu/{~}shmat/shmat{\_}ndss13postman.pdf},
year = {2013}
}
@article{helli,
author = {Venkataraman, Shobha and Brumley, David and Sen, Subhabrata and Spatscheck, Oliver},
journal = {ndss},
pages = {1--17},
title = {{Automatically Inferring the Evolution of Malicious Activity on the Internet}},
url = {papers3://publication/uuid/D22C4021-16EB-414C-970D-E3A28E9586B5},
year = {2013}
}
@article{helli,
author = {Aliasgari, Mehrdad and Blanton, Marina and Zhang, Yihua and Steele, Aaron},
journal = {ndss},
pages = {1--31},
title = {{Secure Computation on Floating Point Numbers}},
year = {2013}
}
@article{helli,
author = {Bhaskar, R and Guha, S},
journal = {ndss},
title = {{Verito: A Practical System for Transparency and Accountability in Virtual Economies}},
url = {http://saikat.guha.cc/{~}saikat/pub/ndss13-verito.pdf},
year = {2013}
}
@article{helli,
author = {Li, Lingjun and Zhao, Xinxin and Xue, Guoliang},
journal = {ndss},
title = {{Unobservable Re-authentication for Smartphones}},
volume = {13},
year = {2013}
}
@article{helli,
author = {Wu, Chiachih and Wang, Zhi and Jiang, Xuxian},
journal = {ndss},
pages = {1--15},
title = {{Taming Hosted Hypervisors with (Mostly) Deprivileged Execution}},
url = {http://www.csc.ncsu.edu/faculty/jiang/pubs/index.html$\backslash$npapers3://publication/uuid/B5FFAC62-70D1-4569-95DB-1E61C28FD6D7},
year = {2013}
}
@article{helli,
author = {Meng, Tey Chee and Gupta, Payas and Gao, Debin},
journal = {ndss},
pages = {1--16},
title = {{I can be You: Questioning the use of Keystroke Dynamics as Biometrics}},
url = {https://www.google.co.kr/$\backslash$npapers3://publication/uuid/BC8B145A-2F27-45CF-9FA1-2CC43C54C766},
year = {2013}
}
@article{helli,
abstract = {Piracy is a mass phenomenon on the Internet today. Various file sharing platforms offer free access to unau- thorised copies of copyrighted works such as media content and software. Copyright holders are using a range of legal and technical methods to protect their rights, and they are lobbying for legislation that would give them additional ways of enforcing their copyright online. However, little is known about how effective current forms of copyright enforcement are and how enduring the effect of proposed new measures can be. In this paper, we report on the results of a large- scale measurement study of the piracy ecosystem that has emerged around One-Click Hosters or “cyberlockers” such as Rapidshare, Megaupload, Mediafire, and Hotfile. Our data shows that current anti-piracy efforts are visible, but their overall impact appears to be rather limited. Furthermore, our analysis of the file sharing ecosystem suggests that future anti- piracy measures that are currently under discussion may not be as successful as their proponents might expect. Ongoing legal proceedings and efforts by payment processors, however, may force hosters to increase their own anti-piracy efforts},
author = {Lauinger, Tobias and Szydlowski, Martin and Onarlioglu, Kaan and Wondracek, Gilbert and Kirda, Engin and Kruegel, Christopher},
journal = {ndss},
pages = {1--14},
title = {{Clickonomics: Determining the Effect of Anti-Piracy Measures for One-Click Hosting}},
url = {http://iseclab.org/publications.html$\backslash$npapers3://publication/uuid/66860951-122B-443E-9720-992BC512D8C9},
year = {2013}
}
@article{helli,
abstract = {As popular tools for spreading spam and malware, Sybils (or fake accounts) pose a serious threat to online communities such as Online Social Networks (OSNs). Today, sophisticated attackers are creating realistic Sybils that effectively befriend legitimate users, rendering most automated Sybil detection techniques ineffective. In this paper, we explore the feasibility of a crowdsourced Sybil detection system for OSNs. We conduct a large user study on the ability of humans to detect today's Sybil accounts, using a large corpus of ground-truth Sybil accounts from the Facebook and Renren networks. We analyze detection accuracy by both "experts" and "turkers" under a variety of conditions, and find that while turkers vary significantly in their effectiveness, experts consistently produce near-optimal results. We use these results to drive the design of a multi-tier crowdsourcing Sybil detection system. Using our user study data, we show that this system is scalable, and can be highly effective either as a standalone system or as a complementary technique to current tools.},
archivePrefix = {arXiv},
arxivId = {arXiv:1205.3856v1},
author = {Wang, Gang and Mohanlal, Manish and Wilson, Christo and Wang, Xiao and Metzger, Miriam and Zheng, Haitao and Zhao, Ben Y},
eprint = {arXiv:1205.3856v1},
journal = {ndss},
pages = {1--14},
title = {{Social Turing Tests: Crowdsourcing Sybil Detection}},
url = {http://arxiv.org/abs/1205.3856v1},
year = {2013}
}
@article{helli,
journal = {ndss},
title = {{On Implementing Deniable Storage Encryption for Mobile Devices}},
year = {2013}
}
@article{helli,
author = {Samorodnitzky, O and Tromer, E and Wool, A},
journal = {ndss},
title = {{Analyzing Unique-Bid Auction Sites for Fun and Profit}},
url = {http://132.66.49.20/{~}yash/ubanalysis.pdf},
year = {2013}
}
@article{helli,
author = {Lee, Kh and Zhang, Xiangyu and Xu, Dongyan},
journal = {ndss},
title = {{High Accuracy Attack Provenance via Binary-based Execution Partition}},
url = {http://friends.cs.purdue.edu/pubs/NDSS13.pdf},
year = {2013}
}
@article{helli,
abstract = {Ideally, security protocol implementations should be for- mally verified before they are deployed. However, this is not true in practice. Numerous high-profile vulnerabilities have been found in web authentication protocol implemen- tations, especially in single-sign on (SSO) protocols imple- mentations recently. Much of the prior work on authentica- tion protocol verification has focused on theoretical foun- dations and building scalable verification tools for checking manually-crafted specifications [17, 18, 44]. In this paper, we address a complementary prob- lem of automatically extracting specifications from im- plementations. We propose AUTHSCAN, an end-to-end platform to automatically recover authentication protocol specifications from their implementations. AUTHSCAN finds a total of 7 security vulnerabilities using off-the-shelf verification tools in specifications it recovers, which include SSO protocol implementations and custom web authentica- tion logic of web sites with millions of users},
author = {Bai, Guangdong and Lei, Jike},
journal = {ndss},
title = {{AUTHSCAN: Automatic extraction of web authentication protocols from implementations}},
url = {http://compsec.comp.nus.edu.sg/papers/AuthScan-NDSS13.pdf},
year = {2013}
}
@article{helli,
author = {Han, Jih and Yan, Qiang and Gao, Debin and Zhou, Jianying and Deng, Robert H},
journal = {ndss},
pages = {1--15},
title = {{Comparing Mobile Privacy Protection through Cross-Platform Applications}},
url = {http://www.liaiqin.com/hanjin/$\backslash$npapers3://publication/uuid/EDE08F21-0175-4B99-B31B-86FC339DAFB4},
year = {2013}
}
@article{helli,
author = {Wang, David Y and Savage, Stefan and Voelker, Geoffrey M},
doi = {10.1.1.278.7807},
journal = {ndss},
pages = {1--17},
title = {{Juice: A Longitudinal Study of an SEO Botnet}},
url = {papers3://publication/uuid/D3E5C37A-B0C8-47CB-89B9-2ECF678DD2E5},
year = {2013}
}
@article{helli,
abstract = {Attack Surface Metrics and Automated Compile-Time Kernel Tailoring},
author = {{© 2013 IBM Corporation} and 1 and {Anil Kurmus} and {February 25th} and {2013 – Ndss'13} and {Andreas Ruprecht, Wolfgang Schr{\"{o}}der-Preikschat}, Daniel Lohmann and R{\"{u}}diger Kapitza and Kapitza, R{\"{u}}diger and Kurmus, Anil and Tartler, Reinhard and Dorneanu, Daniela and Heinloth, Bernhard and Rothberg, Valentin},
journal = {ndss},
pages = {1--63},
title = {{Attack Surface Metrics and Automated Compile-Time Kernel Tailoring}},
url = {http://www.internetsociety.org/sites/default/files/Presentation03{\_}2.pdf},
year = {2013}
}
@article{helli,
abstract = {Security application 제작을 위한 framework},
author = {Shin, Seugwon and Porras, Pa and Yegneswaran, Vinod and Fong, Mw},
doi = {10.1.1.297.7129},
journal = {ndss},
number = {February},
title = {{FRESCO: Modular Composable Security Services for Software-Defined Networks.}},
url = {http://www.csl.sri.com/users/vinod/papers/fresco.pdf},
volume = {2},
year = {2013}
}
@article{helli,
author = {Jansen, Rob and Johnson, Aaron and Syverson, Paul},
journal = {ndss},
title = {{LIRA : Lightweight Incentivized Routing for Anonymity}},
year = {2013}
}
@article{helli,
author = {White, Andrew M and Krishnan, Srinivas and Bailey, Michael and Monrose, Fabian and Porras, Phillip},
journal = {ndss},
pages = {1--16},
title = {{Clear and Present Data: Opaque Traffic and its Security Implications for the Future}},
url = {papers3://publication/uuid/E95763BB-9523-4CB7-A89C-CB69863B1935},
year = {2013}
}
@article{helli,
abstract = {Web attacks are nowadays one of the major threats on the Internet, and several studies have analyzed them, providing details on how they are performed and how they spread. However, no study seems to have sufficiently analyzed the typical behavior of an attacker after a website has been compromised. This paper presents the design, implementation, and de- ployment of a network of 500 fully functional honeypot web- sites, hosting a range of different services, whose aim is to attract attackers and collect information on what they do during and after their attacks. In 100 days of experiments, our system automatically collected, normalized, and clus- tered over 85,000 files that were created during approxi- mately 6,000 attacks. Labeling the clusters allowed us to draw a general picture of the attack landscape, identifying the behavior behind each action performed both during and after the exploitation of a web application.},
author = {Canali, Davide and Balzarotti, Davide},
journal = {ndss},
pages = {n----a},
title = {{Behind the scenes of online attacks: an analysis of exploitation behaviors on the web}},
year = {2013}
}
@article{helli,
abstract = {The Android software stack for mobile devices defines and enforces its own security model for apps through its application-layer permissions model. However, at its foundation, Android relies upon the Linux kernel to protect the system from malicious or flawed apps and to isolate apps from one another. At present, Android leverages Linux dis- cretionary access control (DAC) to enforce these guarantees, despite the known shortcomings of DAC. In this pa- per, we motivate and describe our work to bring flexible mandatory access control (MAC) to Android by enabling the effective use of Security Enhanced Linux (SELinux) for kernel-level MAC and by developing a set of middleware MAC extensions to the Android permissions model. We then demonstrate the benefits of our security enhancements for Android through a detailed analysis of how they mitigate a number of previously published exploits and vulnerabilities for Android. Finally, we evaluate the overheads imposed by our security enhancements.},
author = {Smalley, Stephen and Craig, Robert},
journal = {ndss},
title = {{Security Enhanced (SE) Android: Bringing Flexible MAC to Android}},
url = {http://selinuxproject.org/{~}seandroid/papers/NDSS2013-SEAndroid-Paper.pdf},
year = {2013}
}
@article{helli,
author = {Setty, S and McPherson, R},
journal = {ndss},
title = {{Making argument systems for outsourced computation practical (sometimes)}},
url = {http://www.cs.utexas.edu/pepper/pepper-ndss12.pdf},
year = {2012}
}
@article{helli,
abstract = {Despite the demonstrated usefulness of dynamic data flow tracking (DDFT) techniques in a variety of security applications, the poor performance achieved by available prototypes prevents their widespread adoption and use in production systems. We present and evaluate a novel methodology for improving the performance overhead of DDFT frameworks, by combining static and dynamic analysis. Our intuition is to separate the program logic from the corresponding tracking logic, extracting the semantics of the latter and abstracting them using a Taint Flow Algebra. We then apply optimization techniques to eliminate redundant tracking logic and minimize interference with the target program. Our optimizations are directly applicable to binary-only software and do not require any high level semantics. Furthermore, they do not require additional resources to improve performance, neither do they restrict or remove functionality. Most importantly, our approach is orthogonal to optimizations devised in the past, and can deliver additive performance benefits. We extensively evaluate the correctness and impact of our optimizations, by augmenting a freely available high-performance DDFT framework, and applying it to multiple applications, including command line utilities, server applications, language runtimes, and web browsers. Our results show a speedup of DDFT by as much as 2.23×, with an average of 1.72× across all tested applications.},
author = {Jee, Kangkook and Portokalidis, Georgios and Kemerlis, VP},
journal = {ndss},
title = {{A General Approach for Efficiently Accelerating Software-based Dynamic Data Flow Tracking on Commodity Hardware}},
url = {http://www.cs.columbia.edu/nsl/papers/2012/tfa.ndss12.pdf},
year = {2012}
}
@article{helli,
abstract = {The advent of cloud computing has ushered in an era of mass data storage in remote servers. Remote data storage offers reduced data management overhead for data owners in a cost effective manner. Sensitive documents, however, need to be stored in encrypted format due to security con- cerns. But, encrypted storage makes it difficult to search on the stored documents. Therefore, this poses a major barrier towards selective retrieval of encrypted documents from the remote servers. Various protocols have been proposed for keyword search over encrypted data to address this issue. Most of the available protocols leak data access patterns due to efficiency reasons. Although, oblivious RAM based protocols can be used to hide data access patterns, such protocols are computationally intensive and do not scale well for real world datasets. In this paper, we introduce a novel attack that exploits data access pattern leakage to disclose significant amount of sensitive information using a modicum of prior knowledge. Our empirical analysis with a real world dataset shows that the proposed attack is able to disclose sensitive information with a very high accuracy. Additionally, we propose a simple technique to mitigate the risk against the proposed attack at the expense of a slight increment in computational resources and communication cost. Furthermore, our proposed mitigation technique is generic enough to be used in conjunction with any search- able encryption scheme that reveals data access pattern.},
author = {Islam, Mohammad Saiful and Kuzu, Mehmet and Kantarcioglu, Murat},
journal = {ndss},
keywords = {although,due to efficiency reasons,most of the available,oblivious ram based,patterns,protocols can be used,protocols leak data access,search over encrypted data,such,to address this issue,to hide data access},
title = {{Access pattern disclosure on searchable encryption: Ramification, attack and mitigation}},
year = {2012}
}
@article{helli,
abstract = {The Internet is a lucrative medium for criminals target-ing Internet users. Most common Internet attacks requiresome form of user interaction such as clicking on an exploitlink. Hence, the problem at hand is not only a technical one,but it also has a strong human aspect. Although the securitycommunity has proposed many technical solutions to com-mon attacks, the behavior of users when they face currentthreats, and the way they evaluate the security implicationsof their actions remain largely unexplored.In this paper we describe an online experiment platformwe built for testing the behavior of users when they are con-fronted with prevalent, concrete attack scenarios such as re-flected cross-site scripting, session fixation, and file sharingscams. We conducted experiments with 164 Internet userswith diverse backgrounds. Our findings suggest that manynon-technical users can exhibit performance comparable tosecurity experts at averting relatively simple threats thatthey are frequently exposed to in everyday life. They cando so solely by following their intuition, without actuallyperceiving the severity of the threat. However, when facingmore sophisticated attacks, these non-technical users oftenrely on misleading cues such as the “size” and “length”of artifacts (e.g., URLs), and hence, fail to protect them-selves. We also show that trick banners that are common infile sharing websites and shortened URLs have high successrates of deceiving non-technical users, thus posing a severesecurity risk},
author = {Onarlioglu, Kaan and Yilmaz, Uo and Kirda, E and Balzarotti, Davide},
journal = {ndss},
title = {{Insights into User Behavior in Dealing with Internet Attacks.}},
url = {http://mail.seclab.tuwien.ac.at/papers/onarlioglu{\_}ndss12.pdf},
year = {2012}
}
@article{helli,
abstract = {The design of leakage-resilient password systems (LRPSes) in the absence of trusted devices remains a chal- lenging problem today despite two decades of intensive re- search in the security community. In this paper, we inves- tigate the inherent tradeoff between security and usability in designing LRPS. First, we demonstrate that most of the existing LRPS systems are subject to two types of generic attacks - brute force and statistical attacks, whose power has been underestimated in the literature. Second, in or- der to defend against these two generic attacks, we intro- duce five design principles that are necessary to achieve leakage resilience in the absence of trusted devices. We also show that these attacks cannot be effectively mitigated without significantly sacrificing the usability of LRPS sys- tems. Third, to better understand the tradeoff between se- curity and usability of LRPS, we propose for the first time a quantitative analysis framework on usability costs of pass- word systems. By decomposing the authentication process of existing LRPS systems into atomic cognitive operations in psychology, we show that a secure LRPS in practical set- tings always imposes a considerable amount of cognitive workload on its users, which indicates the inherent limita- tions of such systems and in turn implies that an LRPS has to incorporate certain trusted devices in order to be both secure and usable.},
author = {Yan, Qiang and Han, Jin and Li, Yingjiu and Deng, Robert H},
journal = {ndss},
title = {{On Limitations of Designing Leakage-Resilient Password Systems : Attacks , Principles and Usability}},
url = {http://www.isoc.org/isoc/conferences/ndss/12/},
year = {2012}
}
@article{helli,
abstract = {Remote attestation is the process of secure verification of the in- ternal state of a remote hardware platform. Generally, it can be achieved either statically (at boot time) or dynamically, during nor- mal operation in order to establish a dynamic root of trust. The latter allows the verifier to fully isolate a code region from preexist- ing software (including the operating system) and guarantee untam- pered execution of such code. It also facilitates dynamic execution of certain code despite the untrusted state of the overall platform. A dynamic root of trust can be utilized as a mechanism to exe- cute security sensitive code required in a variety of protocols and applications on embedded platforms. Prior software-based tech- niques lack concrete security guarantees, while hardware-based ap- proaches involve tamper-resistant security co-processors that are not cost-efficient for many types of low-end (commodity) embed- ded devices. In this paper, we present a simple, efficient and secure hardware- based approach (called SMART) for establishing a dynamic root of trust in a remote embedded device. We focus on low-end micro- controller units (MCU) that lack specialized memory management or protection features. SMART requires minimal changes to exist- ing MCUs (while providing concrete security guarantees) and as- sumes few restrictions on adversarial capabilities. We demonstrate practicality and feasibility of our approach by implementing it via hardware modifications on two common MCU platforms: AVR and MSP430. Results show that SMART implementations confine required changes to memory bus access logic. We also synthesized both implementations to an 180nm ASIC process to verify its small impact on MCU size and overall cost.},
author = {Perito, Daniele and Tsudik, Gene and Defrawy, Karim El},
journal = {ndss},
title = {{SMART : Secure and Minimal Architecture for ( Establishing a Dynamic ) Root of Trust}},
url = {http://francillon.net/{~}aurel/papers/2012{\_}SMART.pdf},
year = {2012}
}
@article{helli,
abstract = {We take an important step forward in making Oblivious RAM (O-RAM) practical. We propose an O-RAM construction achieving an amortized overhead of 20X-35X (for an O-RAM roughly 1 terabyte in size), about 63 times faster than the best existing scheme. On the theoretic front, we propose a fundamentally novel technique for constructing Oblivious RAMs: specifically, we partition a bigger O-RAM into smaller O-RAMs, and employ a background eviction technique to obliviously evict blocks from the client-side cache into a randomly assigned server-side partition. This novel technique is the key to achieving the gains in practical performance.},
archivePrefix = {arXiv},
arxivId = {1106.3652},
author = {Stefanov, Emil and Shi, Elaine and Song, Dawn},
eprint = {1106.3652},
journal = {ndss},
pages = {1--40},
title = {{Towards practical oblivious RAM}},
url = {http://arxiv.org/abs/1106.3652},
year = {2012}
}
@article{helli,
abstract = {Distributed hash tables suffer from several security and privacy vulnerabilities, including the problem of Sybil attacks. Existing social network-based solutions to mitigate the Sybil attacks in DHT routing have a high state requirement and do not provide an adequate level of privacy. For instance, such techniques require a user to reveal their social network contacts. We design X-Vine, a protection mechanism for distributed hash tables that operates entirely by communicating over social network links. As with traditional peer-to-peer systems, X-Vine provides robustness, scalability, and a platform for innovation. The use of social network links for communication helps protect participant privacy and adds a new dimension of trust absent from previous designs. X-Vine is resilient to denial of service via Sybil attacks, and in fact is the first Sybil defense that requires only a logarithmic amount of state per node, making it suitable for large-scale and dynamic settings. X-Vine also helps protect the privacy of users social network contacts and keeps their IP addresses hidden from those outside of their social circle, providing a basis for pseudonymous communication. We first evaluate our design with analysis and simulations, using several real world large-scale social networking topologies. We show that the constraints of X-Vine allow the insertion of only a logarithmic number of Sybil identities per attack edge; we show this mitigates the impact of malicious attacks while not affecting the performance of honest nodes. Moreover, our algorithms are efficient, maintain low stretch, and avoid hot spots in the network. We validate our design with a PlanetLab implementation and a Facebook plugin.},
archivePrefix = {arXiv},
arxivId = {1109.0971},
author = {Mittal, Prateek and Caesar, Matthew and Borisov, Nikita},
eprint = {1109.0971},
journal = {ndss},
pages = {15},
title = {{X-Vine: Secure and Pseudonymous Routing Using Social Networks}},
url = {http://arxiv.org/abs/1109.0971},
year = {2012}
}
@article{helli,
author = {Golde, Nico and Redon, K and Borgaonkar, Ravishankar},
journal = {ndss},
title = {{Weaponizing femtocells: The effect of rogue devices on mobile telecommunications}},
url = {https://www.isti.tu-berlin.de/fileadmin/fg214/Papers/femto{\_}ndss12.pdf},
year = {2012}
}
@article{helli,
abstract = {Static binary code analysis is a longstanding technique used to find security defects in deployed proprietary software. The complexities of binary code compiled from object-oriented source languages (e.g. C++) has limited the utility of binary analysis to basic applications using simpler coding constructs, so vulnerabilities in object-oriented code remain undetected. In this paper, we present vtable escape bugs—a class of type confusion errors specific to C++ code present in real, deployed software including Adobe Reader, Microsoft Office, and theWindows subsystem DLLs. We developed automated binary code analyses able to statically detect vtable escape bugs by reconstructing high-level objects and analyzing the safety of their use. We implemented our analysis in our own general object code decompilation framework to demonstrate that classes of object-oriented vulnerabilities can be uncovered from compiled binaries. We successfully found vtable escape bugs in a collection of test samples that mimic publicly disclosed vulnerabilities in Adobe Reader and Microsoft Excel. With these new analyses, security analysts gain the ability to find common flaws introduced by applications compiled from C++.},
author = {Dewey, David and Giffin, Jonathon},
journal = {ndss},
title = {{Static detection of C++ vtable escape vulnerabilities in binary code}},
url = {https://www.internetsociety.org/sites/default/files/P14{\_}2.pdf},
year = {2012}
}
@article{helli,
abstract = {Software exploits are one of the major threats to the In- ternet security. A large family of exploits works by corrupt- ing memory of the victim process to execute malicious code. To quickly respond to these attacks, it is critical to automati- cally diagnose such exploits to find out how they circumvent existing defense mechanisms. Because of the complexity of the victim programs and sophistication of recent exploits, existing analysis techniques fall short: they either miss im- portant attack steps or report too much irrelevant informa- tion. In this paper, based on the observation that the key steps in memory corruption exploits often involve pointer misuses, we propose a novel solution, PointerScope, to use type inference on binary execution to detect the pointer mis- uses induced by an exploit. These pointer misuses high- light the important attack steps of the exploit, and there- fore convey valuable information about the exploit mecha- nisms. Our approach complements dependency-based solu- tions to perform more comprehensive diagnosis of sophis- ticated memory exploits. We prototyped PointerScope and evaluated it using real-world exploit samples and demon- strated that PointerScope can successfully capture the key attack steps, which significantly facilitates attack response},
author = {Zhang, Mingwei and Prakash, Aravind and Li, Xiaolei and Liang, Zhenkai and Yin, Heng},
journal = {ndss},
title = {{Identifying and Analyzing Pointer Misuses for Sophisticated Memory-corruption Exploit Diagnosis}},
year = {2012}
}
@article{helli,
abstract = {Worms exploiting JavaScript XSS vulnerabilities ram- pantly infect millions of web pages, while drawing the ire of helpless users. To date, users across all the popular social networks, including Facebook,MySpace, Orkut and Twitter, have been vulnerable to XSSworms. We propose PathCutter as a new approach to severing the self-propagation path of JavaScript worms. PathCutter works by blocking two criti- cal steps in the propagation path of an XSS worm: (i) DOM access to different views at the client side and (ii) unautho- rized HTTP request to the server. As a result, although an XSS vulnerability is successfully exercised at the client, the XSS worm is prevented from successfully propagating to the would-be victim’s own social network page. PathCutter is effective against all the current forms of XSS worms, includ- ing those that exploit traditional XSS,DOM-based XSS, and content sniffing XSS vulnerabilities. We present and evaluate both a server-side and proxy- side deployment of PathCutter. We implement PathCutter on WordPress and Elgg and demonstrate its resilience against two proof-of-concept attacks. We also evaluate the Path- Cutter implementation on five real-world worms: Boonana, MySpace Samy, Renren, SpaceFlash, and the Yamanner worm. We show that although the worms themselves exploit different vulnerabilities, at either the client side or server side, they are successfully thwarted by PathCutter as it is vulnerability agnostic and blocks the propagation path of the infection. Our performance evaluation shows that ren- dering overhead of PathCutter is less than 4{\%}, and memory overhead for one additional view is less than 1{\%}},
author = {Cao, Y and Yegneswaran, V},
isbn = {9781450309486},
journal = {ndss},
pages = {745},
title = {{Pathcutter: Severing the self-propagation path of xss javascript worms in social web networks}},
url = {http://www.dnssec-test-dyn.com/sites/default/files/08{\_}2.pdf},
year = {2012}
}
@article{helli,
author = {Evans, David and Katz, Jonathan},
journal = {ndss},
number = {February},
pages = {5--8},
title = {{Private Set Intersection : Are Garbled Circuits Better than Custom Protocols ?}},
year = {2012}
}
@article{helli,
abstract = {Cellular phones have become a ubiquitous means of communications with over 5 billion users worldwide in 2010, of which 80{\%} are GSM subscribers. Due to their use of the wireless medium and their mobile nature, those phones listen to broadcast communications that could re- veal their physical location to a passive adversary. In this paper, we investigate techniques to test if a user is present within a small area, or absent from a large area by simply listening on the broadcast GSM channels. With a combina- tion of readily available hardware and open source soft- ware, we demonstrate practical location test attacks that include circumventing the temporary identifier designed to protect the identity of the end user. Finally we propose solu- tions that would improve the location privacy of users with low system impact. 1},
author = {Kune, Df and Koelndorfer, John},
journal = {ndss},
title = {{Location leaks on the GSM Air Interface}},
url = {http://people.cs.umass.edu/{~}foo/research/docs/fookune{\_}ndss{\_}gsm.pdf},
year = {2012}
}
@article{helli,
abstract = {Attackers often use domain names for various malicious purposes such as phishing, botnet command and control, and malware propagation. An obvious strategy for prevent- ing these activities is deleting the malicious domain from the upper level DNS servers. In this paper, we show that this is insufficient. We demonstrate a vulnerability affecting the large majority of popular DNS implementations which allows a malicious domain name to stay resolvable long af- ter it has been removed from the upper level servers. Our experiments with 19,045 open DNS servers show that even one week after a domain name has been revoked and its TTL expired, more than 70{\%} of the servers will still resolve it. Finally, we discuss several strategies to prevent this attack},
author = {Jiang, Jian and Liang, Jinjin},
journal = {ndss},
title = {{Ghost Domain Names : Revoked Yet Still Resolvable}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Ghost+Domain+Names+:+Revoked+Yet+Still+Resolvable{\#}0},
year = {2012}
}
@article{helli,
abstract = {In this paper, we present a systematic study for the de- tection of malicious applications (or apps) on popular An- droid Markets. To this end, we first propose a permission- based behavioral footprinting scheme to detect new sam- ples of known Android malware families. Then we apply a heuristics-based filtering scheme to identify certain inher- ent behaviors of unknown malicious families. We imple- mented both schemes in a system called DroidRanger. The experiments with 204, 040 apps collected from five different Android Markets in May-June 2011 reveal 211 malicious ones: 32 from the official Android Market (0.02{\%} infec- tion rate) and 179 from alternative marketplaces (infection rates ranging from 0.20{\%} to 0.47{\%}). Among those mali- cious apps, our system also uncovered two zero-day mal- ware (in 40 apps): one from the official Android Market and the other from alternative marketplaces. The results show that current marketplaces are functional and rela- tively healthy. However, there is also a clear need for a rigorous policing process, especially for non-regulated al- ternative marketplaces.},
author = {Zhou, Yajin and Wang, Zhi and Zhou, Wu and Jiang, Xuxian},
doi = {http://www.internetsociety.org/hey-you-get-my-market-detecting-malicious-apps-official-and-alternative-android-markets},
journal = {ndss},
number = {2},
pages = {5--8},
title = {{Hey, You, Get Off of My Market: Detecting Malicious Apps in Official and Alternative Android Markets}},
year = {2012}
}
@article{helli,
author = {Cai, Zhuhua and Jermaine, Christopher},
isbn = {0000000000000},
journal = {ndss},
title = {{The latent community model for detecting sybil attacks in social networks}},
year = {2012}
}
@article{helli,
author = {Bates, Adam M and Butler, Kevin R B and Sherr, Micah and Shields, Clay and Traynor, Patrick and Wallach, Dan S},
journal = {ndss},
title = {{Accountable Wiretapping-or-I know they can hear you now.}},
year = {2012}
}
@article{helli,
author = {Stark, Emily and Huang, Lin-Shung and Israni, Dinesh and Jackson, Collin and Boneh, Dan},
journal = {ndss},
title = {{The Case for Prefetching and Prevalidating TLS Server Certificates}},
url = {http://www.internetsociety.org/case-prefetching-and-prevalidating-tls-server-certificates},
year = {2012}
}
@article{helli,
author = {Bindschaedler, Laurent and Jadliwala, Murtuza and Bilogrevic, Igor and Aad, Imad and Ginzboorg, Philip and Niemi, Valtteri and Hubaux, Jean-Pierre},
journal = {ndss},
pages = {1--17},
title = {{Track Me If You Can: On the Effectiveness of Context-based Identifier Changes in Deployed Mobile Networks}},
url = {http://www.google.co.kr/url?sa=t{\&}rct=j{\&}q="track me if you can: on the effectiveness of context-based identifier changes in deployed mobile networks"{\&}source=web{\&}cd=2{\&}ved=0CDMQFjAB{\&}url=http://infoscience.epfl.ch/record/169827/files/tmiyc{\_}BindJadBAGNH{\_}final.},
year = {2012}
}
@article{helli,
abstract = {Many web services aim to track clients as a basis for analyzing their behavior and providing personalized services. Despite much debate regarding the collection of client information, there have been few quantitative studies that analyze the effectiveness of host-tracking and the associated privacy risks. In this paper,we performa large-scale study to quan- tify the amount of information revealed by common host identifiers. We analyze month-long anonymized datasets collected by the Hotmail web-mail service and the Bing search engine, which includemillions of hosts across the global IP address space. In this setting, we compare the use of multiple identifiers, including browser informa- tion, IP addresses, cookies, and user login IDs. We further demonstrate the privacy and security im- plications of host-tracking in two contexts. In the first, we study the causes of cookie churn in web services, and show thatmany returning users can still be tracked even if they clear cookies or utilize private browsing. In the second, we show that host-tracking can be leveraged to improve security. Specifically, by aggregating informa- tion across hosts, we uncover a stealthymalicious attack associated with over 75,000 bot accounts that forward cookies to distributed locations},
author = {Yen, Ting-Fang and Xie, Yinglian and Yu, Fang and Yu, Roger Peng and Abadi, Martin},
journal = {ndss},
pages = {1--16},
title = {{Host Fingerprinting and Tracking on the Web: Privacy and Security Implications}},
url = {http://www.google.co.kr/url?sa=t{\&}rct=j{\&}q=host fingerprinting and tracking on the web: privacy and security implications{\&}source=web{\&}cd=2{\&}ved=0CDcQFjAB{\&}url=http://research.microsoft.com/pubs/156901/ndss2012.pdf{\&}ei=BEDgTqiADeWViQeY{\_}onMCw{\&}usg=AFQjCNEJFLEh2g2V},
year = {2012}
}
@article{helli,
abstract = {gnuplot plot},
author = {Gao, Hongyu and Chen, Yan and Lee, Kathy and Palsetia, Diana and Chudhary, Alok},
journal = {ndss},
pages = {1--16},
title = {{Towards Online Spam Filtering in Social Networks}},
url = {http://www.cs.northwestern.edu/{~}ychen/publication-byYear.html$\backslash$npapers3://publication/uuid/3D6625C7-C9E8-40A8-8A94-872FEF73C0AE},
year = {2012}
}
@article{helli,
abstract = {WOODPECKER. They do "detection of capability leaks". They discover that several privileged permissions owned by stock apps in popular Android smartphones are unsafely exposed to external apps. Explicit leak: app has permission X, and the dangerous API is reachable from outside. Implicit leak: if an app as the userID, then it might be able to reach the dangerous component, if not proper checks are done. Two steps: possible-path identification + feasible-path refinement. Refinement: Symbolic path execution: while traversing the CFG, they check that "constraints are consistent". If not, they prune. They use aggressive JOINs for scalability. Type-analysis while they traverse. They use method summaries (i.e., cache). Manual modelling of framework stuff, implicit edges, dangerous permission{\~{}}>API mapping. They support AIDL.},
author = {Grace, Michael and Zhou, Yajin and Wang, Zhi and Jiang, Xuxian},
journal = {ndss},
title = {{Systematic Detection of Capability Leaks in Stock Android Smartphones}},
year = {2012}
}
@article{helli,
abstract = {Runtime and control-flow attacks (such as code injection or return-oriented programming) constitute one of the most severe threats to software programs. These attacks are prevalent and have been recently applied to smartphone applications as well, of which hundreds of thousands are downloaded by users every day. While a framework for control-flow integrity (CFI) enforcement, an approach to prohibit this kind of attacks, exists for the Intel x86 platform, there is no such a solution for smartphones. In this paper, we present a novel framework, MoCFI (Mobile CFI), that provides a general countermeasure against control-flow attacks on smartphone platforms by enforcing CFI. We show that CFI on typical smartphone platforms powered by an ARM processor is technically involved due to architectural differences between ARMand Intel x86, as well as the specifics of smartphone OSes. Our framework performs CFI on-the-fly during runtime without requiring the application’s source code. For our reference implementation we chose Apple’s iOS, because it has been an attractive target for control-flow attacks. Nevertheless, our framework is also applicable to other ARM-based devices such as Google’s Android. Our performance evaluation demonstrates that MoCFI is efficient and does not induce notable overhead when applied to popular iOS applications.},
author = {Davi, Lucas and Dmitrienko, Alexandra and Egele, Manuel and Thomas, Fischer and Holz, Thorsten and Hund, Ralf and Nurnberger, Stefan and Sadeghi, Ahmad-Reza},
doi = {10.1.1.232.4165},
journal = {ndss},
title = {{MoCFI: A framework to mitigate control-flow attacks on smartphones}},
url = {http://www.researchgate.net/publication/228517736{\_}MoCFI{\_}A{\_}Framework{\_}to{\_}Mitigate{\_}Control-Flow{\_}Attacks{\_}on{\_}Smartphones/file/79e4150814635b1821.pdf},
year = {2012}
}
@article{helli,
abstract = {Uncovering semantic data of interest in memory pages without memory mapping information is an important capability in computer forensics. Existing memory mapping-guided techniques do not work in that scenario as pointers in the un-mappable memory cannot be resolved and navi- gated. To address this problem, we present a probabilistic inference-based approach called DIMSUM to enable the recognition of data structure instances from un-mappable memory. Given a set of memory pages and the specification of a target data structure, DIMSUM will identify instances of the data structure in those pages with quantifiable confidence. More specifically, it builds graphical models based on boolean constraints generated from the data structure and the memory page contents. Probabilistic inference is performed on the graphical models to generate results ranked with probabilities. Our experiments with realworld applications on both Linux and Android platforms show that DIMSUM achieves higher effectiveness than non- probabilistic approaches without memory mapping information.},
author = {Lin, Zhiqiang and Rhee, Junghwan and Wu, Chao},
journal = {ndss},
title = {{DIMSUM: Discovering Semantic Data of Interest from Un-mappable Memory with Confidence}},
url = {https://www.internetsociety.org/sites/default/files/10{\_}1.pdf},
year = {2012}
}
@article{helli,
journal = {ndss},
title = {{WARNINGBIRD:Detecting Suspicious URLs in Twitter Stream}},
year = {2012}
}
@article{helli,
abstract = {Content-centric networking - also known as information-centric networking (ICN) - shifts emphasis from hosts and interfaces (as in today's Internet) to data. Named data becomes addressable and routable, while locations that currently store that data become irrelevant to applications. Named Data Networking (NDN) is a large collaborative research effort that exemplifies the content-centric approach to networking. NDN has some innate privacy-friendly features, such as lack of source and destination addresses on packets. However, as discussed in this paper, NDN architecture prompts some privacy concerns mainly stemming from the semantic richness of names. We examine privacy-relevant characteristics of NDN and present an initial attempt to achieve communication privacy. Specifically, we design an NDN add-on tool, called ANDaNA, that borrows a number of features from Tor. As we demonstrate via experiments, it provides comparable anonymity with lower relative overhead.},
archivePrefix = {arXiv},
arxivId = {1112.2205},
author = {DiBenedetto, Steven and Gasti, Paolo},
eprint = {1112.2205},
journal = {ndss},
pages = {1--20},
title = {{ANDaNA : Anonymous Named Data Networking Application}},
url = {http://arxiv.org/abs/1112.2205},
year = {2012}
}
@article{helli,
abstract = {Modern web browsers are complex. They provide a high-performance and rich computational environment for web-based applications, but they are prone to nu- merous types of security vulnerabilities that attackers actively exploit. However, because major browser plat- forms differ in their implementations they rarely exhibit the same vulnerabilities. In this paper we present Cocktail, a system that uses three different off-the-shelf web browsers in parallel to provide replicated execution for withstanding browser- based attacks and improving browser reliability. Cock- tail mirrors inputs to each replica and votes on browser states and outputs to detect potential attacks, while con- tinuing to run. The net effect of Cocktail’s architecture is to shift the security burden of the system from complex browsers to a simplified layer of software. We demon- strate that Cocktail can withstand real-world browser exploits and reliability issues, such as browser crashes, while adding only 31.5{\%} overhead to page load latency times on average, and remaining compatible with popu- lar web sites. 1},
author = {Xue, Hui and Dautenhahn, Nathan and King, St},
journal = {ndss},
title = {{Using replicated execution for a more secure and reliable web browser}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Using+Replicated+Execution+for+a+More+Secure+and+Reliable+Web+Browser{\#}3},
year = {2012}
}
@article{helli,
abstract = {Kernel heap buffer overflow vulnerabilities have beenexposed for decades, but there are few practical counter-measure that can be applied to OS kernels. Previous so-lutions either suffer from high performance overhead orcompatibility problems with mainstream kernels and hard-ware. In this paper, we present KRUISER, a concurrentkernel heap buffer overflow monitor. Unlike conventionalmethods, the security enforcement of which is usually in-lined into the kernel execution, Kruiser migrates securityenforcement from the kernel’s normal execution to a con-current monitor process, leveraging the increasingly pop-ular multi-core architectures. To reduce the synchroniza-tion overhead between the monitor process and the runningkernel, we design a novel semi-synchronized non-blockingmonitoring algorithm, which enables efficient runtime de-tection on live memory without incurring false positives. Toprevent the monitor process from being tampered and pro-vide guaranteed performance isolation, we utilize the virtu-alization technology to run the monitor process out of themonitored VM, while heap memory allocation informationis collected inside the monitored VM in a secure and effi-cient way. The hybrid VM monitoring technique combinedwith the secure canary that cannot be counterfeited by at-tackers provides guaranteed overflow detection with highefficiency. We have implemented a prototype of KRUISERbased on Linux and the Xen hypervisor. The evaluationshows that Kruiser can detect realistic kernel heap bufferoverflow attacks effectively with minimal overhead},
author = {Tian, Donghai and Zeng, Q and Wu, D and Liu, P and Hu, C},
journal = {ndss},
title = {{Kruiser: Semi-synchronized Non-blocking Concurrent Kernel Heap Buffer Overflow Monitoring}},
url = {http://test.scripts.psu.edu/users/q/u/quz105/papers/kruiser-ndss2012.pdf},
year = {2012}
}
@article{helli,
author = {Castelluccia, Claude and D{\"{u}}rmuth, M and Perito, Daniele},
journal = {ndss},
title = {{Adaptive password-strength meters from Markov models}},
url = {http://planete.inrialpes.fr/{~}perito/papers/pass{\_}check.pdf$\backslash$npapers3://publication/uuid/FB5DE60F-9EFE-4856-95B9-98C796BF13CE},
volume = {2012},
year = {2012}
}
@article{helli,
abstract = {The Datagram Transport Layer Security (DTLS) proto- col provides confidentiality and integrity of data exchanged between a client and a server. We describe an efficient and full plaintext recovery attack against the OpenSSL imple- mentation of DTLS, and a partial plaintext recovery attack against the GnuTLS implementation of DTLS. The attack against the OpenSSL implementation is a variant of Vaude- nay’s padding oracle attack and exploits small timing differ- ences arising during the cryptographic processing of DTLS packets. It would have been prevented if the OpenSSL im- plementation had been in accordance with the DTLS RFC. In contrast, the GnuTLS implementation does follow the DTLS RFC closely, but is still vulnerable to attack. The attacks require new insights to overcome the lack of error messages in DTLS and to amplify the timing differences. We discuss the reasons why these implementations are insecure, drawing lessons for secure protocol design and implemen- tation in general.},
author = {Alfardan, Nadhem and Paterson, Kenny},
journal = {ndss},
keywords = {Faculty of Science$\backslash$Mathematics},
title = {{Plaintext-Recovery Attacks Against Datagram TLS}},
url = {http://digirep.rhul.ac.uk/items/19a59a8a-d03b-17ba-72d4-1b9ce4d9a2aa/3/},
year = {2012}
}
@article{helli,
author = {Au, Man Ho and Kapadia, Apu and Susilo, Willy},
journal = {ndss},
pages = {1--17},
title = {{BLACR: TTP-Free Blacklistable Anonymous Credentials with Reputation}},
year = {2012}
}
@article{helli,
abstract = {Ideally, a privacy-preserving database-in-the-cloud en- vironment would allow a database owner to outsource its encrypted database to a cloud server. The owner would retain control over what records can be queried and by whom, by granting each authorized user a search token and a decryption key. A user would then present this token to cloud server who would use it to find encrypted matching records, while learning nothing else. A user could then use its owner-issued decryption key to learn the actualmatching records. Themain challenge is howto enable efficient search over encrypted data without sacrificing privacy. Many research efforts have focused on similar problems, however, none supports efficient logarithmic-complexity search. In this paper, we construct the first provably secure logarithmic search mechanism suitable for privacy-preserving cloud setting. Specifically, we propose an efficient and provably secure range predicate encryption scheme. Based on this scheme, we demonstrate how to build a system that sup- ports logarithmic search over encrypted data. Besides pri- vacy guarantees, we show that the proposed system sup- ports query authentication and secure update. 1 Introduction Cloud computing refers to massive computing},
author = {Lu, Yanbin},
journal = {ndss},
title = {{Privacy-Preserving Logarithmic-time Search on Encrypted Data in Cloud}},
year = {2012}
}
@article{helli,
journal = {ndss},
pages = {1--20},
title = {{Gatling : Automatic Attack Discovery in Large-Scale Distributed Systems}},
year = {2012}
}
@article{helli,
author = {Chen, Y and Peng, B},
journal = {ndss},
title = {{Large-scale privacy-preserving mapping of human genomic sequences on hybrid clouds}},
url = {http://www.informatics.indiana.edu/xw7/papers/ndss2012.pdf},
year = {2012}
}
@article{helli,
abstract = {Android’s security framework has been an appealing subject of research in the last few years. Android has been shown to be vulnerable to application-level privilege escalation attacks, such as confused deputy attacks, and more recently, attacks by colluding applications. While most of the proposed approaches aim at solving confused deputy attacks, there is still no solution that simultaneously addresses collusion attacks. In this paper, we investigate the problem of designing and implementing a practical security framework for Android to protect against confused deputy and collusion attacks. We realize that defeating collusion attacks calls for a rather system-centric solution as opposed to application-dependent policy enforcement. To support our design decisions, we conduct a heuristic analysis of Android’s system behavior (with popular apps) to identify attack patterns, classify different adversary models, and point out the challenges to be tackled. Then we propose a solution for a system-centric and policy-driven runtime monitoring of communication channels between applications at multiple layers: 1) at the middleware we control IPCs between applications and indirect communication via Android system components. Moreover, inspired by the approach in QUIRE, we establish semantic links between IPCs and enable the reference monitor to verify the call-chain; 2) at the kernel level we realize mandatory access control on the file system (including Unix domain sockets) and local Internet sockets. To allow for runtime, dynamic low-level policy enforcement, we provide a callback channel between the kernel and the middleware. Finally, we evaluate the efficiency and effectiveness of our framework on known confused deputy and collusion attacks, and discuss future directions.},
author = {Bugiel, Sven and Davi, Lucas and Dmitrienko, Alexandra and Fischer, Thomas and Sadeghi, Ahmad-reza and Shastry, Bhargava},
journal = {ndss},
title = {{Towards Taming Privilege-Escalation Attacks on Android}},
year = {2012}
}
@article{helli,
author = {Schrittwieser, Sebastian and Fr{\"{u}}hwirt, Peter and Kieseberg, Peter and Leithner, Manuel and Mulazzani, Martin and Huber, Markus and Weippl, Edgar R},
journal = {ndss},
title = {{Guess Who's Texting You? Evaluating the Security of Smartphone Messaging Applications.}},
year = {2012}
}
@article{helli,
abstract = {Network intrusion detection and prevention systemscommonly use regular expression (RE) signatures to rep-resent individual security threats. While the correspondingDFA for any one RE is typically small, the DFA that cor-responds to the entire set of REs is usually too large to beconstructed or deployed. To address this issue, a varietyof alternative automata implementations that compress thesize of the final automaton have been proposed such as XFAand D2FA. The resulting final automata are typically muchsmaller than the corresponding DFA. However, the previ-ously proposed automata construction algorithms do sufferfrom some drawbacks. First, most employ a “Union thenMinimize” framework where the automata for each RE arefirst joined before minimization occurs. This leads to anexpensive NFA to DFA subset construction on a relativelylarge NFA. Second, most construct the corresponding largeDFA as an intermediate step. In some cases, this DFA is solarge that the final automaton cannot be constructed eventhough the final automaton is small enough to be deployed.In this paper, we propose a “Minimize then Union” frame-work for constructing compact alternative automata focus-ing on the D2FA. We show that we can construct an almostoptimal final D2FA with small intermediate parsers. Thekey to our approach is a space and time efficient routinefor merging two compact D2FA into a compact D2FA. Inour experiments, our algorithm runs up to 302 times fasterand uses 1390 times less memory than previous algorithms.For example, we are able to construct a D2FA with over80,000,000 states using only 1GB of main memory in only77 minutes},
author = {Liu, JPAX},
journal = {ndss},
title = {{Bypassing Space Explosion in Regular Expression Matching for Network Intrusion Detection and Prevention Systems}},
url = {http://www.cse.msu.edu/{~}torng/Research/Pubs/NDSS2012.pdf},
year = {2012}
}
@article{helli,
author = {Chaabane, Abdelberi and Acs, Gergely and Kaafar, Mohamed Ali},
journal = {ndss},
pages = {1--14},
title = {{You Are What You Like! Information Leakage Through Users’ Interests}},
url = {http://www.crysys.hu/{~}acs/publications.html$\backslash$npapers3://publication/uuid/5ECCE87D-3464-4596-B7B4-B8AEF5A27B5E},
year = {2012}
}
@article{helli,
abstract = {Tor is a large and popular overlay network providing both anonymity to its users and a platform for anonymous communication research. New design proposals and attacks on the system are challenging to test in the live network because of deployment issues and the risk of invading users’ privacy, while alternative Tor experimentation techniques are limited in scale, are inaccurate, or create results that are difficult to reproduce or verify. We present the design and implementation of Shadow, an architecture for efficiently running accurate Tor experiments on a single machine. We validate Shadow’s accuracy with a private Tor deployment on PlanetLab and a comparison to live network performance statistics. To demonstrate Shadow’s powerful capabilities, we investigate circuit scheduling and find that the EWMA circuit scheduler reduces aggregate client performance under certain loads when deployed to the entire Tor network. Our software is open source and available for download.},
author = {Jansen, Rob and Hooper, N and Hopper, Nicholas J.},
journal = {ndss},
title = {{Shadow: Running Tor in a box for accurate and efficient experimentation}},
url = {http://www.cs.umn.edu/tech{\_}reports{\_}upload/tr2011/11-020.pdf$\backslash$nhttp://oai.dtic.mil/oai/oai?verb=getRecord{\&}metadataPrefix=html{\&}identifier=ADA559181},
year = {2012}
}
@article{helli,
author = {Backes, M and Maffei, M and Pecina, K},
journal = {ndss},
title = {{Automated synthesis of privacy-preserving distributed applications}},
url = {http://www.lbs.cs.uni-saarland.de/publications/asosda-long.pdf},
year = {2012}
}
@article{helli,
abstract = {Protecting commodity systems running commercial Op-erating Systems (OSes) without significantly degrading per-formance or usability still remains an open problem. Tomake matters worse, the overall security depends on com-plex applications that perform multiple inter-dependenttasks with Internet-borne code. Recent research has shownthe need for context-dependent trustworthy environmentsthat can segregate different user activities to lower risk ofcross-contamination and safeguard private information.In this paper, we introduce a novel BIOS-assisted mech-anism for secure instantiation and management of trustedexecution environments. A key design characteristic of oursystem is usability: the ability to quickly and securely switchbetween operating environments without requiring any spe-cialized hardware or code modifications. Our aim is toeliminate any mutable, non-BIOS code sharing while se-curely reusing existing hardware: even when an untrustedenvironment is compromised, there is no potential for exfil-tration or inference attacks. To safeguard against spoofingattacks, we can force the user to physically set a hardwareswitch, an action that cannot be reproduced by software.In addition, we provide visible indication to the user aboutthe current running environment leveraging one of the frontpanel Light Emitting Diodes (LEDs). In our prototype, theentire switching process takes approximately six seconds onaverage. This empowers users to frequently and seamlesslyalternate between trusted and untrusted environments.},
author = {Sun, Kun and Wang, Jiang and Zhang, Fengwei and Stavrou, Angelos},
journal = {ndss},
title = {{SecureSwitch : BIOS-Assisted Isolation and Switch between Trusted and Untrusted Commodity OSes}},
year = {2012}
}
@article{helli,
abstract = {An important class of attacks against cellular network infrastructures, i.e., signaling DoS attack, paging channel overload, and channel exhaustion attack, operates by sending low rate data traffic to a large number of mobile devices at a particular location to exhaust bottleneck resources such as radio resource and radio resource controller. We term this class of attack targeted DoS attack on cellular networks, given the focus on a specific location. The success of such attacks depends on an important but unvalidated assumption that it is possible to create a relatively accurate hit list of mobile devices associated with the target network location to which attackers can direct traffic. In this study, we take an important first step to validate this assumption by performing a large-scale study on the feasibility of these attacks. In addition, we propose accurate and efficient techniques for generating IP address to network location association in real time for existing commercial UMTS networks. Our technique relies on developing and measuring network signatures consisting of both static and dynamic features of key network elements such as Radio Network Controllers (RNCs) that are stable within the same location but distinct across locations. We find that a single feature in some cases is unique enough to locate a city such as NYC.With as little as 800kbps probe rate, we can identify a sufficient number of IPs to accurately target a network location, a},
author = {Quian, Zhiyun and Wang, Zhaoguang and Xu, Qiang and Mao, Z. Morley and Zhang, Ming and Wang, Yi-Min},
journal = {ndss},
title = {{You Can Run, but You Can't Hide: Exposing Network Location for Targeted DoS Attacks in Cellular Networks}},
url = {http://web.eecs.umich.edu/{~}zhiyunq/pub/ndss12{\_}rnc{\_}fingerprinting.pdf},
year = {2012}
}
@article{helli,
author = {Nakibly, Gabi and Kirshon, Alex and Gonikman, Dima and Boneh, Dan},
journal = {ndss},
title = {{Persistent OSPF Attacks}},
url = {http://wwwvm.cs.technion.ac.il/he/people/gnakibly/online-publications/PersistentOSPF.pdf},
year = {2012}
}
@article{helli,
abstract = {The widely popular browser extensions now become one of the most commonly used malware attack vectors. The Google Chrome browser, which implements the principles of least privileges and privilege separation by design, of- fers a strong security mechanism to protect malicious web- sites from damaging the whole browser system via exten- sions. In this study, we however reveal that Chrome’s ex- tension security model is not a panacea for all possible at- tacks with browser extensions. Through a series of prac- tical bot-based attacks that can be performed even under typical settings, we demonstrate that malicious Chrome ex- tensions pose serious threats, including both information dispersion and harvesting, to browsers. We further con- duct an in-depth analysis of Chrome’s extension security model, and conclude that its vulnerabilities are rooted from the violation of the principles of least privileges and privi- lege separation. Following these principles, we propose a set of countermeasures that enforce the policies of micro- privilege management and differentiating DOM elements. Using a prototype developed on the latest Chrome browser, we show that they can effectively mitigate the threats posed by malicious Chrome extensions with little effect on normal browsing experience},
author = {Liu, L and Zhang, X and Yan, G and Chen, Songqing},
journal = {ndss},
title = {{Chrome extensions: Threat analysis and countermeasures}},
url = {https://www.cs.gmu.edu/{~}sqchen/publications/NDSS-2012.pdf},
year = {2012}
}
@article{helli,
journal = {ndss},
title = {{ ShortMAC: Efficient Data-Plane Fault Localization }},
year = {2012}
}
@article{Romana,
abstract = {We explore the threat of smartphone malware with access to on-board sensors, which opens new avenues for illicit collection of private information. While existing work shows that such "sensory malware" can convey raw sensor data (e.g., video and audio) to a remote server, these approaches lack stealthiness, incur significant communication and computation overhead during data transmission and processing, and can easily be defeated by existing protections like denying installation of applications with access to both sensitive sensors and the network. We present Soundcomber, a Trojan with few and innocuous permissions, that can extract a small amount of targeted private information from the audio sensor of the phone. Using targeted profiles for context-aware analysis, Soundcomber intelligently "pulls out" sensitive data such as credit card and PIN numbers from both tone- and speech-based interaction with phone menu systems. Soundcomber performs efficient, stealthy local extraction, thereby greatly reducing the communication cost for delivering stolen data. Soundcomber automatically infers the destination phone number by analyzing audio, circumvents known security defenses, and conveys information remotely without direct network access. We also design and implement a defensive architecture that foils Soundcomber, identify new covert channels specific to smartphones, and provide a video demonstration of Soundcomber.},
author = {Schlegel, Roman and Zhang, Kehuan and Zhou, Xiaoyong},
file = {::},
journal = {ndss},
pages = {17--33},
title = {{Soundcomber: A stealthy and context-aware sound trojan for smartphones}},
url = {https://www.cs.indiana.edu/{~}kapadia/papers/soundcomber-ndss11.pdf},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Losing Control of the Internet: Using the Data Plane to Attack the Control Plane}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Tracker: Security and Privacy for RFID-based Supply Chains}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Accurate and Provably Secure Latency Estimation with Treeple}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Privacy-Preserving Aggregation of Time-Series Data}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{WebShield: Enabling Various Web Defense Techniques without Client Side Modifications}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{ Efficient Privacy-Preserving Biometric Identification }},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Efficient Monitoring of Untrusted Kernel-Mode Execution}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Using Classification to Protect the Integrity of Spectrum Measurements in White Space Networks}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Relay Attacks on Passive Keyless Entry and Start Systems in Modern Cars}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Howard: A Dynamic Excavator for Reverse Engineering Data Structures}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{AEG: Automatic Exploit Generation}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{ SPARE: Replicas on Hold }},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{No Loitering: Exploiting Lingering Vulnerabilities in Default COM Objects}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{DTA++: Dynamic Taint Analysis with Targeted Control-Flow Propagation}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Location Privacy via Private Proximity Testing}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{SigGraph: Brute Force Scanning of Kernel Data Structure Instances Using Graph-based Signatures}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{TIE: Principled Reverse Engineering of Types in Binary Programs}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Practical Protection of Kernel Integrity for Commodity OS from Untrusted Extensions}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Good Neighbor: Ad hoc Pairing of Nearby Wireless Devices by Multiple Antennas}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{PiOS: Detecting Privacy Leaks in iOS Applications}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Automated Discovery of Parameter Pollution Vulnerabilities in Web Applications}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{SWIRL: A Scalable Watermark to Detect Correlated Network Flows}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{On Measuring the Similarity of Network Hosts: Pitfalls, New Metrics, and Empirical Analyses}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{HTTPOS: Sealing Information Leaks with Browser-side Obfuscation of Encrypted Flows}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{EXPOSURE: Finding Malicious Domains Using Passive DNS Analysis}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{Usability Testing a Malware-Resistant Input Mechanism}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{A Security API for Distributed Social Networks}},
year = {2011}
}
@article{helli,
journal = {ndss},
title = {{ Stealth DoS Attacks on Secure Channels }},
year = {2010}
}
@article{helli,
abstract = {Online gaming is a lucrative and growing industry but one that is slowed
by cheating that compromises the gaming experience and hence drives away
players (and revenue). In this paper we develop a technique by which
game developers can enable game operators to validate the behavior of
game clients as being consistent with valid execution of the sanctioned
client software. Our technique employs symbolic execution of the client
software to extract constraints on client-side state implied by each
client-to-server message, and then uses constraint solving to determine
whether the sequence of client-to-server messages can be ``explained{\{}''{\}}
by any possible user inputs, in light of the server-to-client messages
already received. The requisite constraints and solving components can
be developed either simultaneously with the game or retroactively for
existing games. We demonstrate our approach in three case studies on the
open-source game XPilot, a game similar to Pac-Man of our own design,
and an open-source multiplayer version of Tetris.},
author = {Bethea, Darrell and Cochran, Robert A and Reiter, Michael K},
doi = {10.1145/2043628.2043633},
issn = {1094-9224},
journal = {ndss},
keywords = {Security; Verification; Computer games; cheat dete},
number = {4},
title = {{Server-Side Verification of Client Behavior in Online Games}},
volume = {14},
year = {2010}
}
@article{helli,
abstract = {Browser extensions are remarkably popular, with one in three Firefox users running at least one extension. Although well-intentioned, extension developers are often not security experts and write buggy code that can be exploited by ma- licious web site operators. In the Firefox extension system, these exploits are dangerous because extensions run with the users full privileges and can read and write arbitrary files and launch new processes. In this paper, we analyze 25 popular Firefox extensions and find that 88{\%} of these extensions need less than the full set of available privileges. Additionally, we find that 76{\%} of these extensions use un- necessarily powerful APIs, making it difficult to reduce their privileges. We propose a new browser extension system that improves security by using least privilege, privilege separa- tion, and strong isolation. Our system limits the misdeeds an attacker can perform through an extension vulnerabil- ity. Our design has been adopted as the Google Chrome extension system.},
author = {Barth, Adam and Felt, Adrienne Porter and Saxena, Prateek and Boodman, Aaron},
doi = {10.1111/j.1365-2486.2006.01169.x},
issn = {13541013},
journal = {ndss},
pages = {1315--1329},
pmid = {22196736},
title = {{Protecting Browsers from Extension Vulnerabilities}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.5579{\&}amp;rep=rep1{\&}amp;type=pdf},
volume = {147},
year = {2010}
}
@article{helli,
abstract = {We have traditionally viewed spam from the receiver’s point of view: mail servers assaulted by a barrage of spam from which we must pick out a handful of legitimate mes- sages. In this paper we describe a system for better filtering spam by exploiting the vantage point of the spammer. By instantiating and monitoring botnet hosts in a controlled environment, we are able to monitor new spam as it is cre- ated, and consequently infer the underlying template used to generate polymorphic e-mail messages. We demonstrate this approach on mail traces from a range of modern bot- nets and show that we can automatically filter such spam precisely and with virtually no false positives.},
author = {Pitsillidis, Andreas and Kreibich, Christian and Weaver, Nicholas and Kanich, Chris and Savage, Stefan},
doi = {10.1.1.162.1106},
journal = {ndss},
title = {{Botnet Judo : Fighting Spam with Itself}},
year = {2010}
}
@article{helli,
abstract = {Researchers at the University ofWashington recently proposed Vanish [19], a system for creating messages that automatically “self-destruct” after a period of time. Vanish works by encrypting each message with a random key and storing shares of the key in a large, public distributed hash table (DHT). Normally, DHTs expunge data older than a certain age. After they expire, the key is permanently lost, and the encrypted data is permanently unreadable. Vanish is an interesting approach to an important privacy problem, but, in its current form, it is insecure. In this paper, we defeat the deployed Vanish implementation, explain how the original paper’s security analysis is flawed, and draw lessons for future system designs. We present two Sybil attacks against the current Vanish implementation, which stores its encryption keys in the million-node Vuze BitTorrent DHT. These attacks work by continuously crawling the DHT and saving each stored value before it ages out. They can efficiently recover keys for more than 99{\%} of Vanish messages. We show that the dominant cost of these attacks is network data transfer, not memory usage as the Vanish authors expected, and that the total cost is two orders of magnitude less than they estimated. While we consider potential defenses, we conclude that public DHTs like Vuze probably cannot provide strong security for Vanish.},
author = {Wolchok, Scott and Hofmann, Owen S and Heninger, Nadia and Felten, Edward W and Halderman, J Alex and Rossbach, Christopher J and Waters, Brent and Witchel, Emmett},
journal = {ndss},
pages = {1--20},
title = {{Defeating Vanish with Low-Cost Sybil Attacks Against Large DHTs}},
year = {2010}
}
@article{helli,
abstract = {Phishing websites, fraudulent sites that impersonate a trusted third party to gain access to private data, continue to cost Internet users over a billion dollars each year. In this paper, we describe the design and performance char- acteristics of a scalable machine learning classifier we de- veloped to detect phishing websites. We use this classifier to maintain Google’s phishing blacklist automatically. Our classifier analyzes millions of pages a day, examining the URL and the contents of a page to determine whether or not a page is phishing. Unlike previous work in this field, we train the classifier on a noisy dataset consisting of mil- lions of samples frompreviously collected live classification data. Despite the noise in the training data, our classifier learns a robust model for identifying phishing pages which correctly classifies more than 90{\%} of phishing pages sev- eral weeks after training concludes.},
author = {Whittaker, Colin and Ryner, Brian and Nazif, Marria},
journal = {ndss},
title = {{Large-Scale Automatic Classification of Phishing Pages}},
url = {http://www.isoc.org/isoc/conferences/ndss/10/pdf/08.pdf$\backslash$nhttp://research.google.com/pubs/pub35580.html},
year = {2010}
}
@article{helli,
abstract = {Publishers wish to sandbox third-party advertisements to protect themselves from malicious advertisements. One promising approach, used by ADsafe, Dojo Secure, and Jacaranda, sandboxes advertisements by statically verify- ing that their JavaScript conforms to a safe subset of the language. These systems blacklist known dangerous proper- ties that would let advertisements escape the sandbox. Un- fortunately, this approach does not prevent advertisements from accessing new methods added to the built-in prototype objects by the hosting page. In this paper, we show that one- third of the Alexa US Top 100 web sites would be exploitable by an ADsafe-verified advertisement. We propose an im- proved statically verified JavaScript subset that whitelists known-safe properties using namespaces. Our approach maintains the expressiveness and performance of static ver- ification while improving security.},
author = {Finifter, Matthew and Weinberger, Joel and Barth, Adam},
doi = {10.1016/S1353-4858(10)70027-1},
journal = {ndss},
pages = {14},
title = {{Preventing Capability Leaks in Secure JavaScript Subsets Network Network Web Page}},
year = {2010}
}
@article{helli,
journal = {ndss},
title = {{ A3: An Extensible Platform for Application-Aware Anonymity }},
year = {2010}
}
@article{helli,
author = {Antonatos, S and Polakis, I},
journal = {ndss},
title = {{A systematic characterization of IM threats using honeypots}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?rep=rep1{\&}type=pdf{\&}doi=10.1.1.183.3171},
year = {2010}
}
@article{helli,
abstract = {We present Joe-E, a language designed to support the development of secure software systems. Joe-E is a subset of Java that makes it easier to architect and implement programs with strong security properties that can be checked during a security review. It enables programmers to apply the principle of least privilege to their programs; implement application-specific reference monitors that cannot be bypassed; introduce and use domain-specific security abstractions; safely execute and interact with untrusted code; and build secure, extensible systems. Joe-E demonstrates how it is possible to achieve the strong security properties of an object-capability language while retaining the features and feel of a mainstream object-oriented language. Additionally, we present ways in which Java's static type safety complements object-capability analysis and permits additional security properties to be verified statically, compared with previous object-capability languages which rely on runtime checks. In this paper, we describe the design and implementation of Joe-E and its advantages for security and auditability over standard Java. We demonstrate how Joe-E can be used to develop systems with novel security properties that would be difficult or impossible to ensure otherwise, including a web application platform that provides transparent, transactional object persistence and can safely host multiple mutually-distrustful applications in a single JVM.},
author = {Mettler, Adrian and Close, Tyler},
doi = {10.1016/j.actaastro.2004.12.002},
issn = {<null>},
journal = {ndss},
pages = {1--20},
title = {{Joe-E : A Security-Oriented Subset of Java}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.3673{\&}amp;rep=rep1{\&}amp;type=pdf},
year = {2010}
}
@article{helli,
abstract = {Unsolicited bulk e-mail (UBE) or spam constitutes a sig- nificant fraction of all e-mail connection attempts and rou- tinely frustrates users, consumes resources, and serves as an infection vector for malicious software. In an effort to scalably and effectively reduce the impact of these e-mails, e-mail system designers have increasingly turned to black- listing. Blacklisting (blackholing, block listing) is a form of course-grained, reputation-based, dynamic policy enforce- ment in which real-time feeds of spam sending hosts are sent to networks so that the e-mail from these hosts may be re- jected. Unfortunately, current spam blacklist services are highly inaccurate and exhibit both false positives and sig- nificant false negatives. In this paper, we explore the root causes of blacklist inaccuracy and show that the trend to- ward stealthier spam exacerbates the existing tension be- tween false positives and false negatives when assigning spamming IP reputation. We argue that to relieve this ten- sion, global aggregation and reputation assignment should be replaced with local aggregation and reputation assign- ment, utilizing preexisting global spam collection, with the addition of local usage, policy, and reachability informa- tion. We propose two specific techniques based on this premise, dynamic thresholding and speculative aggregation, whose goal is to improve the accuracy of blacklist genera- tion. We evaluate the performance and accuracy of these solutions in the context of our own deployment consisting of 2.5 million production e-mails and 14 million e-mails from spamtraps deployed in 11 domains over a month-long pe- riod. We show that the proposed approaches significantly improve the false positive and false negative rates when compared to existing approaches. 1},
author = {Sinha, Sushant and Bailey, Michael and Jahanian, Farnam and Arbor, Ann},
journal = {ndss},
title = {{Improving Spam Blacklisting Through Dynamic Thresholding and Speculative Aggregation}},
year = {2010}
}
@article{helli,
abstract = {We analyze filename-based privilege escalation attacks, where an attacker$\backslash$ncreates filesystem links, thereby "tricking" a victim program into$\backslash$nopening unintended files. We develop primitives for a POSIX environment,$\backslash$nproviding assurance that files in "safe directories" (such as /etc/passwd)$\backslash$ncannot be opened by looking up a file by an "unsafe pathname" (such$\backslash$nas a pathname that resolves through a symbolic link in a world-writable$\backslash$ndirectory). In today's UNIX systems, solutions to this problem are$\backslash$ntypically built into (some) applications and use application-specific$\backslash$nknowledge about (un)safety of certain directories. In contrast, we$\backslash$nseek solutions that can be implemented in the filesystem itself (or$\backslash$na library on top of it), thus providing protection to all applications.$\backslash$n$\backslash$n$\backslash$nOur solution is built around the concept of pathname manipulators,$\backslash$nwhich are roughly the users that can influence the result of a file$\backslash$nlookup operation. For each user, we distinguish unsafe pathnames$\backslash$nfrom safe pathnames according to whether or not the pathname has$\backslash$nany manipulators other than that user or root. We propose a safe-open$\backslash$nprocedure that keeps track of the safety of the current pathname$\backslash$nas it resolves it, and that takes extra precautions while opening$\backslash$nfiles with unsafe pathnames. We prove that our solution can prevent$\backslash$na common class of filename-based privilege escalation attacks, and$\backslash$ndescribe our implementation of the safe-open procedure as a library$\backslash$nfunction over the POSIX filesystem interface. We tested our implementation$\backslash$non several UNIX variants to evaluate its implications for systems$\backslash$nand applications. Our experiments suggest that this solution can$\backslash$nbe deployed in a portable way without breaking existing systems,$\backslash$nand that it is effective against this class of pathname resolution$\backslash$nattacks.},
author = {Chari, Suresh and Halevi, S. and Venema, W.},
journal = {ndss},
title = {{Where Do You Want to Go Today ? Escalating Privileges by Pathname Manipulation}},
url = {http://domino.watson.ibm.com/library/CyberDig.nsf/papers/234774460318DB03852576710068B0EB/{\$}File/rc24900.pdf},
year = {2010}
}
@article{helli,
journal = {ndss},
title = {{ InvisiType: Object-Oriented Security Policies }},
year = {2010}
}
@article{helli,
author = {Pan, YGXCN and Mao, ZM},
journal = {ndss},
title = {{On the Safety of Enterprise Policy Deployment}},
url = {http://web.eecs.umich.edu/{~}stgyd/papers/ndssGao2010.pdf},
year = {2010}
}
@article{helli,
author = {Lin, Zhiqiang and Zhang, Xiangyu and Xu, Dongyan},
journal = {ndss},
title = {{Automatic reverse engineering of data structures from binary execution}},
year = {2010}
}
@article{helli,
abstract = {Online behavioral advertising (OBA) refers to the practice of tracking users across web sites in order to infer user interests and preferences. These interests and preferences are then used for selecting ads to present to the user. There is great concern that behavioral advertising in its present form infringes on user privacy. The resulting public debate — which includes consumer advocacy organizations, professional associations, and government agencies — is premised on the notion that OBA and privacy are inherently in conflict. In this paper we propose a practical architecture that enables targeting without compromising user privacy. Behavioral profiling and targeting in our system takes place in the user’s browser. We discuss the effectiveness of the system as well as potential social engineering and web-based attacks on the architecture. One complication is billing; ad-networks must bill the correct advertiser without knowing which ad was displayed to the user. We propose an efficient cryptographic billing system that directly solves the problem. We implemented the core targeting system as a Firefox extension and report on its effectiveness.},
author = {Toubiana, Vincent and Narayanan, Arvind and Boneh, Dan and Nissenbaum, Helen and Barocas, Solon},
journal = {ndss},
pages = {1--21},
title = {{Adnostic : Privacy Preserving Targeted Advertising}},
url = {http://www.internetsociety.org/doc/adnostic-privacy-preserving-targeted-advertising},
year = {2010}
}
@article{helli,
abstract = {Random number generators (RNGs) are consistently a weak link in the secure use of cryptography. Routine cryptographic operations such as encryption and signing can fail spectacularly given predictable or repeated randomness, even when using good long-lived key material. This has proved problematic in prior settings when RNG implementation bugs, poor design, or low-entropy sources have resulted in predictable randomness. We investigate a new way in which RNGs fail due to reuse of virtual machine (VM) snapshots. We exhibit such VM reset vulnerabilities in widely-used TLS clients and servers: the attacker takes advantage of (or forces) snapshot replay to compromise sessions or even expose a server's DSA signing key. Our next contribution is a backwards-compatible framework for hedging routine cryptographic operations against bad randomness, thereby mitigating the damage due to randomness failures. We apply our framework to the OpenSSL library and experimentally confirm that it has little overhead.},
author = {Ristenpart, T and Yilek, S},
journal = {ndss},
number = {Vm},
title = {{When Good Randomness Goes Bad: Virtual Machine Reset Vulnerabilities and Hedging Deployed Cryptography.}},
url = {http://pages.cs.wisc.edu/{~}rist/papers/sslhedge.pdf},
year = {2010}
}
@article{helli,
author = {Schwartz, Edward J and Mccune, Jonathan M},
journal = {ndss},
keywords = {anonymous authentication,group signatures,trusted computing},
number = {September},
title = {{Contractual Anonymity}},
year = {2010}
}
@article{helli,
abstract = {The complexity of the client-side components of web applications has exploded with the increase in popularity of web 2.0 applications. Today, traditional desktop ap- plications, such as document viewers, presentation tools and chat applications are commonly available as online JavaScript applications. Previous research on web vulnerabilities has primarily concentrated on flaws in the server-side components of web applications. This paper highlights a new class of vulnera- bilities, which we term client-side validation (or CSV) vul- nerabilities. CSV vulnerabilities arise from unsafe usage of untrusted data in the client-side code of the web applica- tion that is typically written in JavaScript. In this paper, we demonstrate that they can result in a broad spectrum of attacks. Our work provides empirical evidence that CSV vulnerabilities are not merely conceptual but are prevalent in todays web applications. We propose dynamic analysis techniques to systemati- cally discover vulnerabilities of this class. The techniques are light-weight, efficient, and have no false positives. We implement our techniques in a prototype tool called FLAX, which scales to real-world applications and has discovered 11 vulnerabilities in the wild so far.},
author = {Saxena, Prateek and Hanna, Steve},
journal = {ndss},
pages = {17},
title = {{FLAX : Systematic Discovery of Client-side Validation Vulnerabilities in Rich Web Applications}},
year = {2010}
}
@article{helli,
abstract = {Binary code reutilization is the process of automatically identifying the interface and extracting the instructions and data dependencies of a code fragment from an executable program, so that it is selfcontained and can be reused by external code. Binary code reutilization is useful for a number of security applications, including reusing the proprietary cryptographic or unpacking functions from a malware sample and for rewriting a network dialog. In this paper we conduct the first systematic study of automated binary code reutilization and its security applications. The main challenge in binary code reutilization is understanding the code fragments interface. We propose a novel technique to identify the prototype of an undocumented code fragment directly from the programs binary, without access to source code or symbol information. Further, we must also extract the code itself from the binary so that it is self-contained and can be easily reused in another program. We design and implement a tool that uses a combination of dynamic and static analysis to automatically identify the prototype and extract the instructions of an assembly function into a form that can be reused by other C code. The extracted function can be run independently of the rest of the programs functionality and shared with other users. We apply our approach to scenarios that include extracting the encryption and decryption routines from malware samples, and show that these routines can be reused by a network proxy to decrypt encrypted traffic on the network. This allows the network proxy to rewrite the malwares encrypted traffic by combining the extracted encryption and decryption functions with the session keys and the protocol grammar. We also show that we can reuse a code fragment from an unpacking function for the unpacking routine for a different sample of the same family, even if the code fragment is not a complete function.},
author = {Caballero, Juan and Johnson, Noah M. and Mccamant, Stephen and Song, Dawn},
journal = {ndss},
title = {{Binary Code Extraction and Interface Identification for Security Applications}},
year = {2010}
}
@article{helli,
abstract = {Learning-based anomaly detection has proven to be an effective black-box technique for detecting unknown attacks. However, the effectiveness of this technique crucially depends upon both the quality and the com- pleteness of the training data. Unfortunately, in most cases, the traffic to the system (e.g., a web applica- tion or daemon process) protected by an anomaly de- tector is not uniformly distributed. Therefore, some components (e.g., authentication, payments, or content publishing) might not be exercised enough to train an anomaly detection system in a reasonable time frame. This is of particular importance in real-world settings, where anomaly detection systems are deployed with lit- tle or no manual configuration, and they are expected to automatically learn the normal behavior of a system to detect or block attacks. In this work, we first demonstrate that the features utilized to train a learning-based detector can be se- mantically grouped, and that features of the same group tend to induce similar models. Therefore, we propose addressing local training data deficiencies by exploiting clustering techniques to construct a knowledge base of well-trained models that can be utilized in case of un- dertraining. Our approach, which is independent of the particular type of anomaly detector employed, is vali- dated using the realistic case of a learning-based system protecting a pool of web servers running several web applications such as blogs, forums, orWeb services. We run our experiments on a real-world data set containing over 58 million HTTP requests to more than 36,000 dis- tinct web application components. The results show that by using the proposed solution, it is possible to achieve effective attack detection even with scarce training data.},
author = {Robertson, William and Maggi, Federico and Vigna, C.K.G.},
doi = {10.1.1.183.3323},
journal = {ndss},
keywords = {anomaly detection,training data,web appli-},
pages = {16},
title = {{Effective Anomaly Detection with Scarce Training Data}},
url = {http://wilrobertson.com/public/files/publications/ndss2010scarcity.pdf},
year = {2010}
}
@article{helli,
abstract = {Malware is the root cause of many security threats on the Internet. To cope with the thousands of new malware samples that are discovered every day, security compa- nies and analysts rely on automated tools to extract the runtime behavior of malicious programs. Of course, mal- ware authors are aware of these tools and increasingly try to thwart their analysis techniques. To this end, mal- ware code is often equipped with checks that look for ev- idence of emulated or virtualized analysis environments. When such evidence is found, the malware program be- haves differently or crashes, thus showing a different “personality” than on a real system. Recent work has introduced transparent analysis plat- forms (such as Ether or Cobra) that make it signif- icantly more difficult for malware programs to detect their presence. Others have proposed techniques to iden- tify and bypass checks introduced by malware authors. Both approaches are often successful in exposing the runtime behavior of malware even when the malicious code attempts to thwart analysis efforts. However, these techniques induce significant performance overhead, es- pecially for fine-grained analysis. Unfortunately, this makes them unsuitable for the analysis of current high- volume malware feeds. In this paper, we present a technique that efficiently detects when a malware program behaves differently in an emulated analysis environment and on an uninstru- mented reference host. The basic idea is simple: we just compare the runtime behavior of a sample in our anal- ysis system and on a reference machine. However, ob- taining a robust and efficient comparison is very difficult. In particular, our approach consists of recording the in- teractions of the malware with the operating system in one run and using this information to deterministically replay the program in our analysis environment. Our ex- periments demonstrate that, by using our approach, one 3 University of California, Santa Barbara can efficiently detect malware samples that use a variety of techniques to identify emulated analysis environments.},
author = {Balzarotti, Davide and Cova, Marco and Karlberger, Christoph and Kruegel, Christopher and Kirda, Engin and Vigna, Giovanni},
journal = {ndss},
title = {{Efficient Detection of Split Personalities in Malware.}},
url = {https://cs.ucsb.edu/{~}vigna/publications/2010{\_}balzarotti{\_}cova{\_}karlberger{\_}kruegel{\_}kirda{\_}vigna{\_}SplitPersonality.pdf},
year = {2010}
}
@article{helli,
abstract = {Domain Name System Security Extensions (DNSSEC) and Hashed Authenticated Denial of Existence (NSEC3) are slated for adoption by important parts of the DNS hierar- chy, including the root zone, as a solution to vulnerabili- ties such as ”cache-poisoning” attacks. We study the secu- rity goals and operation of DNSSEC/NSEC3 using Mur휑, a finite-state enumeration tool, to analyze security prop- erties that may be relevant to various deployment scenar- ios. Our systematic study reveals several subtleties and po- tential pitfalls that can be avoided by proper configuration choices, including resource records that may remain valid after the expiration of relevant signatures and potential in- sertion of forged names into a DNSSEC-enabled domain via the opt-out option. We demonstrate the exploitability of DNSSEC opt-out options in an enterprise setting by con- structing a browser cookie-stealing attack on a laboratory domain. Under recommended configuration settings, fur- ther Mur휑 model checking finds no vulnerabilities within our threat model, suggesting that DNSSEC with NSEC3 provides significant security benefits. 1},
author = {Bau, Jason and Mitchell, JC},
journal = {ndss},
title = {{A Security Evaluation of DNSSEC with NSEC3.}},
url = {http://crypto.stanford.edu/cs155/papers/dnssec{\_}ndss10.pdf},
year = {2010}
}
@article{helli,
author = {Qian, Zhiyun and Mao, Zm and Xie, Yinglian and Yu, Fang},
journal = {ndss},
title = {{On Network-level Clusters for Spam Detection.}},
url = {https://web.eecs.umich.edu/{~}zmao/Papers/ndssZhiyun2010.pdf},
year = {2010}
}
@article{helli,
abstract = {We describe CSAR, a novel technique for generating cryptographically strong, accountable randomness. Using CSAR, we can generate a pseudo-random sequence and a proof that the elements of this sequence up to a given point have been correctly generated, while future values in the sequence remain unpredictable. CSAR enables accountability for distributed systems that use randomized protocols. External auditors can check if a node has deviated from its expected behavior without learning anything about the node’s future random choices. In particular, an accountable node does not need to leak secrets that would make its future actions predictable. We demonstrate that CSAR is practical and efficient, and we apply it to implement accountability for a server that uses random sampling for billing purposes. 1},
author = {Backes, Michael and Druschel, P. and Haeberlen, a.},
journal = {ndss},
pages = {341--353},
title = {{CSAR: A practical and provable technique to make randomized systems accountable}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.158.2601{\&}amp;rep=rep1{\&}amp;type=pdf},
year = {2009}
}
@article{helli,
author = {Danezis, George and Mittal, Prateek},
journal = {ndss},
title = {{Sybilinfer: Detecting sybil nodes using social networks}},
url = {papers3://publication/uuid/C7EB41A7-E264-4881-A536-77862831FBFF},
year = {2009}
}
@article{helli,
abstract = {We present Spectrogram, a machine learning based statistical anomaly detection (AD) sensor for defense against web-layer code-injection attacks. These attacks include PHP ﬁle inclusion, SQL-injection and cross-site-scripting; memory-layer exploits such as buffer overﬂows are addressed as well. Statistical AD sensors offer the advantage of being driven by the data that is being protected and not by malcode samples captured in the wild. While models using higher order statistics can often improve accuracy, trade-offs with false-positive rates and model efﬁciency remain a limiting usability factor. This paper presents a new model and sensor framework that offers a favorable balance under this constraint and demonstrates improvement over some existing approaches. Spectrogram is a network situated sensor that dynamically assembles packets to reconstruct content ﬂows and learns to recognize legitimate web-layer script input. We describe an efﬁcient model for this task in the form of a mixture of Markov-chains and derive the corresponding training algorithm. Our evaluations show signiﬁcant detection results on an array of real world web layer attacks, comparing favorably against other AD approaches.},
author = {Song, Yingbo and a.D. Keromytis},
journal = {ndss},
pages = {15},
title = {{Spectrogram: A mixture-of-markov-chains model for anomaly detection in web traffic}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.147.2436{\&}amp;rep=rep1{\&}amp;type=pdf$\backslash$nhttp://www.cs.fit.edu/{~}pkc/id/related/song09ndss.pdf},
year = {2009}
}
@article{helli,
abstract = {Cross-site scripting (or XSS) has been the most domi- nant class of web vulnerabilities in 2007. The main under- lying reason for XSS vulnerabilities is that web markup and client-side languages do not provide principledmechanisms to ensure secure, ground-up isolation of user-generated data in web application code. In this paper, we develop a new approach that combines randomization of web ap- plication code and runtime tracking of untrusted data both on the server and the browser to combat XSS attacks. Our technique ensures a fundamental integrity property that pre- vents untrusted data from altering the structure of trusted code throughout the execution lifetime of the web applica- tion. We call this property document structure integrity (or DSI). Similar to prepared statements in SQL, DSI enforce- ment ensures automatic syntactic isolation of inline user- generated data at the parser-level. This forms the basis for confinement of untrusted data in the web browser based on a server-specified policy. We propose a client-server architecture that enforces document structure integrity in a way that can be imple- mented in current browsers with a minimal impact to com- patibility and that requires minimal effort from the web de- veloper. We implemented a proof-of-concept and demon- strated that suchDSI enforcement with a simple default pol- icy is sufficient to defeat over 98{\%} of 5,328 real-world re- flected XSS vulnerabilities documented in 2007, with very low performance overhead both on the client and server.},
author = {Nadji, Y and Saxena, P and Song, D},
journal = {ndss},
title = {{Document structure integrity: A robust basis for cross-site scripting defense}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.3372{\&}rep=rep1{\&}type=pdf},
year = {2009}
}
@article{helli,
abstract = {attacks, where the tasks involved in an at- tack are distributed amongst multiple sources, can be used by an adversary to obfuscate his incursion. In this paper we present an approach to detecting  attacks that is based on adversary modeling of the },
author = {Gates, C},
journal = {ndss},
title = {{Coordinated scan detection}},
url = {http://206.131.241.137/isoc/conferences/ndss/09/pdf/09.pdf$\backslash$npapers2://publication/uuid/7C607850-1CD4-469E-A619-8567667AA42D},
year = {2009}
}
@article{helli,
author = {Hu, Xin and Knysz, Matthew and Shin, Kang G},
journal = {ndss},
title = {{Rb-seeker: Auto-detection of redirection botnets}},
url = {papers3://publication/uuid/8EBB1266-4CC4-4672-9022-5338C3763159},
year = {2009}
}
@article{helli,
abstract = {The prevalence of malware such as keyloggers and screen scrapers has$\backslash$nmade the prospect of providing sensitive infor- mation via web pages$\backslash$ndisconcerting for security-conscious users. We present Bumpy, a system$\backslash$nto exclude the legacy operating system and applications from the$\backslash$ntrusted com- puting base for sensitive input, without requiring a$\backslash$nhyper- visor or VMM. Bumpy allows the user to specify strings of$\backslash$ninput as sensitive when she enters them, and ensures that these inputs$\backslash$nreach the desired endpoint in a protected state. The inputs are processed$\backslash$nin an isolated code module on the user’s system, where they can be$\backslash$nencrypted or otherwise processed for a remote webserver. We present$\backslash$na prototype implementation of Bumpy.},
author = {McCune, Jonathan M and Perrig, Adrian and Reiter, Michael K},
journal = {ndss},
pages = {301--320},
title = {{Safe passage for passwords and other sensitive data}},
url = {http://www.cs.unc.edu/{~}reiter/papers/2009/NDSS.pdf},
year = {2009}
}
@article{helli,
abstract = {Traffic Morphing Against Statistical Analysis},
author = {Wright, Charles V and Coull, Scott E and Monrose, Fabian and Hill, Chapel},
journal = {ndss},
number = {3},
pages = {375--382},
title = {{Traffic Morphing : An Efficient Defense Against Statistical Traffic Analysis}},
url = {https://ng.gnunet.org/morphing09},
volume = {CE-33},
year = {2009}
}
@article{helli,
author = {Gundy, Matthew Van and Gundy, Matthew Van and Chen, Hao and Chen, Hao},
journal = {ndss},
pages = {1--18},
title = {{Noncespaces: using randomization to enforce information ow tracking and thwart cross-site scripting attacks}},
year = {2009}
}
@article{helli,
abstract = {The number of identified integer overflow vulnerabilities has been increasing rapidly in recent years. In this paper, we present a system, IntScope, which can automatically detect integer overflow vulnerabilities in x86 binaries before an attacker does, with the goal of finally eliminating the vulnerabilities. IntScope first translates the disassembled code into our own intermediate representation (IR), and then performs a path sensitive data flow analysis on the IR by leveraging symbolic execution and taint analysis to identify the vulnerable point of integer overflow. Compared with other approaches, IntScope does not run the binary directly, and is scalable to large software as it can just symbolically execute the interesting program paths. Experimental results show IntScope is quite encouraging: it has detected more than 20 zero-day integer overflows (e.g., CVE-2008-4201, FrSIRT/ADV-2008-2919) in widely-used software such as QEMU, Xen and Xine.},
author = {Wang, Tielei and Wei, Tao and Lin, Zhiqiang and Zou, Wei},
issn = {00223166},
journal = {ndss},
pages = {1--63},
pmid = {3822816},
title = {{IntScope : Automatically Detecting Integer Overflow Vulnerability in X86 Binary Using Symbolic Execution}},
url = {http://www.cs.purdue.edu/homes/zlin/ndss09.html},
year = {2009}
}
@article{helli,
abstract = {Kernel rootkits provide user level-malware programs with additional capabilities of hiding their malicious activities by altering the legitimate kernel behavior of the operating system. In this paper, we present an approach that enables automatic discovery of the system data manipulation behaviors of rootkits. We have performed experiments on several kernel malware samples and shown that our system can successfully extract all malicious data manipulation behaviors from them. We also discuss the limitations of our current system on newer rootkit strategies.},
author = {Lanzi, a and Sharif, Mi and Lee, W},
doi = {http://www.isoc.org/isoc/conferences/ndss/09/pdf/12.pdf},
journal = {ndss},
pages = {163--169},
title = {{K-Tracer: A System for Extracting Kernel Malware Behavior.}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6295971$\backslash$nhttps://www.iseclab.org/people/andrew/download/K-Tracer.pdf},
year = {2009}
}
@article{helli,
author = {Dagon, David and Antonakakis, Manos and Day, Kevin},
journal = {ndss},
title = {{Recursive DNS architectures and vulnerability implications}},
url = {http://jbcn.dhs.org/papers/recursive{\_}dns{\_}architectures.pdf},
year = {2009}
}
@article{helli,
abstract = {Shifts in flower symmetry have occurred frequently during the diversification of angiosperms, and it is thought that such shifts play important roles in plant-pollinator interactions. In the model developmental system Antirrhinum majus (snapdragon), the closely related genes CYCLOIDEA (CYC) and DICHOTOMA (DICH) are needed for the development of zygomorphic flowers and the determination of adaxial (dorsal) identity of floral organs, including adaxial stamen abortion and asymmetry of adaxial petals. However, it is not known whether these genes played a role in the divergence of species differing in flower morphology and pollination mode. We compared A. majus with a close relative, Mohavea confertiflora (desert ghost flower), which differs from Antirrhinum in corolla (petal) symmetry and pollination mode. In addition, Mohavea has undergone a homeotic-like transformation in stamen number relative to Antirrhinum, aborting the lateral and adaxial stamens during flower development. Here we show that the patterns of expression of CYC and DICH orthologs have shifted in concert with changes in floral morphology. Specifically, lateral stamen abortion in Mohavea is correlated with an expansion of CYC and DICH expression, and internal symmetry of Mohavea adaxial petals is correlated with a reduction in DICH expression during petal differentiation. We propose that changes in the pattern of CYC and DICH expression have contributed to the derived flower morphology of Mohavea and may reflect adaptations to a pollination strategy resulting from a mimetic relationship, linking the genetic basis for morphological evolution to the ecological context in which the morphology arose.},
author = {Bayer, Ulrich and Comparetti, Paolo Milani and Hlauschek, Clemens and Kruegel, Christopher and Kirda, Engin},
doi = {10.1073/pnas.1835725100},
issn = {00278424},
journal = {ndss},
number = {3},
pages = {51--88},
pmid = {8999854},
title = {{Scalable , Behavior-Based Malware Clustering}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.7690{\&}amp;rep=rep1{\&}amp;type=pdf},
volume = {272},
year = {2009}
}
@article{helli,
abstract = {Several off-the-shelf products enable network operators to enforce usage restrictions by actively terminating con- nections when deemed undesirable. While the spectrum of their application is large—from ISPs limiting the usage of P2P applications to the “Great Firewall of China”—many of these systems implement the same approach to disrupt the communication: they inject artificial TCP Reset (RST) packets into the network, causing the endpoints to shut down communication upon receipt. In this work, we study the characteristics of packets injected by such traffic con- trol devices. We show that by exploiting the race-conditions that out-of-band devices inevitably face, we not only can detect the interference but often also fingerprint the spe- cific device in use. We develop an efficient injection detector and demonstrate its effectiveness by identifying a range of disruptive activity seen in traces from four different sites, including termination of P2P connections, anti-spam and anti-virus mechanisms, and the finding that China’s “Great Firewall” has multiple components, sometimes apparently operating without coordination. We also find a number of sources of idiosyncratic connection termination that do not reflect third-party traffic disruption, including NATs, load- balancers, and spam bots. In general, our findings highlight that (i) Internet traffic faces a wide range of control devices using injected RST packets, and (ii) to reliably detect RST injection while avoiding misidentification of other types of activity requires significant care.},
author = {Weaver, N and Sommer, R and Paxson, V},
journal = {ndss},
pages = {15},
title = {{Detecting Forged TCP Reset Packets}},
url = {papers://9934fd52-194f-4a2f-b130-d9de48bdab09/Paper/p69},
year = {2009}
}
@article{helli,
author = {Williams, Peter and Sion, Radu and Shasha, D},
journal = {ndss},
title = {{The Blind Stone Tablet : Outsourcing Durability to Untrusted Parties}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.150.9287{\&}rep=rep1{\&}type=pdf},
year = {2009}
}
@article{helli,
author = {Chow, Sherman S M and Lee, Jie-Han and Subramanian, Lakshminarayanan},
journal = {ndss},
pages = {--1----1},
title = {{Two-Party Computation Model for Privacy-Preserving Queries over Distributed Databases.}},
year = {2009}
}
@article{helli,
author = {Chen, Hong and Li, Ninghui and Mao, Ziqing},
doi = {10.1007/978-3-642-38631-2},
isbn = {978-3-642-38630-5},
journal = {ndss},
pages = {11--16},
title = {{Analyzing and Comparing the Protection Quality of Security Enhanced Operating Systems.}},
year = {2009}
}
@article{helli,
author = {Karlof, Chris and Tygar, J. D. and Wagner, David},
doi = {10.1145/1572532.1572578},
isbn = {9781605587363},
journal = {ndss},
pages = {1},
title = {{Conditioned-safe ceremonies and a user study of an application to web authentication}},
url = {http://portal.acm.org/citation.cfm?doid=1572532.1572578},
year = {2009}
}
@article{helli,
abstract = {Over the past few years, injection vulnerabilities have become the primary target for remote exploits. SQL in- jection, command injection, and cross-site scripting are some of the popular attacks that exploit these vulnerabili- ties. Taint-tracking has emerged as one of the most promis- ing approaches for defending against these exploits, as it supports accurate detection (and prevention) of popular in- jection attacks. However, practical deployment of taint- tracking defenses has been hampered by a number of fac- tors, including: (a) high performance overheads (often over 100{\%}), (b) the need for deep instrumentation, which has the potential to impact application robustness and stabil- ity, and (c) specificity to the language in which an appli- cation is written. In order to overcome these limitations, we present a new technique in this paper called taint infer- ence. This technique does not require any source-code or binary instrumentation of the application to be protected; instead, it operates by intercepting requests and responses from this application. For most web applications, this inter- ception may be achieved using network layer interposition or library interposition. We then develop a class of policies called syntax- and taint-aware policies that can accurately detect and/or block most injection attacks. An experimental evaluation shows that our techniques are effective in detect- ing a broad range of attacks on applications written in mul- tiple languages (including PHP, Java and C), and impose low performance overheads (below 5{\%}).},
author = {Brook, Stony},
journal = {ndss},
number = {January 2006},
title = {{An Efficient Black-box Technique for Defeating Web Application Attacks}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.153.1791{\&}amp;rep=rep1{\&}amp;type=pdf},
year = {2009}
}
@article{helli,
abstract = {Linking network flows is an important problem in intrusion detection as well as anonymity. Passive traffic analysis can link flows but requires long periods of observation to reduce errors. Watermarking techniques allow for better precision and blind detection, but they do so by introducing significant delays to the traffic flow, enabling attacks that detect and remove the mark, while at the same time slowing down legitimate traffic. We propose a new, non-blind watermarking scheme called RAINBOW that is able to use delays hundreds of times smaller than existing watermarks by eliminating the interference caused by the flow in the blind case. As a result, our watermark is invisible to detection, as confirmed by experiments using information-theoretic detection tools. We analyze the error rates of our scheme based on a mathematical model of network traffic and jitter. We also validate the analysis using an implementation running on PlanetLab. We find that our scheme generates orders of magnitudes lower rates of false errors than passive traffic analysis, while using only a few hundred observed packets. We also extend our scheme so that it is robust to packet drops and repacketization and show that flows can still be reliably linked, though at the cost of somewhat longer observation period.},
author = {Houmansadr, Amir and Kiyavash, Negar and Borisov, Nikita},
journal = {ndss},
keywords = {corrleation,network flow,scalable waqtermark},
title = {{RAINBOW: A Robust And Invisible Non-Blind Watermark for Network Flows.}},
url = {http://hatswitch.org/{~}nikita/papers/rainbow-ndss09.pdf},
year = {2009}
}
